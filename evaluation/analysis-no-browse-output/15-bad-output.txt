=== PHASE 1: ANALYSIS ===

Calling tool: createTodo
Todo List Created
Todo List (22 items):
- [ ] Search for any remaining references to removed classes `FormatError`, `FormatOn`, `FormatOff`, and ensure they are fully deleted and not imported or referenced anywhere in `black.py`. (ID: todo-1)
- [ ] Verify that `UnformattedLines` class and all its usages are removed: no instantiation, no type checks, no branching on `isinstance(..., UnformattedLines)`. (ID: todo-2)
- [ ] Confirm `LineGenerator.line()` signature no longer accepts a `type` parameter and all call sites are updated accordingly (no callers passing `type=...`). (ID: todo-3)
- [ ] Check `EmptyLineTracker.extra_empty_lines()` (and related methods) no longer special-case `UnformattedLines` and that removed logic doesn't leave unreachable branches. (ID: todo-4)
- [ ] Ensure `split_line()` only short-circuits on `line.is_comment` and that there are no remaining checks for `UnformattedLines`. (ID: todo-5)
- [ ] Confirm `generate_comments()` no longer raises any `FormatOn`/`FormatOff` exceptions and that all try/except handling for these exceptions has been removed from visitors. (ID: todo-6)
- [ ] Validate `LineGenerator.visit_default()` no longer contains exception handling for `FormatOff`/`FormatOn` and that comment handling only relies on `generate_comments()` results. (ID: todo-7)
- [ ] Verify the new `LineGenerator.visit_STANDALONE_COMMENT()` method exists and is registered by the visitor (method name matches token alias), calling `line()` only before the comment when no open brackets, then delegating to `visit_default()`. (ID: todo-8)
- [ ] Confirm that `visit_default()` will not produce extra blank lines around a `STANDALONE_COMMENT` leaf: since it iterates over comments in the leaf's prefix only, ensure it won't re-insert additional `line()` calls for the `STANDALONE_COMMENT` value itself. (ID: todo-9)
- [ ] Verify `normalize_fmt_off()` now repeatedly applies `convert_one_fmt_off_pair()` until no more conversions occur (looping with a boolean return), covering the entire file. (ID: todo-10)
- [ ] Inspect `convert_one_fmt_off_pair()` to ensure it only triggers on standalone or disguised standalone `# fmt: off` comments (checks `comment.type == STANDALONE_COMMENT` or preceding leaf is missing/whitespace) and skips inline `# fmt: off`. (ID: todo-11)
- [ ] Confirm that `convert_one_fmt_off_pair()` collects ignored nodes using `generate_ignored_nodes(leaf)`, removes them from the tree, and inserts a single `STANDALONE_COMMENT` leaf at the correct index (`first_idx`) in the parent. (ID: todo-12)
- [ ] Check that when building the new comment value, trailing newline from ignored nodes is trimmed (using `hidden_value.endswith("\n")`) to avoid introducing extra blank lines. (ID: todo-13)
- [ ] Ensure any necessary prefix handling is correct when replacing nodes with a `STANDALONE_COMMENT` leaf so that indentation/newlines before the block are preserved (verify use of prefixes and indices around insertion). (ID: todo-14)
- [ ] Review `generate_ignored_nodes()` to confirm it stops when encountering `# fmt: on` in the container's prefix and also stops at `token.ENDMARKER` (no unbounded traversal). (ID: todo-15)
- [ ] Validate `container_of()` now stops ascending at `syms.file_input`, preventing cross-file or top-level overreach when determining the container, and still respects `SURROUNDED_BY_BRACKETS` boundaries. (ID: todo-16)
- [ ] Ensure constants and symbols referenced in the new logic are defined/imported: `FMT_ON`, `FMT_OFF`, `STANDALONE_COMMENT`, `WHITESPACE`, `syms`, `SURROUNDED_BY_BRACKETS`. (ID: todo-17)
- [ ] Confirm that converting a `# fmt: off/on` region into a `STANDALONE_COMMENT` results in lines flagged as comments (`line.is_comment == True`) so that later formatting/splitting phases skip them (consistent with `split_line()` behavior). (ID: todo-18)
- [ ] Check that unmatched `# fmt: off` (no corresponding `# fmt: on`) is handled gracefully: by reading until block end without raising errors (no lingering raises of `SyntaxError` from prior implementation). (ID: todo-19)
- [ ] Verify `DebugVisitor.show()` signature accepts `Union[str, Leaf, Node]` and properly parses only when input is `str`, without breaking any call sites that used the previous signature. (ID: todo-20)
- [ ] Check typing imports: `Type` was removed from imports; ensure there are no remaining type hints or usages requiring `Type`. (ID: todo-21)
- [ ] Review test `test_fmtonoff2` to ensure it exercises a top-level `# fmt: off` region spanning multiple statements/functions and asserts that: (a) no extra blank lines are inserted between functions, and (b) code inside the off/on block (e.g., list of tuples) is not reformatted. (ID: todo-22)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 22
description: 'Search for any remaining references to removed classes `FormatError`, `FormatOn`, `FormatOff`, and ensure they are fully deleted and not imported or referenced anywhere in `black.py`.'
Calling tool: grepTool
Format(Error|On|Off)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
Format(Error|On|Off)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
FormatError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError

Calling tool: grepTool
class\s+Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
(?i)format(on|off|error)|Format(On|Off|Error)|FMT_ON|FMT_OFF
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
Format(On|Off|Error)|except\s+Format
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched the codebase with grep for FormatError/FormatOn/FormatOff and found no occurrences in black.py. The only remaining references are in docs. The diff removed the classes and their usages; no imports or references remain in black.py.


Todo item 1 of 22 is correct
description: 'Search for any remaining references to removed classes `FormatError`, `FormatOn`, `FormatOff`, and ensure they are fully deleted and not imported or referenced anywhere in `black.py`.'
Validating todo item 2 of 22
description: 'Verify that `UnformattedLines` class and all its usages are removed: no instantiation, no type checks, no branching on `isinstance(..., UnformattedLines)`.'
Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
class UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
isinstance\([^\)]*UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
visit_unformatted|type=UnformattedLines|UnformattedLines|visit_STANDALONE_COMMENT|FMT_OFF|generate_ignored_nodes|normalize_fmt_off|convert_one_fmt_off_pair|container_of|generate_comments|split_line|EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:608:    elt = EmptyLineTracker(is_pyi=is_pyi)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1426:            for comment in generate_comments(node):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2618:    container: Optional[LN] = container_of(leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:84:.. autofunction:: black.split_line
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:114:.. autofunction:: black.generate_comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:14::class:`EmptyLineTracker`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:17:.. autoclass:: black.EmptyLineTracker
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/comments5.py:61:# Note: crappy but inevitable.  The current design of EmptyLineTracker doesn't

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]

Calling tool: grepTool
visit_unformatted
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
line\(type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched the codebase for UnformattedLines and found no class or usages in black.py. Verified removals: no class definition, no instantiation, no isinstance/type checks, and line() no longer accepts a type argument. Only references left are in docs, not code.


Todo item 2 of 22 is correct
description: 'Verify that `UnformattedLines` class and all its usages are removed: no instantiation, no type checks, no branching on `isinstance(..., UnformattedLines)`.'
Validating todo item 3 of 22
description: 'Confirm `LineGenerator.line()` signature no longer accepts a `type` parameter and all call sites are updated accordingly (no callers passing `type=...`).'
Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:

Calling tool: grepTool
\.line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1433:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1437:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1440:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1453:        yield from self.line(+1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1461:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1468:        yield from self.line(-1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1487:                yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1505:                yield from self.line(+1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1507:                yield from self.line(-1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1511:                yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1516:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1532:            yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1537:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1542:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1546:            yield from self.line()

Calling tool: grepTool
(?i)UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
line\([^)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
\.line\(type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1406:    def line(self, indent: int = 0) -> Iterator[Line]:

Calling tool: grepTool
\.line\([^\)]*,
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `LineGenerator.line()` now has signature `def line(self, indent: int = 0)` and internally always constructs `Line`. Grep across the repo shows no `.line(` calls with `type=` or a second positional argument; all call sites pass only the indent (or none).


Todo item 3 of 22 is correct
description: 'Confirm `LineGenerator.line()` signature no longer accepts a `type` parameter and all call sites are updated accordingly (no callers passing `type=...`).'
Validating todo item 4 of 22
description: 'Check `EmptyLineTracker.extra_empty_lines()` (and related methods) no longer special-case `UnformattedLines` and that removed logic doesn't leave unreachable branches.'
Calling tool: grepTool
class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
extra_empty_lines\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
EmptyLineTracker\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:608:    elt = EmptyLineTracker(is_pyi=is_pyi)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: grepTool
visit_unformatted\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
EmptyLineTracker[\s\S]*isinstance\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: UnformattedLines is removed from black.py, and EmptyLineTracker.maybe_empty_lines (and helpers) no longer check for it. The early return special-case was deleted, and there are no remaining references to UnformattedLines or unreachable branches in these methods.


Todo item 4 of 22 is correct
description: 'Check `EmptyLineTracker.extra_empty_lines()` (and related methods) no longer special-case `UnformattedLines` and that removed logic doesn't leave unreachable branches.'
Validating todo item 5 of 22
description: 'Ensure `split_line()` only short-circuits on `line.is_comment` and that there are no remaining checks for `UnformattedLines`.'
Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with

Calling tool: grepTool
isinstance\(.*UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Checked split_line in black.py: it now only short-circuits on `line.is_comment` (no `UnformattedLines` check). Grep confirms no remaining references or isinstance checks for `UnformattedLines` in code (only in docs).


Todo item 5 of 22 is correct
description: 'Ensure `split_line()` only short-circuits on `line.is_comment` and that there are no remaining checks for `UnformattedLines`.'
Validating todo item 6 of 22
description: 'Confirm `generate_comments()` no longer raises any `FormatOn`/`FormatOff` exceptions and that all try/except handling for these exceptions has been removed from visitors.'
Calling tool: grepTool
class Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
generate_comments\(|FormatOn|FormatOff|visit_unformatted|UnformattedLines|try\:.*Format(On|Off)|except\s+Format(On|Off)
Matched content:
1426:            for comment in generate_comments(node):
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,

Calling tool: grepTool
except\s+Format(On|Off)|try\:.*Format(On|Off)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_unformatted|UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py that generate_comments (lines ~1971-1992) only yields comment Leaves and does not raise exceptions. Searched the codebase and found no FormatOn/FormatOff classes or try/except blocks handling them; LineGenerator.visit_default (lines ~1422-1448) processes comments without try/except, and UnformattedLines/visit_unformatted were removed.


Todo item 6 of 22 is correct
description: 'Confirm `generate_comments()` no longer raises any `FormatOn`/`FormatOff` exceptions and that all try/except handling for these exceptions has been removed from visitors.'
Validating todo item 7 of 22
description: 'Validate `LineGenerator.visit_default()` no longer contains exception handling for `FormatOff`/`FormatOn` and that comment handling only relies on `generate_comments()` results.'
Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: grepTool
def visit_default\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:701:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:712:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1422:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py LineGenerator.visit_default() (lines 1422-1448) there is no try/except for FormatOff/FormatOn. It iterates only over comments from generate_comments(node) and handles them accordingly. Also generate_comments no longer raises FormatOn/Off (lines 1971-1992), confirming reliance solely on its yielded comments.


Todo item 7 of 22 is correct
description: 'Validate `LineGenerator.visit_default()` no longer contains exception handling for `FormatOff`/`FormatOn` and that comment handling only relies on `generate_comments()` results.'
Validating todo item 8 of 22
description: 'Verify the new `LineGenerator.visit_STANDALONE_COMMENT()` method exists and is registered by the visitor (method name matches token alias), calling `line()` only before the comment when no open brackets, then delegating to `visit_default()`.'
Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:
2700:    lpar, expr, rpar = node.children
2701:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2702:        return is_yield(expr)
2703:
2704:    return False
2705:
2706:
2707:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2708:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2709:
2710:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2711:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2712:    extended iterable unpacking (PEP 3132) and additional unpacking
2713:    generalizations (PEP 448).
2714:    """
2715:    if leaf.type not in STARS or not leaf.parent:
2716:        return False
2717:
2718:    p = leaf.parent
2719:    if p.type == syms.star_expr:
2720:        # Star expressions are also used as assignment targets in extended
2721:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2722:        if not p.parent:
2723:            return False
2724:
2725:        p = p.parent
2726:
2727:    return p.type in within
2728:
2729:
2730:def is_multiline_string(leaf: Leaf) -> bool:
2731:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2732:    value = leaf.value.lstrip("furbFURB")
2733:    return value[:3] in {'"""', "'''"} and "\n" in value
2734:
2735:
2736:def is_stub_suite(node: Node) -> bool:
2737:    """Return True if `node` is a suite with a stub body."""
2738:    if (
2739:        len(node.children) != 4
2740:        or node.children[0].type != token.NEWLINE
2741:        or node.children[1].type != token.INDENT
2742:        or node.children[3].type != token.DEDENT
2743:    ):
2744:        return False
2745:
2746:    return is_stub_body(node.children[2])
2747:
2748:
2749:def is_stub_body(node: LN) -> bool:
2750:    """Return True if `node` is a simple statement containing an ellipsis."""
2751:    if not isinstance(node, Node) or node.type != syms.simple_stmt:
2752:        return False
2753:
2754:    if len(node.children) != 2:
2755:        return False
2756:
2757:    child = node.children[0]
2758:    return (
2759:        child.type == syms.atom
2760:        and len(child.children) == 3
2761:        and all(leaf == Leaf(token.DOT, ".") for leaf in child.children)
2762:    )
2763:
2764:
2765:def max_delimiter_priority_in_atom(node: LN) -> int:
2766:    """Return maximum delimiter priority inside `node`.
2767:
2768:    This is specific to atoms with contents contained in a pair of parentheses.
2769:    If `node` isn't an atom or there are no enclosing parentheses, returns 0.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Found LineGenerator.visit_STANDALONE_COMMENT in black.py which checks for open brackets and calls line() only when none are open, then delegates to visit_default(). The method name matches the STANDALONE_COMMENT token alias ensuring visitor dispatch.


Todo item 8 of 22 is correct
description: 'Verify the new `LineGenerator.visit_STANDALONE_COMMENT()` method exists and is registered by the visitor (method name matches token alias), calling `line()` only before the comment when no open brackets, then delegating to `visit_default()`.'
Validating todo item 9 of 22
description: 'Confirm that `visit_default()` will not produce extra blank lines around a `STANDALONE_COMMENT` leaf: since it iterates over comments in the leaf's prefix only, ensure it won't re-insert additional `line()` calls for the `STANDALONE_COMMENT` value itself.'
Calling tool: grepTool
visit_STANDALONE_COMMENT\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
visit_STANDALONE_COMMENT\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: grepTool
def visit_default\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:701:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:712:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1422:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: grepTool
def visit_NEWLINE\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `visit_default()` iterates only over `generate_comments(node)` which yields comments from `leaf.prefix` only, not the leaf’s own value. For a `STANDALONE_COMMENT` leaf, `visit_STANDALONE_COMMENT` yields a line before, then delegates to `visit_default()`. Since `generate_comments` won’t return the `STANDALONE_COMMENT` value, `visit_default()` won’t call `line()` again around it, avoiding extra blank lines.


Todo item 9 of 22 is correct
description: 'Confirm that `visit_default()` will not produce extra blank lines around a `STANDALONE_COMMENT` leaf: since it iterates over comments in the leaf's prefix only, ensure it won't re-insert additional `line()` calls for the `STANDALONE_COMMENT` value itself.'
Validating todo item 10 of 22
description: 'Verify `normalize_fmt_off()` now repeatedly applies `convert_one_fmt_off_pair()` until no more conversions occur (looping with a boolean return), covering the entire file.'
Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
normalize_fmt_off\(|convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)

Calling tool: grepTool
hide_fmt_off\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_fmt_off(node) now uses a while loop with a try_again flag that repeatedly calls convert_one_fmt_off_pair(node) until it returns False (lines 2555–2560). convert_one_fmt_off_pair returns True upon converting a pair and False otherwise (lines 2562–2611). normalize_fmt_off is invoked on the root src_node, covering the entire file (line 602).


Todo item 10 of 22 is correct
description: 'Verify `normalize_fmt_off()` now repeatedly applies `convert_one_fmt_off_pair()` until no more conversions occur (looping with a boolean return), covering the entire file.'
Validating todo item 11 of 22
description: 'Inspect `convert_one_fmt_off_pair()` to ensure it only triggers on standalone or disguised standalone `# fmt: off` comments (checks `comment.type == STANDALONE_COMMENT` or preceding leaf is missing/whitespace) and skips inline `# fmt: off`.'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1796:                return NO
1797:
1798:        elif t == token.NAME:
1799:            if v == "import":
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent

Calling tool: grepTool
WHITESPACE\s*=\s*\{
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py convert_one_fmt_off_pair(), the code explicitly checks for STANDALONE_COMMENT or a disguised standalone via preceding_leaf being missing/WHITESPACE before acting; otherwise it continues, thereby skipping inline `# fmt: off`. Verified at lines 2570–2577.


Todo item 11 of 22 is correct
description: 'Inspect `convert_one_fmt_off_pair()` to ensure it only triggers on standalone or disguised standalone `# fmt: off` comments (checks `comment.type == STANDALONE_COMMENT` or preceding leaf is missing/whitespace) and skips inline `# fmt: off`.'
Validating todo item 12 of 22
description: 'Confirm that `convert_one_fmt_off_pair()` collects ignored nodes using `generate_ignored_nodes(leaf)`, removes them from the tree, and inserts a single `STANDALONE_COMMENT` leaf at the correct index (`first_idx`) in the parent.'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""

Calling tool: grepTool
def remove\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/**/black.py: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/**/black.py: No such file or directory (os error 2)


Calling tool: grepTool
def remove\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.py:141:    def remove(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.pyi:34:    def remove(self) -> Optional[int]: ...

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.py
1:# Copyright 2006 Google, Inc. All Rights Reserved.
2:# Licensed to PSF under a Contributor Agreement.
3:
4:"""
5:Python parse tree definitions.
6:
7:This is a very concrete parse tree; we need to keep every token and
8:even the comments and whitespace between tokens.
9:
10:There's also a pattern matching implementation here.
11:"""
12:
13:__author__ = "Guido van Rossum <guido@python.org>"
14:
15:import sys
16:from io import StringIO
17:
18:HUGE = 0x7FFFFFFF  # maximum repeat count, default max
19:
20:_type_reprs = {}
21:def type_repr(type_num):
22:    global _type_reprs
23:    if not _type_reprs:
24:        from .pygram import python_symbols
25:        # printing tokens is possible but not as useful
26:        # from .pgen2 import token // token.__dict__.items():
27:        for name, val in python_symbols.__dict__.items():
28:            if type(val) == int: _type_reprs[val] = name
29:    return _type_reprs.setdefault(type_num, type_num)
30:
31:class Base(object):
32:
33:    """
34:    Abstract base class for Node and Leaf.
35:
36:    This provides some default functionality and boilerplate using the
37:    template pattern.
38:
39:    A node may be a subnode of at most one parent.
40:    """
41:
42:    # Default values for instance variables
43:    type = None    # int: token number (< 256) or symbol number (>= 256)
44:    parent = None  # Parent node pointer, or None
45:    children = ()  # Tuple of subnodes
46:    was_changed = False
47:    was_checked = False
48:
49:    def __new__(cls, *args, **kwds):
50:        """Constructor that prevents Base from being instantiated."""
51:        assert cls is not Base, "Cannot instantiate Base"
52:        return object.__new__(cls)
53:
54:    def __eq__(self, other):
55:        """
56:        Compare two nodes for equality.
57:
58:        This calls the method _eq().
59:        """
60:        if self.__class__ is not other.__class__:
61:            return NotImplemented
62:        return self._eq(other)
63:
64:    __hash__ = None # For Py3 compatibility.
65:
66:    def _eq(self, other):
67:        """
68:        Compare two nodes for equality.
69:
70:        This is called by __eq__ and __ne__.  It is only called if the two nodes
71:        have the same type.  This must be implemented by the concrete subclass.
72:        Nodes should be considered equal if they have the same structure,
73:        ignoring the prefix string and other context information.
74:        """
75:        raise NotImplementedError
76:
77:    def clone(self):
78:        """
79:        Return a cloned (deep) copy of self.
80:
81:        This must be implemented by the concrete subclass.
82:        """
83:        raise NotImplementedError
84:
85:    def post_order(self):
86:        """
87:        Return a post-order iterator for the tree.
88:
89:        This must be implemented by the concrete subclass.
90:        """
91:        raise NotImplementedError
92:
93:    def pre_order(self):
94:        """
95:        Return a pre-order iterator for the tree.
96:
97:        This must be implemented by the concrete subclass.
98:        """
99:        raise NotImplementedError
100:
101:    def replace(self, new):
102:        """Replace this node with a new one in the parent."""
103:        assert self.parent is not None, str(self)
104:        assert new is not None
105:        if not isinstance(new, list):
106:            new = [new]
107:        l_children = []
108:        found = False
109:        for ch in self.parent.children:
110:            if ch is self:
111:                assert not found, (self.parent.children, self, new)
112:                if new is not None:
113:                    l_children.extend(new)
114:                found = True
115:            else:
116:                l_children.append(ch)
117:        assert found, (self.children, self, new)
118:        self.parent.children = l_children
119:        self.parent.changed()
120:        self.parent.invalidate_sibling_maps()
121:        for x in new:
122:            x.parent = self.parent
123:        self.parent = None
124:
125:    def get_lineno(self):
126:        """Return the line number which generated the invocant node."""
127:        node = self
128:        while not isinstance(node, Leaf):
129:            if not node.children:
130:                return
131:            node = node.children[0]
132:        return node.lineno
133:
134:    def changed(self):
135:        if self.was_changed:
136:            return
137:        if self.parent:
138:            self.parent.changed()
139:        self.was_changed = True
140:
141:    def remove(self):
142:        """
143:        Remove the node from the tree. Returns the position of the node in its
144:        parent's children before it was removed.
145:        """
146:        if self.parent:
147:            for i, node in enumerate(self.parent.children):
148:                if node is self:
149:                    del self.parent.children[i]
150:                    self.parent.changed()
151:                    self.parent.invalidate_sibling_maps()
152:                    self.parent = None
153:                    return i
154:
155:    @property
156:    def next_sibling(self):
157:        """
158:        The node immediately following the invocant in their parent's children
159:        list. If the invocant does not have a next sibling, it is None
160:        """
161:        if self.parent is None:
162:            return None
163:
164:        if self.parent.next_sibling_map is None:
165:            self.parent.update_sibling_maps()
166:        return self.parent.next_sibling_map[id(self)]
167:
168:    @property
169:    def prev_sibling(self):
170:        """
171:        The node immediately preceding the invocant in their parent's children
172:        list. If the invocant does not have a previous sibling, it is None.
173:        """
174:        if self.parent is None:
175:            return None
176:
177:        if self.parent.prev_sibling_map is None:
178:            self.parent.update_sibling_maps()
179:        return self.parent.prev_sibling_map[id(self)]
180:
181:    def leaves(self):
182:        for child in self.children:
183:            yield from child.leaves()
184:
185:    def depth(self):
186:        if self.parent is None:
187:            return 0
188:        return 1 + self.parent.depth()
189:
190:    def get_suffix(self):
191:        """
192:        Return the string immediately following the invocant node. This is
193:        effectively equivalent to node.next_sibling.prefix
194:        """
195:        next_sib = self.next_sibling
196:        if next_sib is None:
197:            return ""
198:        return next_sib.prefix
199:
200:    if sys.version_info < (3, 0):
201:        def __str__(self):
202:            return str(self).encode("ascii")
203:
204:class Node(Base):
205:
206:    """Concrete implementation for interior nodes."""
207:
208:    def __init__(self,type, children,
209:                 context=None,
210:                 prefix=None,
211:                 fixers_applied=None):
212:        """
213:        Initializer.
214:
215:        Takes a type constant (a symbol number >= 256), a sequence of
216:        child nodes, and an optional context keyword argument.
217:
218:        As a side effect, the parent pointers of the children are updated.
219:        """
220:        assert type >= 256, type

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), it collects ignored_nodes via generate_ignored_nodes(leaf), removes each ignored node (capturing the index of the first removal as first_idx), and inserts a single STANDALONE_COMMENT Leaf at parent.insert_child(first_idx, ...). Verified on lines 2579–2605 of black.py.


Todo item 12 of 22 is correct
description: 'Confirm that `convert_one_fmt_off_pair()` collects ignored nodes using `generate_ignored_nodes(leaf)`, removes them from the tree, and inserts a single `STANDALONE_COMMENT` leaf at the correct index (`first_idx`) in the parent.'
Validating todo item 13 of 22
description: 'Check that when building the new comment value, trailing newline from ignored nodes is trimmed (using `hidden_value.endswith("\n")`) to avoid introducing extra blank lines.'
Calling tool: grepTool
convert_one_fmt_off_pair\(|hidden_value\.endswith\(|normalize_fmt_off\(|hide_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2587:                if hidden_value.endswith("\n"):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s convert_one_fmt_off_pair(), the new comment value hidden_value is built and then checked with hidden_value.endswith("\n"); if true, the trailing newline is trimmed (hidden_value = hidden_value[:-1]). This prevents extra blank lines, satisfying the requirement.


Todo item 13 of 22 is correct
description: 'Check that when building the new comment value, trailing newline from ignored nodes is trimmed (using `hidden_value.endswith("\n")`) to avoid introducing extra blank lines.'
Validating todo item 14 of 22
description: 'Ensure any necessary prefix handling is correct when replacing nodes with a `STANDALONE_COMMENT` leaf so that indentation/newlines before the block are preserved (verify use of prefixes and indices around insertion).'
Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:

Calling tool: globTool
**/*test*
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black: No such file or directory (os error 2)


Calling tool: globTool
**/*test*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py

Calling tool: grepTool
test_fmtonoff2
Matched content:
404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(
480:                unstyle(str(report)),
481:                "2 files reformatted, 2 files left unchanged, "
482:                "1 file failed to reformat.",
483:            )
484:            self.assertEqual(report.return_code, 123)
485:            report.failed(Path("e2"), "boom")
486:            self.assertEqual(len(out_lines), 4)
487:            self.assertEqual(len(err_lines), 2)
488:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
489:            self.assertEqual(
490:                unstyle(str(report)),
491:                "2 files reformatted, 2 files left unchanged, "
492:                "2 files failed to reformat.",
493:            )
494:            self.assertEqual(report.return_code, 123)
495:            report.path_ignored(Path("wat"), "no match")
496:            self.assertEqual(len(out_lines), 5)
497:            self.assertEqual(len(err_lines), 2)
498:            self.assertEqual(out_lines[-1], "wat ignored: no match")
499:            self.assertEqual(

Calling tool: globTool
**/tests/data/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
def read_data\(
Matched content:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py
1:#!/usr/bin/env python3
2:import asyncio
3:import sys
4:
5:from third_party import X, Y, Z
6:
7:from library import some_connection, \
8:                    some_decorator
9:# fmt: off
10:from third_party import (X,
11:                         Y, Z)
12:# fmt: on
13:f'trigger 3.6 mode'
14:# fmt: off
15:def func_no_args():
16:  a; b; c
17:  if True: raise RuntimeError
18:  if False: ...
19:  for i in range(10):
20:    print(i)
21:    continue
22:  exec('new-style exec', {}, {})
23:  return None
24:async def coroutine(arg, exec=False):
25: 'Single-line docstring. Multiline is harder to reformat.'
26: async with some_connection() as conn:
27:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
28: await asyncio.sleep(1)
29:@asyncio.coroutine
30:@some_decorator(
31:with_args=True,
32:many_args=[1,2,3]
33:)
34:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
35: return text[number:-1]
36:# fmt: on
37:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r''):
38: offset = attr.ib(default=attr.Factory( lambda: _r.uniform(10000, 200000)))
39: assert task._cancel_stack[:len(old_stack)] == old_stack
40:def spaces_types(a: int = 1, b: tuple = (), c: list = [], d: dict = {}, e: bool = True, f: int = -1, g: int = 1 if False else 2, h: str = "", i: str = r''): ...
41:def spaces2(result= _core.Value(None)):
42: ...
43:something = {
44:    # fmt: off
45:    key: 'value',
46:}
47:def example(session):
48:    # fmt: off
49:    result = session\
50:        .query(models.Customer.id)\
51:        .filter(models.Customer.account_id == account_id,
52:                models.Customer.email == email_address)\
53:        .order_by(models.Customer.id.asc())\
54:        .all()
55:    # fmt: on
56:def long_lines():
57:    if True:
58:        typedargslist.extend(
59:            gen_annotated_params(ast_args.kwonlyargs, ast_args.kw_defaults, parameters, implicit_default=True)
60:        )
61:        # fmt: off
62:        a = (
63:            unnecessary_bracket()
64:        )
65:        # fmt: on
66:    _type_comment_re = re.compile(
67:        r"""
68:        ^
69:        [\t ]*
70:        \#[ ]type:[ ]*
71:        (?P<type>
72:            [^#\t\n]+?
73:        )
74:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
75:                        # a trailing space which is why we need the silliness below
76:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
77:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
78:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
79:        [\t ]*
80:        (?P<nl>
81:            (?:\#[^\n]*)?
82:            \n?
83:        )
84:        $
85:        """,
86:        # fmt: off
87:        re.MULTILINE|re.VERBOSE
88:        # fmt: on
89:    )
90:def single_literal_yapf_disable():
91:    """Black does not support this."""
92:    BAZ = {
93:        (1, 2, 3, 4),
94:        (5, 6, 7, 8),
95:        (9, 10, 11, 12),
96:    }  # yapf: disable
97:cfg.rule(
98:    "Default", "address",
99:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
100:    xxxxxx="xx_xxxxx", xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
101:    xxxxxxxxx_xxxx=True, xxxxxxxx_xxxxxxxxxx=False,
102:    xxxxxx_xxxxxx=2, xxxxxx_xxxxx_xxxxxxxx=70, xxxxxx_xxxxxx_xxxxx=True,
103:    # fmt: off
104:    xxxxxxx_xxxxxxxxxxxx={
105:        "xxxxxxxx": {
106:            "xxxxxx": False,
107:            "xxxxxxx": False,
108:            "xxxx_xxxxxx": "xxxxx",
109:        },
110:        "xxxxxxxx-xxxxx": {
111:            "xxxxxx": False,
112:            "xxxxxxx": True,
113:            "xxxx_xxxxxx": "xxxxxx",
114:        },
115:    },
116:    # fmt: on
117:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5
118:)
119:# fmt: off
120:# No formatting to the end of the file
121:l=[1,2,3]
122:d={'a':1,
123:   'b':2}
124:
125:# output
126:
127:
128:#!/usr/bin/env python3
129:import asyncio
130:import sys
131:
132:from third_party import X, Y, Z
133:
134:from library import some_connection, some_decorator
135:
136:# fmt: off
137:from third_party import (X,
138:                         Y, Z)
139:# fmt: on
140:f"trigger 3.6 mode"
141:# fmt: off
142:def func_no_args():
143:  a; b; c
144:  if True: raise RuntimeError
145:  if False: ...
146:  for i in range(10):
147:    print(i)
148:    continue
149:  exec('new-style exec', {}, {})
150:  return None
151:async def coroutine(arg, exec=False):
152: 'Single-line docstring. Multiline is harder to reformat.'
153: async with some_connection() as conn:
154:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
155: await asyncio.sleep(1)
156:@asyncio.coroutine
157:@some_decorator(
158:with_args=True,
159:many_args=[1,2,3]
160:)
161:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
162: return text[number:-1]
163:# fmt: on
164:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r""):
165:    offset = attr.ib(default=attr.Factory(lambda: _r.uniform(10000, 200000)))
166:    assert task._cancel_stack[: len(old_stack)] == old_stack
167:
168:
169:def spaces_types(
170:    a: int = 1,
171:    b: tuple = (),
172:    c: list = [],
173:    d: dict = {},
174:    e: bool = True,
175:    f: int = -1,
176:    g: int = 1 if False else 2,
177:    h: str = "",
178:    i: str = r"",
179:):
180:    ...
181:
182:
183:def spaces2(result=_core.Value(None)):
184:    ...
185:
186:
187:something = {
188:    # fmt: off
189:    key: 'value',
190:}
191:
192:
193:def example(session):
194:    # fmt: off
195:    result = session\
196:        .query(models.Customer.id)\
197:        .filter(models.Customer.account_id == account_id,
198:                models.Customer.email == email_address)\
199:        .order_by(models.Customer.id.asc())\
200:        .all()
201:    # fmt: on
202:
203:
204:def long_lines():
205:    if True:
206:        typedargslist.extend(
207:            gen_annotated_params(
208:                ast_args.kwonlyargs,
209:                ast_args.kw_defaults,
210:                parameters,
211:                implicit_default=True,
212:            )
213:        )
214:        # fmt: off
215:        a = (
216:            unnecessary_bracket()
217:        )
218:        # fmt: on
219:    _type_comment_re = re.compile(
220:        r"""
221:        ^
222:        [\t ]*
223:        \#[ ]type:[ ]*
224:        (?P<type>
225:            [^#\t\n]+?
226:        )
227:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
228:                        # a trailing space which is why we need the silliness below
229:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
230:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
231:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
232:        [\t ]*
233:        (?P<nl>
234:            (?:\#[^\n]*)?
235:            \n?
236:        )
237:        $
238:        """,
239:        # fmt: off
240:        re.MULTILINE|re.VERBOSE
241:        # fmt: on
242:    )
243:
244:
245:def single_literal_yapf_disable():
246:    """Black does not support this."""
247:    BAZ = {(1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12)}  # yapf: disable
248:
249:
250:cfg.rule(
251:    "Default",
252:    "address",
253:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
254:    xxxxxx="xx_xxxxx",
255:    xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
256:    xxxxxxxxx_xxxx=True,
257:    xxxxxxxx_xxxxxxxxxx=False,
258:    xxxxxx_xxxxxx=2,
259:    xxxxxx_xxxxx_xxxxxxxx=70,
260:    xxxxxx_xxxxxx_xxxxx=True,
261:    # fmt: off
262:    xxxxxxx_xxxxxxxxxxxx={
263:        "xxxxxxxx": {
264:            "xxxxxx": False,
265:            "xxxxxxx": False,
266:            "xxxx_xxxxxx": "xxxxx",
267:        },
268:        "xxxxxxxx-xxxxx": {
269:            "xxxxxx": False,
270:            "xxxxxxx": True,
271:            "xxxx_xxxxxx": "xxxxxx",
272:        },
273:    },
274:    # fmt: on
275:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5,
276:)
277:# fmt: off
278:# No formatting to the end of the file
279:l=[1,2,3]
280:d={'a':1,
281:   'b':2}

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), the code trims the original container prefix at the fmt: off location (first.prefix = prefix[comment.consumed:]) and inserts a STANDALONE_COMMENT leaf at the correct index (first_idx) with a prefix that preserves preceding whitespace/newlines (prefix[:previous_consumed] + "\n" * comment.newlines). This ensures indentation/newlines before the block are preserved during replacement.


Todo item 14 of 22 is correct
description: 'Ensure any necessary prefix handling is correct when replacing nodes with a `STANDALONE_COMMENT` leaf so that indentation/newlines before the block are preserved (verify use of prefixes and indices around insertion).'
Validating todo item 15 of 22
description: 'Review `generate_ignored_nodes()` to confirm it stops when encountering `# fmt: on` in the container's prefix and also stops at `token.ENDMARKER` (no unbounded traversal).'
Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Reviewed black.py: generate_ignored_nodes() loops while container is not None and not ENDMARKER, and returns immediately upon encountering FMT_ON in the container’s prefix. This satisfies both stopping conditions.


Todo item 15 of 22 is correct
description: 'Review `generate_ignored_nodes()` to confirm it stops when encountering `# fmt: on` in the container's prefix and also stops at `token.ENDMARKER` (no unbounded traversal).'
Validating todo item 16 of 22
description: 'Validate `container_of()` now stops ascending at `syms.file_input`, preventing cross-file or top-level overreach when determining the container, and still respects `SURROUNDED_BY_BRACKETS` boundaries.'
Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Validated in black/black.py container_of(): it now breaks when parent.type == syms.file_input (lines ~1852-1854) and still breaks for parent.type in SURROUNDED_BY_BRACKETS (line ~1855). This prevents top-level overreach while respecting bracket boundaries.


Todo item 16 of 22 is correct
description: 'Validate `container_of()` now stops ascending at `syms.file_input`, preventing cross-file or top-level overreach when determining the container, and still respects `SURROUNDED_BY_BRACKETS` boundaries.'
Validating todo item 17 of 22
description: 'Ensure constants and symbols referenced in the new logic are defined/imported: `FMT_ON`, `FMT_OFF`, `STANDALONE_COMMENT`, `WHITESPACE`, `syms`, `SURROUNDED_BY_BRACKETS`.'
Calling tool: grepTool
(?i)^\s*(FMT_ON|FMT_OFF|STANDALONE_COMMENT|WHITESPACE|SURROUNDED_BY_BRACKETS|syms)\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:77:syms = pygram.python_symbols
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:748:    syms.if_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:749:    syms.while_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:750:    syms.for_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:751:    syms.try_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:752:    syms.except_clause,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:753:    syms.with_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:754:    syms.funcdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:755:    syms.classdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:786:    syms.arglist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:787:    syms.argument,  # double star in arglist
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:788:    syms.trailer,  # single argument to call
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:789:    syms.typedargslist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:790:    syms.varargslist,  # lambdas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:793:    syms.atom,  # single element of a list or set literal
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:794:    syms.dictsetmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:795:    syms.listmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:796:    syms.testlist_gexp,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:797:    syms.testlist_star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:800:    syms.typedargslist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:801:    syms.arglist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:802:    syms.subscriptlist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:803:    syms.vfplist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:804:    syms.import_as_names,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:805:    syms.yield_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:806:    syms.testlist_gexp,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:807:    syms.testlist_star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:808:    syms.listmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:809:    syms.dictsetmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:812:    syms.test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:813:    syms.lambdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:814:    syms.or_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:815:    syms.and_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:816:    syms.not_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:817:    syms.comparison,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:818:    syms.star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:819:    syms.expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:820:    syms.xor_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:821:    syms.and_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:822:    syms.shift_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:823:    syms.arith_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:824:    syms.trailer,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:825:    syms.term,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:826:    syms.power,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1601:        syms.subscript,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1602:        syms.subscriptlist,

Calling tool: grepTool
FMT_ON\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}

Calling tool: grepTool
FMT_OFF\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}

Calling tool: grepTool
pygram\.
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:76:pygram.initialize(CACHE_DIR)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:77:syms = pygram.python_symbols
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:640:    pygram.python_grammar_no_print_statement_no_exec_statement,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:641:    pygram.python_grammar_no_print_statement,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:642:    pygram.python_grammar,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:648:    grammar = pygram.python_grammar_no_print_statement

Calling tool: grepTool
from\s+lib2to3\.(pygram|pgen2|pygram)\s+import|import\s+lib2to3\.pygram
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,
820:    syms.xor_expr,
821:    syms.and_expr,
822:    syms.shift_expr,
823:    syms.arith_expr,
824:    syms.trailer,
825:    syms.term,
826:    syms.power,
827:}
828:ASSIGNMENTS = {
829:    "=",
830:    "+=",
831:    "-=",
832:    "*=",
833:    "@=",
834:    "/=",
835:    "%=",
836:    "&=",
837:    "|=",
838:    "^=",
839:    "<<=",
840:    ">>=",
841:    "**=",
842:    "//=",
843:}
844:COMPREHENSION_PRIORITY = 20
845:COMMA_PRIORITY = 18
846:TERNARY_PRIORITY = 16
847:LOGIC_PRIORITY = 14
848:STRING_PRIORITY = 12
849:COMPARATOR_PRIORITY = 10

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment

Calling tool: grepTool
def\s+list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result

Calling tool: grepTool
def\s+normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified all referenced names exist in black.py: syms defined from blib2to3.pygram; WHITESPACE, STANDALONE_COMMENT, SURROUNDED_BY_BRACKETS constants are defined; FMT_OFF and FMT_ON sets are defined before use. New logic references resolve correctly.


Todo item 17 of 22 is correct
description: 'Ensure constants and symbols referenced in the new logic are defined/imported: `FMT_ON`, `FMT_OFF`, `STANDALONE_COMMENT`, `WHITESPACE`, `syms`, `SURROUNDED_BY_BRACKETS`.'
Validating todo item 18 of 22
description: 'Confirm that converting a `# fmt: off/on` region into a `STANDALONE_COMMENT` results in lines flagged as comments (`line.is_comment == True`) so that later formatting/splitting phases skip them (consistent with `split_line()` behavior).'
Calling tool: grepTool
class Line|def is_comment|is_comment\b|STANDALONE_COMMENT|normalize_fmt_off|convert_one_fmt_off_pair|generate_ignored_nodes|split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2064:    if line.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The fix converts fmt-off/on regions into a single STANDALONE_COMMENT leaf (convert_one_fmt_off_pair inserts Leaf(STANDALONE_COMMENT, ...), lines 2600-2605). Line.is_comment returns True when the line has exactly one STANDALONE_COMMENT leaf (lines 1048-1051). LineGenerator.visit_STANDALONE_COMMENT flushes before appending the comment so it stands alone on its own Line (lines 1544-1547). split_line() now skips such lines by early-return when line.is_comment is True (lines 2064-2066).


Todo item 18 of 22 is correct
description: 'Confirm that converting a `# fmt: off/on` region into a `STANDALONE_COMMENT` results in lines flagged as comments (`line.is_comment == True`) so that later formatting/splitting phases skip them (consistent with `split_line()` behavior).'
Validating todo item 19 of 22
description: 'Check that unmatched `# fmt: off` (no corresponding `# fmt: on`) is handled gracefully: by reading until block end without raising errors (no lingering raises of `SyntaxError` from prior implementation).'
Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:

Calling tool: grepTool
SyntaxError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:255:    disagree, a SyntaxError will be raised. If the encoding cookie is an invalid
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:256:    charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:283:            raise SyntaxError("unknown encoding: " + encoding)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:288:                raise SyntaxError('encoding problem: utf-8')
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/pgen.py:334:        raise SyntaxError(msg, (self.filename, self.end[0],

Calling tool: globTool
**/test_fmtonoff2*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: globTool
**/tests/data/fmtonoff2.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
fmt: off
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:9:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:14:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:44:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:48:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:61:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:86:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:103:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:119:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:136:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:141:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:188:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:194:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:214:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:239:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:261:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:277:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py:6:# fmt: off

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py
1:#!/usr/bin/env python3
2:import asyncio
3:import sys
4:
5:from third_party import X, Y, Z
6:
7:from library import some_connection, \
8:                    some_decorator
9:# fmt: off
10:from third_party import (X,
11:                         Y, Z)
12:# fmt: on
13:f'trigger 3.6 mode'
14:# fmt: off
15:def func_no_args():
16:  a; b; c
17:  if True: raise RuntimeError
18:  if False: ...
19:  for i in range(10):
20:    print(i)
21:    continue
22:  exec('new-style exec', {}, {})
23:  return None
24:async def coroutine(arg, exec=False):
25: 'Single-line docstring. Multiline is harder to reformat.'
26: async with some_connection() as conn:
27:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
28: await asyncio.sleep(1)
29:@asyncio.coroutine
30:@some_decorator(
31:with_args=True,
32:many_args=[1,2,3]
33:)
34:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
35: return text[number:-1]
36:# fmt: on
37:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r''):
38: offset = attr.ib(default=attr.Factory( lambda: _r.uniform(10000, 200000)))
39: assert task._cancel_stack[:len(old_stack)] == old_stack
40:def spaces_types(a: int = 1, b: tuple = (), c: list = [], d: dict = {}, e: bool = True, f: int = -1, g: int = 1 if False else 2, h: str = "", i: str = r''): ...
41:def spaces2(result= _core.Value(None)):
42: ...
43:something = {
44:    # fmt: off
45:    key: 'value',
46:}
47:def example(session):
48:    # fmt: off
49:    result = session\
50:        .query(models.Customer.id)\
51:        .filter(models.Customer.account_id == account_id,
52:                models.Customer.email == email_address)\
53:        .order_by(models.Customer.id.asc())\
54:        .all()
55:    # fmt: on
56:def long_lines():
57:    if True:
58:        typedargslist.extend(
59:            gen_annotated_params(ast_args.kwonlyargs, ast_args.kw_defaults, parameters, implicit_default=True)
60:        )
61:        # fmt: off
62:        a = (
63:            unnecessary_bracket()
64:        )
65:        # fmt: on
66:    _type_comment_re = re.compile(
67:        r"""
68:        ^
69:        [\t ]*
70:        \#[ ]type:[ ]*
71:        (?P<type>
72:            [^#\t\n]+?
73:        )
74:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
75:                        # a trailing space which is why we need the silliness below
76:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
77:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
78:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
79:        [\t ]*
80:        (?P<nl>
81:            (?:\#[^\n]*)?
82:            \n?
83:        )
84:        $
85:        """,
86:        # fmt: off
87:        re.MULTILINE|re.VERBOSE
88:        # fmt: on
89:    )
90:def single_literal_yapf_disable():
91:    """Black does not support this."""
92:    BAZ = {
93:        (1, 2, 3, 4),
94:        (5, 6, 7, 8),
95:        (9, 10, 11, 12),
96:    }  # yapf: disable
97:cfg.rule(
98:    "Default", "address",
99:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
100:    xxxxxx="xx_xxxxx", xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
101:    xxxxxxxxx_xxxx=True, xxxxxxxx_xxxxxxxxxx=False,
102:    xxxxxx_xxxxxx=2, xxxxxx_xxxxx_xxxxxxxx=70, xxxxxx_xxxxxx_xxxxx=True,
103:    # fmt: off
104:    xxxxxxx_xxxxxxxxxxxx={
105:        "xxxxxxxx": {
106:            "xxxxxx": False,
107:            "xxxxxxx": False,
108:            "xxxx_xxxxxx": "xxxxx",
109:        },
110:        "xxxxxxxx-xxxxx": {
111:            "xxxxxx": False,
112:            "xxxxxxx": True,
113:            "xxxx_xxxxxx": "xxxxxx",
114:        },
115:    },
116:    # fmt: on
117:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5
118:)
119:# fmt: off
120:# No formatting to the end of the file
121:l=[1,2,3]
122:d={'a':1,
123:   'b':2}
124:
125:# output
126:
127:
128:#!/usr/bin/env python3
129:import asyncio
130:import sys
131:
132:from third_party import X, Y, Z
133:
134:from library import some_connection, some_decorator
135:
136:# fmt: off
137:from third_party import (X,
138:                         Y, Z)
139:# fmt: on
140:f"trigger 3.6 mode"
141:# fmt: off
142:def func_no_args():
143:  a; b; c
144:  if True: raise RuntimeError
145:  if False: ...
146:  for i in range(10):
147:    print(i)
148:    continue
149:  exec('new-style exec', {}, {})
150:  return None
151:async def coroutine(arg, exec=False):
152: 'Single-line docstring. Multiline is harder to reformat.'
153: async with some_connection() as conn:
154:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
155: await asyncio.sleep(1)
156:@asyncio.coroutine
157:@some_decorator(
158:with_args=True,
159:many_args=[1,2,3]
160:)
161:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
162: return text[number:-1]
163:# fmt: on
164:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r""):
165:    offset = attr.ib(default=attr.Factory(lambda: _r.uniform(10000, 200000)))
166:    assert task._cancel_stack[: len(old_stack)] == old_stack
167:
168:
169:def spaces_types(
170:    a: int = 1,
171:    b: tuple = (),
172:    c: list = [],
173:    d: dict = {},
174:    e: bool = True,
175:    f: int = -1,
176:    g: int = 1 if False else 2,
177:    h: str = "",
178:    i: str = r"",
179:):
180:    ...
181:
182:
183:def spaces2(result=_core.Value(None)):
184:    ...
185:
186:
187:something = {
188:    # fmt: off
189:    key: 'value',
190:}
191:
192:
193:def example(session):
194:    # fmt: off
195:    result = session\
196:        .query(models.Customer.id)\
197:        .filter(models.Customer.account_id == account_id,
198:                models.Customer.email == email_address)\
199:        .order_by(models.Customer.id.asc())\
200:        .all()
201:    # fmt: on
202:
203:
204:def long_lines():
205:    if True:
206:        typedargslist.extend(
207:            gen_annotated_params(
208:                ast_args.kwonlyargs,
209:                ast_args.kw_defaults,
210:                parameters,
211:                implicit_default=True,
212:            )
213:        )
214:        # fmt: off
215:        a = (
216:            unnecessary_bracket()
217:        )
218:        # fmt: on
219:    _type_comment_re = re.compile(
220:        r"""
221:        ^
222:        [\t ]*
223:        \#[ ]type:[ ]*
224:        (?P<type>
225:            [^#\t\n]+?
226:        )
227:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
228:                        # a trailing space which is why we need the silliness below
229:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
230:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
231:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
232:        [\t ]*
233:        (?P<nl>
234:            (?:\#[^\n]*)?
235:            \n?
236:        )
237:        $
238:        """,
239:        # fmt: off
240:        re.MULTILINE|re.VERBOSE
241:        # fmt: on
242:    )
243:
244:
245:def single_literal_yapf_disable():
246:    """Black does not support this."""
247:    BAZ = {(1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12)}  # yapf: disable
248:
249:
250:cfg.rule(
251:    "Default",
252:    "address",
253:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
254:    xxxxxx="xx_xxxxx",
255:    xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
256:    xxxxxxxxx_xxxx=True,
257:    xxxxxxxx_xxxxxxxxxx=False,
258:    xxxxxx_xxxxxx=2,
259:    xxxxxx_xxxxx_xxxxxxxx=70,
260:    xxxxxx_xxxxxx_xxxxx=True,
261:    # fmt: off
262:    xxxxxxx_xxxxxxxxxxxx={
263:        "xxxxxxxx": {
264:            "xxxxxx": False,
265:            "xxxxxxx": False,
266:            "xxxx_xxxxxx": "xxxxx",
267:        },
268:        "xxxxxxxx-xxxxx": {
269:            "xxxxxx": False,
270:            "xxxxxxx": True,
271:            "xxxx_xxxxxx": "xxxxxx",
272:        },
273:    },
274:    # fmt: on
275:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5,
276:)
277:# fmt: off
278:# No formatting to the end of the file
279:l=[1,2,3]
280:d={'a':1,
281:   'b':2}

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The new fmt on/off handling no longer raises exceptions. generate_comments no longer raises FormatOff/On, normalize_fmt_off() is called up front and convert_one_fmt_off_pair()/generate_ignored_nodes() convert an unmatched “# fmt: off” into a STANDALONE_COMMENT containing all following nodes until the end of the block or ENDMARKER (see black.py:2555-2613). container_of() was updated to stop at file_input (black.py:1852-1856), so generate_ignored_nodes walks siblings only. No SyntaxError is raised anywhere; unmatched off is handled gracefully to block end, satisfying the todo and matching test_fmtonoff2.


Todo item 19 of 22 is correct
description: 'Check that unmatched `# fmt: off` (no corresponding `# fmt: on`) is handled gracefully: by reading until block end without raising errors (no lingering raises of `SyntaxError` from prior implementation).'
Validating todo item 20 of 22
description: 'Verify `DebugVisitor.show()` signature accepts `Union[str, Leaf, Node]` and properly parses only when input is `str`, without breaking any call sites that used the previous signature.'
Calling tool: grepTool
DebugVisitor\.show\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:102:.. py:function:: black.DebugVisitor.show(code: str) -> None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:752:            black.DebugVisitor.show(source)

Calling tool: grepTool
class DebugVisitor
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:2:class DebugVisitor(Visitor[T]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:709:class DebugVisitor(Visitor[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):
710:    tree_depth: int = 0
711:
712:    def visit_default(self, node: LN) -> Iterator[T]:
713:        indent = " " * (2 * self.tree_depth)
714:        if isinstance(node, Node):
715:            _type = type_repr(node.type)
716:            out(f"{indent}{_type}", fg="yellow")
717:            self.tree_depth += 1
718:            for child in node.children:
719:                yield from self.visit(child)
720:
721:            self.tree_depth -= 1
722:            out(f"{indent}/{_type}", fg="yellow", bold=False)
723:        else:
724:            _type = token.tok_name.get(node.type, str(node.type))
725:            out(f"{indent}{_type}", fg="blue", nl=False)
726:            if node.prefix:
727:                # We don't have to handle prefixes for `Node` objects since
728:                # that delegates to the first child anyway.
729:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py
1:@dataclass
2:class DebugVisitor(Visitor[T]):
3:    tree_depth: int = 0
4:
5:    def visit_default(self, node: LN) -> Iterator[T]:
6:        indent = ' ' * (2 * self.tree_depth)
7:        if isinstance(node, Node):
8:            _type = type_repr(node.type)
9:            out(f'{indent}{_type}', fg='yellow')
10:            self.tree_depth += 1
11:            for child in node.children:
12:                yield from self.visit(child)
13:
14:            self.tree_depth -= 1
15:            out(f'{indent}/{_type}', fg='yellow', bold=False)
16:        else:
17:            _type = token.tok_name.get(node.type, str(node.type))
18:            out(f'{indent}{_type}', fg='blue', nl=False)
19:            if node.prefix:
20:                # We don't have to handle prefixes for `Node` objects since
21:                # that delegates to the first child anyway.
22:                out(f' {node.prefix!r}', fg='green', bold=False, nl=False)
23:            out(f' {node.value!r}', fg='blue', bold=False)
24:
25:    @classmethod
26:    def show(cls, code: str) -> None:
27:        """Pretty-prints a given string of `code`.
28:
29:        Convenience method for debugging.
30:        """
31:        v: DebugVisitor[None] = DebugVisitor()
32:        list(v.visit(lib2to3_parse(code)))

Calling tool: grepTool
\.show\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:102:.. py:function:: black.DebugVisitor.show(code: str) -> None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:752:            black.DebugVisitor.show(source)

Calling tool: grepTool
class Leaf|class Node|from .* import Leaf, Node|Leaf\]|Node\]|Visitor\[
Matched content:
67:LN = Union[Leaf, Node]
709:class DebugVisitor(Visitor[T]):
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
738:        v: DebugVisitor[None] = DebugVisitor()
874:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
876:    previous: Optional[Leaf] = None
987:    def get_open_lsqb(self) -> Optional[Leaf]:
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1394:class LineGenerator(Visitor[Line]):
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2176:    tail_leaves: List[Leaf] = []
2177:    body_leaves: List[Leaf] = []
2178:    head_leaves: List[Leaf] = []
3272:        Callable[[Sequence[Leaf]], Iterator[Tuple[Index, Leaf]]],
3280:        comment: Optional[Leaf]

Calling tool: grepTool
from .* import Leaf, Node
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
pytree import
Matched content:
43:from blib2to3.pytree import Node, Leaf, type_repr

Calling tool: grepTool
class Visitor
Matched content:
682:class Visitor(Generic[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")
680:
681:
682:class Visitor(Generic[T]):
683:    """Basic lib2to3 visitor that yields things of type `T` on `visit()`."""
684:
685:    def visit(self, node: LN) -> Iterator[T]:
686:        """Main method to visit `node` and its children.
687:
688:        It tries to find a `visit_*()` method for the given `node.type`, like
689:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
730:        node = black.lib2to3_parse("# comment\nfrom __future__ import black\n")
731:        self.assertEqual({"black"}, black.get_future_imports(node))
732:        node = black.lib2to3_parse('"""docstring"""\nfrom __future__ import black\n')
733:        self.assertEqual({"black"}, black.get_future_imports(node))
734:        node = black.lib2to3_parse("some(other, code)\nfrom __future__ import black\n")
735:        self.assertEqual(set(), black.get_future_imports(node))
736:        node = black.lib2to3_parse("from some.module import black\n")
737:        self.assertEqual(set(), black.get_future_imports(node))
738:
739:    def test_debug_visitor(self) -> None:
740:        source, _ = read_data("debug_visitor.py")
741:        expected, _ = read_data("debug_visitor.out")
742:        out_lines = []
743:        err_lines = []
744:
745:        def out(msg: str, **kwargs: Any) -> None:
746:            out_lines.append(msg)
747:
748:        def err(msg: str, **kwargs: Any) -> None:
749:            err_lines.append(msg)
750:
751:        with patch("black.out", out), patch("black.err", err):
752:            black.DebugVisitor.show(source)
753:        actual = "\n".join(out_lines) + "\n"
754:        log_name = ""
755:        if expected != actual:
756:            log_name = black.dump_to_file(*out_lines)
757:        self.assertEqual(
758:            expected,
759:            actual,
760:            f"AST print out is different. Actual version dumped to {log_name}",
761:        )
762:
763:    def test_format_file_contents(self) -> None:
764:        empty = ""
765:        with self.assertRaises(black.NothingChanged):
766:            black.format_file_contents(empty, line_length=ll, fast=False)
767:        just_nl = "\n"
768:        with self.assertRaises(black.NothingChanged):
769:            black.format_file_contents(just_nl, line_length=ll, fast=False)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":

Calling tool: grepTool
def lib2to3_parse
Matched content:
646:def lib2to3_parse(src_txt: str) -> Node:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: DebugVisitor.show now accepts Union[str, Leaf, Node] and only calls lib2to3_parse when the input is a str. Existing call sites (tests call with a string) remain valid, so no breakage occurs.


Todo item 20 of 22 is correct
description: 'Verify `DebugVisitor.show()` signature accepts `Union[str, Leaf, Node]` and properly parses only when input is `str`, without breaking any call sites that used the previous signature.'
Validating todo item 21 of 22
description: 'Check typing imports: `Type` was removed from imports; ensure there are no remaining type hints or usages requiring `Type`.'
Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
typing\.Type
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
Type\[
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":
121:        mode = cls.AUTO_DETECT
122:        if py36:
123:            mode |= cls.PYTHON36
124:        if pyi:
125:            mode |= cls.PYI
126:        if skip_string_normalization:
127:            mode |= cls.NO_STRING_NORMALIZATION
128:        return mode
129:
130:

Calling tool: grepTool
line\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
from\s+typing\s+import\s+.*\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified that `Type` was removed from typing imports and there are no remaining uses. Grep found no occurrences of `Type` or `typing.Type`, and the only previous usage in `LineGenerator.line` was refactored to remove the `type: Type[Line]` parameter.


Todo item 21 of 22 is correct
description: 'Check typing imports: `Type` was removed from imports; ensure there are no remaining type hints or usages requiring `Type`.'
Validating todo item 22 of 22
description: 'Review test `test_fmtonoff2` to ensure it exercises a top-level `# fmt: off` region spanning multiple statements/functions and asserts that: (a) no extra blank lines are inserted between functions, and (b) code inside the off/on block (e.g., list of tuples) is not reformatted.'
Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(
480:                unstyle(str(report)),
481:                "2 files reformatted, 2 files left unchanged, "
482:                "1 file failed to reformat.",
483:            )
484:            self.assertEqual(report.return_code, 123)
485:            report.failed(Path("e2"), "boom")
486:            self.assertEqual(len(out_lines), 4)
487:            self.assertEqual(len(err_lines), 2)
488:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
489:            self.assertEqual(
490:                unstyle(str(report)),
491:                "2 files reformatted, 2 files left unchanged, "
492:                "2 files failed to reformat.",
493:            )
494:            self.assertEqual(report.return_code, 123)
495:            report.path_ignored(Path("wat"), "no match")
496:            self.assertEqual(len(out_lines), 5)
497:            self.assertEqual(len(err_lines), 2)
498:            self.assertEqual(out_lines[-1], "wat ignored: no match")
499:            self.assertEqual(

Calling tool: globTool
**/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: globTool
**/tests/data/fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:
2700:    lpar, expr, rpar = node.children
2701:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2702:        return is_yield(expr)
2703:
2704:    return False
2705:
2706:
2707:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2708:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2709:
2710:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2711:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2712:    extended iterable unpacking (PEP 3132) and additional unpacking
2713:    generalizations (PEP 448).
2714:    """
2715:    if leaf.type not in STARS or not leaf.parent:
2716:        return False
2717:
2718:    p = leaf.parent
2719:    if p.type == syms.star_expr:
2720:        # Star expressions are also used as assignment targets in extended
2721:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2722:        if not p.parent:
2723:            return False
2724:
2725:        p = p.parent
2726:
2727:    return p.type in within
2728:
2729:
2730:def is_multiline_string(leaf: Leaf) -> bool:
2731:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2732:    value = leaf.value.lstrip("furbFURB")
2733:    return value[:3] in {'"""', "'''"} and "\n" in value
2734:
2735:
2736:def is_stub_suite(node: Node) -> bool:
2737:    """Return True if `node` is a suite with a stub body."""
2738:    if (
2739:        len(node.children) != 4
2740:        or node.children[0].type != token.NEWLINE
2741:        or node.children[1].type != token.INDENT
2742:        or node.children[3].type != token.DEDENT
2743:    ):
2744:        return False
2745:
2746:    return is_stub_body(node.children[2])
2747:
2748:
2749:def is_stub_body(node: LN) -> bool:
2750:    """Return True if `node` is a simple statement containing an ellipsis."""
2751:    if not isinstance(node, Node) or node.type != syms.simple_stmt:
2752:        return False
2753:
2754:    if len(node.children) != 2:
2755:        return False
2756:
2757:    child = node.children[0]
2758:    return (
2759:        child.type == syms.atom

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test `test_fmtonoff2` loads `tests/data/fmtonoff2.py` which contains a top-level `# fmt: off` block spanning multiple functions and a list of tuples. Since there is no `# output` marker, the test asserts the formatted output equals the input, ensuring no extra blank lines are inserted and content inside the off/on block is not reformatted.


Todo item 22 of 22 is correct
description: 'Review test `test_fmtonoff2` to ensure it exercises a top-level `# fmt: off` region spanning multiple statements/functions and asserts that: (a) no extra blank lines are inserted between functions, and (b) code inside the off/on block (e.g., list of tuples) is not reformatted.'
Validating todo item 1 of 22
description: 'Search for any remaining references to removed classes `FormatError`, `FormatOn`, `FormatOff`, and ensure they are fully deleted and not imported or referenced anywhere in `black.py`.'

Calling tool: grepTool
Format(Error|On|Off)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
Format(Error|On|Off)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
FormatError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError

Calling tool: grepTool
class\s+Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
(?i)format(on|off|error)|Format(On|Off|Error)|FMT_ON|FMT_OFF
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
Format(On|Off|Error)|except\s+Format
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched the codebase with grep for FormatError/FormatOn/FormatOff and found no occurrences in black.py. The only remaining references are in docs. The diff removed the classes and their usages; no imports or references remain in black.py.

Todo item 1 of 22 is correct
description: 'Search for any remaining references to removed classes `FormatError`, `FormatOn`, `FormatOff`, and ensure they are fully deleted and not imported or referenced anywhere in `black.py`.'

Validating todo item 2 of 22
description: 'Verify that `UnformattedLines` class and all its usages are removed: no instantiation, no type checks, no branching on `isinstance(..., UnformattedLines)`.'

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
class UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
isinstance\([^\)]*UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
visit_unformatted|type=UnformattedLines|UnformattedLines|visit_STANDALONE_COMMENT|FMT_OFF|generate_ignored_nodes|normalize_fmt_off|convert_one_fmt_off_pair|container_of|generate_comments|split_line|EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:608:    elt = EmptyLineTracker(is_pyi=is_pyi)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1426:            for comment in generate_comments(node):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2618:    container: Optional[LN] = container_of(leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:84:.. autofunction:: black.split_line
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:114:.. autofunction:: black.generate_comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:14::class:`EmptyLineTracker`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:17:.. autoclass:: black.EmptyLineTracker
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/comments5.py:61:# Note: crappy but inevitable.  The current design of EmptyLineTracker doesn't

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]

Calling tool: grepTool
visit_unformatted
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
line\(type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched the codebase for UnformattedLines and found no class or usages in black.py. Verified removals: no class definition, no instantiation, no isinstance/type checks, and line() no longer accepts a type argument. Only references left are in docs, not code.

Todo item 2 of 22 is correct
description: 'Verify that `UnformattedLines` class and all its usages are removed: no instantiation, no type checks, no branching on `isinstance(..., UnformattedLines)`.'

Validating todo item 3 of 22
description: 'Confirm `LineGenerator.line()` signature no longer accepts a `type` parameter and all call sites are updated accordingly (no callers passing `type=...`).'

Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:

Calling tool: grepTool
\.line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1433:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1437:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1440:                    yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1453:        yield from self.line(+1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1461:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1468:        yield from self.line(-1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1487:                yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1505:                yield from self.line(+1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1507:                yield from self.line(-1)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1511:                yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1516:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1532:            yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1537:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1542:        yield from self.line()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1546:            yield from self.line()

Calling tool: grepTool
(?i)UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
line\([^)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
\.line\(type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1406:    def line(self, indent: int = 0) -> Iterator[Line]:

Calling tool: grepTool
\.line\([^\)]*,
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `LineGenerator.line()` now has signature `def line(self, indent: int = 0)` and internally always constructs `Line`. Grep across the repo shows no `.line(` calls with `type=` or a second positional argument; all call sites pass only the indent (or none).

Todo item 3 of 22 is correct
description: 'Confirm `LineGenerator.line()` signature no longer accepts a `type` parameter and all call sites are updated accordingly (no callers passing `type=...`).'

Validating todo item 4 of 22
description: 'Check `EmptyLineTracker.extra_empty_lines()` (and related methods) no longer special-case `UnformattedLines` and that removed logic doesn't leave unreachable branches.'

Calling tool: grepTool
class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
extra_empty_lines\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
EmptyLineTracker\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:608:    elt = EmptyLineTracker(is_pyi=is_pyi)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: grepTool
visit_unformatted\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
EmptyLineTracker[\s\S]*isinstance\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: UnformattedLines is removed from black.py, and EmptyLineTracker.maybe_empty_lines (and helpers) no longer check for it. The early return special-case was deleted, and there are no remaining references to UnformattedLines or unreachable branches in these methods.

Todo item 4 of 22 is correct
description: 'Check `EmptyLineTracker.extra_empty_lines()` (and related methods) no longer special-case `UnformattedLines` and that removed logic doesn't leave unreachable branches.'

Validating todo item 5 of 22
description: 'Ensure `split_line()` only short-circuits on `line.is_comment` and that there are no remaining checks for `UnformattedLines`.'

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with

Calling tool: grepTool
isinstance\(.*UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Checked split_line in black.py: it now only short-circuits on `line.is_comment` (no `UnformattedLines` check). Grep confirms no remaining references or isinstance checks for `UnformattedLines` in code (only in docs).

Todo item 5 of 22 is correct
description: 'Ensure `split_line()` only short-circuits on `line.is_comment` and that there are no remaining checks for `UnformattedLines`.'

Validating todo item 6 of 22
description: 'Confirm `generate_comments()` no longer raises any `FormatOn`/`FormatOff` exceptions and that all try/except handling for these exceptions has been removed from visitors.'

Calling tool: grepTool
class Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
generate_comments\(|FormatOn|FormatOff|visit_unformatted|UnformattedLines|try\:.*Format(On|Off)|except\s+Format(On|Off)
Matched content:
1426:            for comment in generate_comments(node):
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,

Calling tool: grepTool
except\s+Format(On|Off)|try\:.*Format(On|Off)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_unformatted|UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py that generate_comments (lines ~1971-1992) only yields comment Leaves and does not raise exceptions. Searched the codebase and found no FormatOn/FormatOff classes or try/except blocks handling them; LineGenerator.visit_default (lines ~1422-1448) processes comments without try/except, and UnformattedLines/visit_unformatted were removed.

Todo item 6 of 22 is correct
description: 'Confirm `generate_comments()` no longer raises any `FormatOn`/`FormatOff` exceptions and that all try/except handling for these exceptions has been removed from visitors.'

Validating todo item 7 of 22
description: 'Validate `LineGenerator.visit_default()` no longer contains exception handling for `FormatOff`/`FormatOn` and that comment handling only relies on `generate_comments()` results.'

Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: grepTool
def visit_default\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:701:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:712:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1422:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py LineGenerator.visit_default() (lines 1422-1448) there is no try/except for FormatOff/FormatOn. It iterates only over comments from generate_comments(node) and handles them accordingly. Also generate_comments no longer raises FormatOn/Off (lines 1971-1992), confirming reliance solely on its yielded comments.

Todo item 7 of 22 is correct
description: 'Validate `LineGenerator.visit_default()` no longer contains exception handling for `FormatOff`/`FormatOn` and that comment handling only relies on `generate_comments()` results.'

Validating todo item 8 of 22
description: 'Verify the new `LineGenerator.visit_STANDALONE_COMMENT()` method exists and is registered by the visitor (method name matches token alias), calling `line()` only before the comment when no open brackets, then delegating to `visit_default()`.'

Calling tool: grepTool
class LineGenerator\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:
2700:    lpar, expr, rpar = node.children
2701:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2702:        return is_yield(expr)
2703:
2704:    return False
2705:
2706:
2707:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2708:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2709:
2710:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2711:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2712:    extended iterable unpacking (PEP 3132) and additional unpacking
2713:    generalizations (PEP 448).
2714:    """
2715:    if leaf.type not in STARS or not leaf.parent:
2716:        return False
2717:
2718:    p = leaf.parent
2719:    if p.type == syms.star_expr:
2720:        # Star expressions are also used as assignment targets in extended
2721:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2722:        if not p.parent:
2723:            return False
2724:
2725:        p = p.parent
2726:
2727:    return p.type in within
2728:
2729:
2730:def is_multiline_string(leaf: Leaf) -> bool:
2731:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2732:    value = leaf.value.lstrip("furbFURB")
2733:    return value[:3] in {'"""', "'''"} and "\n" in value
2734:
2735:
2736:def is_stub_suite(node: Node) -> bool:
2737:    """Return True if `node` is a suite with a stub body."""
2738:    if (
2739:        len(node.children) != 4
2740:        or node.children[0].type != token.NEWLINE
2741:        or node.children[1].type != token.INDENT
2742:        or node.children[3].type != token.DEDENT
2743:    ):
2744:        return False
2745:
2746:    return is_stub_body(node.children[2])
2747:
2748:
2749:def is_stub_body(node: LN) -> bool:
2750:    """Return True if `node` is a simple statement containing an ellipsis."""
2751:    if not isinstance(node, Node) or node.type != syms.simple_stmt:
2752:        return False
2753:
2754:    if len(node.children) != 2:
2755:        return False
2756:
2757:    child = node.children[0]
2758:    return (
2759:        child.type == syms.atom
2760:        and len(child.children) == 3
2761:        and all(leaf == Leaf(token.DOT, ".") for leaf in child.children)
2762:    )
2763:
2764:
2765:def max_delimiter_priority_in_atom(node: LN) -> int:
2766:    """Return maximum delimiter priority inside `node`.
2767:
2768:    This is specific to atoms with contents contained in a pair of parentheses.
2769:    If `node` isn't an atom or there are no enclosing parentheses, returns 0.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Found LineGenerator.visit_STANDALONE_COMMENT in black.py which checks for open brackets and calls line() only when none are open, then delegates to visit_default(). The method name matches the STANDALONE_COMMENT token alias ensuring visitor dispatch.

Todo item 8 of 22 is correct
description: 'Verify the new `LineGenerator.visit_STANDALONE_COMMENT()` method exists and is registered by the visitor (method name matches token alias), calling `line()` only before the comment when no open brackets, then delegating to `visit_default()`.'

Validating todo item 9 of 22
description: 'Confirm that `visit_default()` will not produce extra blank lines around a `STANDALONE_COMMENT` leaf: since it iterates over comments in the leaf's prefix only, ensure it won't re-insert additional `line()` calls for the `STANDALONE_COMMENT` value itself.'

Calling tool: grepTool
visit_STANDALONE_COMMENT\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
visit_STANDALONE_COMMENT\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: grepTool
def visit_default\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:701:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:712:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1422:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: grepTool
def visit_NEWLINE\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `visit_default()` iterates only over `generate_comments(node)` which yields comments from `leaf.prefix` only, not the leaf’s own value. For a `STANDALONE_COMMENT` leaf, `visit_STANDALONE_COMMENT` yields a line before, then delegates to `visit_default()`. Since `generate_comments` won’t return the `STANDALONE_COMMENT` value, `visit_default()` won’t call `line()` again around it, avoiding extra blank lines.

Todo item 9 of 22 is correct
description: 'Confirm that `visit_default()` will not produce extra blank lines around a `STANDALONE_COMMENT` leaf: since it iterates over comments in the leaf's prefix only, ensure it won't re-insert additional `line()` calls for the `STANDALONE_COMMENT` value itself.'

Validating todo item 10 of 22
description: 'Verify `normalize_fmt_off()` now repeatedly applies `convert_one_fmt_off_pair()` until no more conversions occur (looping with a boolean return), covering the entire file.'

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
normalize_fmt_off\(|convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)

Calling tool: grepTool
hide_fmt_off\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_fmt_off(node) now uses a while loop with a try_again flag that repeatedly calls convert_one_fmt_off_pair(node) until it returns False (lines 2555–2560). convert_one_fmt_off_pair returns True upon converting a pair and False otherwise (lines 2562–2611). normalize_fmt_off is invoked on the root src_node, covering the entire file (line 602).

Todo item 10 of 22 is correct
description: 'Verify `normalize_fmt_off()` now repeatedly applies `convert_one_fmt_off_pair()` until no more conversions occur (looping with a boolean return), covering the entire file.'

Validating todo item 11 of 22
description: 'Inspect `convert_one_fmt_off_pair()` to ensure it only triggers on standalone or disguised standalone `# fmt: off` comments (checks `comment.type == STANDALONE_COMMENT` or preceding leaf is missing/whitespace) and skips inline `# fmt: off`.'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1796:                return NO
1797:
1798:        elif t == token.NAME:
1799:            if v == "import":
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent

Calling tool: grepTool
WHITESPACE\s*=\s*\{
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py convert_one_fmt_off_pair(), the code explicitly checks for STANDALONE_COMMENT or a disguised standalone via preceding_leaf being missing/WHITESPACE before acting; otherwise it continues, thereby skipping inline `# fmt: off`. Verified at lines 2570–2577.

Todo item 11 of 22 is correct
description: 'Inspect `convert_one_fmt_off_pair()` to ensure it only triggers on standalone or disguised standalone `# fmt: off` comments (checks `comment.type == STANDALONE_COMMENT` or preceding leaf is missing/whitespace) and skips inline `# fmt: off`.'

Validating todo item 12 of 22
description: 'Confirm that `convert_one_fmt_off_pair()` collects ignored nodes using `generate_ignored_nodes(leaf)`, removes them from the tree, and inserts a single `STANDALONE_COMMENT` leaf at the correct index (`first_idx`) in the parent.'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""

Calling tool: grepTool
def remove\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/**/black.py: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/**/black.py: No such file or directory (os error 2)


Calling tool: grepTool
def remove\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.py:141:    def remove(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.pyi:34:    def remove(self) -> Optional[int]: ...

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pytree.py
1:# Copyright 2006 Google, Inc. All Rights Reserved.
2:# Licensed to PSF under a Contributor Agreement.
3:
4:"""
5:Python parse tree definitions.
6:
7:This is a very concrete parse tree; we need to keep every token and
8:even the comments and whitespace between tokens.
9:
10:There's also a pattern matching implementation here.
11:"""
12:
13:__author__ = "Guido van Rossum <guido@python.org>"
14:
15:import sys
16:from io import StringIO
17:
18:HUGE = 0x7FFFFFFF  # maximum repeat count, default max
19:
20:_type_reprs = {}
21:def type_repr(type_num):
22:    global _type_reprs
23:    if not _type_reprs:
24:        from .pygram import python_symbols
25:        # printing tokens is possible but not as useful
26:        # from .pgen2 import token // token.__dict__.items():
27:        for name, val in python_symbols.__dict__.items():
28:            if type(val) == int: _type_reprs[val] = name
29:    return _type_reprs.setdefault(type_num, type_num)
30:
31:class Base(object):
32:
33:    """
34:    Abstract base class for Node and Leaf.
35:
36:    This provides some default functionality and boilerplate using the
37:    template pattern.
38:
39:    A node may be a subnode of at most one parent.
40:    """
41:
42:    # Default values for instance variables
43:    type = None    # int: token number (< 256) or symbol number (>= 256)
44:    parent = None  # Parent node pointer, or None
45:    children = ()  # Tuple of subnodes
46:    was_changed = False
47:    was_checked = False
48:
49:    def __new__(cls, *args, **kwds):
50:        """Constructor that prevents Base from being instantiated."""
51:        assert cls is not Base, "Cannot instantiate Base"
52:        return object.__new__(cls)
53:
54:    def __eq__(self, other):
55:        """
56:        Compare two nodes for equality.
57:
58:        This calls the method _eq().
59:        """
60:        if self.__class__ is not other.__class__:
61:            return NotImplemented
62:        return self._eq(other)
63:
64:    __hash__ = None # For Py3 compatibility.
65:
66:    def _eq(self, other):
67:        """
68:        Compare two nodes for equality.
69:
70:        This is called by __eq__ and __ne__.  It is only called if the two nodes
71:        have the same type.  This must be implemented by the concrete subclass.
72:        Nodes should be considered equal if they have the same structure,
73:        ignoring the prefix string and other context information.
74:        """
75:        raise NotImplementedError
76:
77:    def clone(self):
78:        """
79:        Return a cloned (deep) copy of self.
80:
81:        This must be implemented by the concrete subclass.
82:        """
83:        raise NotImplementedError
84:
85:    def post_order(self):
86:        """
87:        Return a post-order iterator for the tree.
88:
89:        This must be implemented by the concrete subclass.
90:        """
91:        raise NotImplementedError
92:
93:    def pre_order(self):
94:        """
95:        Return a pre-order iterator for the tree.
96:
97:        This must be implemented by the concrete subclass.
98:        """
99:        raise NotImplementedError
100:
101:    def replace(self, new):
102:        """Replace this node with a new one in the parent."""
103:        assert self.parent is not None, str(self)
104:        assert new is not None
105:        if not isinstance(new, list):
106:            new = [new]
107:        l_children = []
108:        found = False
109:        for ch in self.parent.children:
110:            if ch is self:
111:                assert not found, (self.parent.children, self, new)
112:                if new is not None:
113:                    l_children.extend(new)
114:                found = True
115:            else:
116:                l_children.append(ch)
117:        assert found, (self.children, self, new)
118:        self.parent.children = l_children
119:        self.parent.changed()
120:        self.parent.invalidate_sibling_maps()
121:        for x in new:
122:            x.parent = self.parent
123:        self.parent = None
124:
125:    def get_lineno(self):
126:        """Return the line number which generated the invocant node."""
127:        node = self
128:        while not isinstance(node, Leaf):
129:            if not node.children:
130:                return
131:            node = node.children[0]
132:        return node.lineno
133:
134:    def changed(self):
135:        if self.was_changed:
136:            return
137:        if self.parent:
138:            self.parent.changed()
139:        self.was_changed = True
140:
141:    def remove(self):
142:        """
143:        Remove the node from the tree. Returns the position of the node in its
144:        parent's children before it was removed.
145:        """
146:        if self.parent:
147:            for i, node in enumerate(self.parent.children):
148:                if node is self:
149:                    del self.parent.children[i]
150:                    self.parent.changed()
151:                    self.parent.invalidate_sibling_maps()
152:                    self.parent = None
153:                    return i
154:
155:    @property
156:    def next_sibling(self):
157:        """
158:        The node immediately following the invocant in their parent's children
159:        list. If the invocant does not have a next sibling, it is None
160:        """
161:        if self.parent is None:
162:            return None
163:
164:        if self.parent.next_sibling_map is None:
165:            self.parent.update_sibling_maps()
166:        return self.parent.next_sibling_map[id(self)]
167:
168:    @property
169:    def prev_sibling(self):
170:        """
171:        The node immediately preceding the invocant in their parent's children
172:        list. If the invocant does not have a previous sibling, it is None.
173:        """
174:        if self.parent is None:
175:            return None
176:
177:        if self.parent.prev_sibling_map is None:
178:            self.parent.update_sibling_maps()
179:        return self.parent.prev_sibling_map[id(self)]
180:
181:    def leaves(self):
182:        for child in self.children:
183:            yield from child.leaves()
184:
185:    def depth(self):
186:        if self.parent is None:
187:            return 0
188:        return 1 + self.parent.depth()
189:
190:    def get_suffix(self):
191:        """
192:        Return the string immediately following the invocant node. This is
193:        effectively equivalent to node.next_sibling.prefix
194:        """
195:        next_sib = self.next_sibling
196:        if next_sib is None:
197:            return ""
198:        return next_sib.prefix
199:
200:    if sys.version_info < (3, 0):
201:        def __str__(self):
202:            return str(self).encode("ascii")
203:
204:class Node(Base):
205:
206:    """Concrete implementation for interior nodes."""
207:
208:    def __init__(self,type, children,
209:                 context=None,
210:                 prefix=None,
211:                 fixers_applied=None):
212:        """
213:        Initializer.
214:
215:        Takes a type constant (a symbol number >= 256), a sequence of
216:        child nodes, and an optional context keyword argument.
217:
218:        As a side effect, the parent pointers of the children are updated.
219:        """
220:        assert type >= 256, type

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), it collects ignored_nodes via generate_ignored_nodes(leaf), removes each ignored node (capturing the index of the first removal as first_idx), and inserts a single STANDALONE_COMMENT Leaf at parent.insert_child(first_idx, ...). Verified on lines 2579–2605 of black.py.

Todo item 12 of 22 is correct
description: 'Confirm that `convert_one_fmt_off_pair()` collects ignored nodes using `generate_ignored_nodes(leaf)`, removes them from the tree, and inserts a single `STANDALONE_COMMENT` leaf at the correct index (`first_idx`) in the parent.'

Validating todo item 13 of 22
description: 'Check that when building the new comment value, trailing newline from ignored nodes is trimmed (using `hidden_value.endswith("\n")`) to avoid introducing extra blank lines.'

Calling tool: grepTool
convert_one_fmt_off_pair\(|hidden_value\.endswith\(|normalize_fmt_off\(|hide_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2587:                if hidden_value.endswith("\n"):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s convert_one_fmt_off_pair(), the new comment value hidden_value is built and then checked with hidden_value.endswith("\n"); if true, the trailing newline is trimmed (hidden_value = hidden_value[:-1]). This prevents extra blank lines, satisfying the requirement.

Todo item 13 of 22 is correct
description: 'Check that when building the new comment value, trailing newline from ignored nodes is trimmed (using `hidden_value.endswith("\n")`) to avoid introducing extra blank lines.'

Validating todo item 14 of 22
description: 'Ensure any necessary prefix handling is correct when replacing nodes with a `STANDALONE_COMMENT` leaf so that indentation/newlines before the block are preserved (verify use of prefixes and indices around insertion).'

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:

Calling tool: globTool
**/*test*
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black: No such file or directory (os error 2)


Calling tool: globTool
**/*test*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py

Calling tool: grepTool
test_fmtonoff2
Matched content:
404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(
480:                unstyle(str(report)),
481:                "2 files reformatted, 2 files left unchanged, "
482:                "1 file failed to reformat.",
483:            )
484:            self.assertEqual(report.return_code, 123)
485:            report.failed(Path("e2"), "boom")
486:            self.assertEqual(len(out_lines), 4)
487:            self.assertEqual(len(err_lines), 2)
488:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
489:            self.assertEqual(
490:                unstyle(str(report)),
491:                "2 files reformatted, 2 files left unchanged, "
492:                "2 files failed to reformat.",
493:            )
494:            self.assertEqual(report.return_code, 123)
495:            report.path_ignored(Path("wat"), "no match")
496:            self.assertEqual(len(out_lines), 5)
497:            self.assertEqual(len(err_lines), 2)
498:            self.assertEqual(out_lines[-1], "wat ignored: no match")
499:            self.assertEqual(

Calling tool: globTool
**/tests/data/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
def read_data\(
Matched content:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py
1:#!/usr/bin/env python3
2:import asyncio
3:import sys
4:
5:from third_party import X, Y, Z
6:
7:from library import some_connection, \
8:                    some_decorator
9:# fmt: off
10:from third_party import (X,
11:                         Y, Z)
12:# fmt: on
13:f'trigger 3.6 mode'
14:# fmt: off
15:def func_no_args():
16:  a; b; c
17:  if True: raise RuntimeError
18:  if False: ...
19:  for i in range(10):
20:    print(i)
21:    continue
22:  exec('new-style exec', {}, {})
23:  return None
24:async def coroutine(arg, exec=False):
25: 'Single-line docstring. Multiline is harder to reformat.'
26: async with some_connection() as conn:
27:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
28: await asyncio.sleep(1)
29:@asyncio.coroutine
30:@some_decorator(
31:with_args=True,
32:many_args=[1,2,3]
33:)
34:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
35: return text[number:-1]
36:# fmt: on
37:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r''):
38: offset = attr.ib(default=attr.Factory( lambda: _r.uniform(10000, 200000)))
39: assert task._cancel_stack[:len(old_stack)] == old_stack
40:def spaces_types(a: int = 1, b: tuple = (), c: list = [], d: dict = {}, e: bool = True, f: int = -1, g: int = 1 if False else 2, h: str = "", i: str = r''): ...
41:def spaces2(result= _core.Value(None)):
42: ...
43:something = {
44:    # fmt: off
45:    key: 'value',
46:}
47:def example(session):
48:    # fmt: off
49:    result = session\
50:        .query(models.Customer.id)\
51:        .filter(models.Customer.account_id == account_id,
52:                models.Customer.email == email_address)\
53:        .order_by(models.Customer.id.asc())\
54:        .all()
55:    # fmt: on
56:def long_lines():
57:    if True:
58:        typedargslist.extend(
59:            gen_annotated_params(ast_args.kwonlyargs, ast_args.kw_defaults, parameters, implicit_default=True)
60:        )
61:        # fmt: off
62:        a = (
63:            unnecessary_bracket()
64:        )
65:        # fmt: on
66:    _type_comment_re = re.compile(
67:        r"""
68:        ^
69:        [\t ]*
70:        \#[ ]type:[ ]*
71:        (?P<type>
72:            [^#\t\n]+?
73:        )
74:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
75:                        # a trailing space which is why we need the silliness below
76:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
77:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
78:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
79:        [\t ]*
80:        (?P<nl>
81:            (?:\#[^\n]*)?
82:            \n?
83:        )
84:        $
85:        """,
86:        # fmt: off
87:        re.MULTILINE|re.VERBOSE
88:        # fmt: on
89:    )
90:def single_literal_yapf_disable():
91:    """Black does not support this."""
92:    BAZ = {
93:        (1, 2, 3, 4),
94:        (5, 6, 7, 8),
95:        (9, 10, 11, 12),
96:    }  # yapf: disable
97:cfg.rule(
98:    "Default", "address",
99:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
100:    xxxxxx="xx_xxxxx", xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
101:    xxxxxxxxx_xxxx=True, xxxxxxxx_xxxxxxxxxx=False,
102:    xxxxxx_xxxxxx=2, xxxxxx_xxxxx_xxxxxxxx=70, xxxxxx_xxxxxx_xxxxx=True,
103:    # fmt: off
104:    xxxxxxx_xxxxxxxxxxxx={
105:        "xxxxxxxx": {
106:            "xxxxxx": False,
107:            "xxxxxxx": False,
108:            "xxxx_xxxxxx": "xxxxx",
109:        },
110:        "xxxxxxxx-xxxxx": {
111:            "xxxxxx": False,
112:            "xxxxxxx": True,
113:            "xxxx_xxxxxx": "xxxxxx",
114:        },
115:    },
116:    # fmt: on
117:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5
118:)
119:# fmt: off
120:# No formatting to the end of the file
121:l=[1,2,3]
122:d={'a':1,
123:   'b':2}
124:
125:# output
126:
127:
128:#!/usr/bin/env python3
129:import asyncio
130:import sys
131:
132:from third_party import X, Y, Z
133:
134:from library import some_connection, some_decorator
135:
136:# fmt: off
137:from third_party import (X,
138:                         Y, Z)
139:# fmt: on
140:f"trigger 3.6 mode"
141:# fmt: off
142:def func_no_args():
143:  a; b; c
144:  if True: raise RuntimeError
145:  if False: ...
146:  for i in range(10):
147:    print(i)
148:    continue
149:  exec('new-style exec', {}, {})
150:  return None
151:async def coroutine(arg, exec=False):
152: 'Single-line docstring. Multiline is harder to reformat.'
153: async with some_connection() as conn:
154:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
155: await asyncio.sleep(1)
156:@asyncio.coroutine
157:@some_decorator(
158:with_args=True,
159:many_args=[1,2,3]
160:)
161:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
162: return text[number:-1]
163:# fmt: on
164:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r""):
165:    offset = attr.ib(default=attr.Factory(lambda: _r.uniform(10000, 200000)))
166:    assert task._cancel_stack[: len(old_stack)] == old_stack
167:
168:
169:def spaces_types(
170:    a: int = 1,
171:    b: tuple = (),
172:    c: list = [],
173:    d: dict = {},
174:    e: bool = True,
175:    f: int = -1,
176:    g: int = 1 if False else 2,
177:    h: str = "",
178:    i: str = r"",
179:):
180:    ...
181:
182:
183:def spaces2(result=_core.Value(None)):
184:    ...
185:
186:
187:something = {
188:    # fmt: off
189:    key: 'value',
190:}
191:
192:
193:def example(session):
194:    # fmt: off
195:    result = session\
196:        .query(models.Customer.id)\
197:        .filter(models.Customer.account_id == account_id,
198:                models.Customer.email == email_address)\
199:        .order_by(models.Customer.id.asc())\
200:        .all()
201:    # fmt: on
202:
203:
204:def long_lines():
205:    if True:
206:        typedargslist.extend(
207:            gen_annotated_params(
208:                ast_args.kwonlyargs,
209:                ast_args.kw_defaults,
210:                parameters,
211:                implicit_default=True,
212:            )
213:        )
214:        # fmt: off
215:        a = (
216:            unnecessary_bracket()
217:        )
218:        # fmt: on
219:    _type_comment_re = re.compile(
220:        r"""
221:        ^
222:        [\t ]*
223:        \#[ ]type:[ ]*
224:        (?P<type>
225:            [^#\t\n]+?
226:        )
227:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
228:                        # a trailing space which is why we need the silliness below
229:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
230:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
231:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
232:        [\t ]*
233:        (?P<nl>
234:            (?:\#[^\n]*)?
235:            \n?
236:        )
237:        $
238:        """,
239:        # fmt: off
240:        re.MULTILINE|re.VERBOSE
241:        # fmt: on
242:    )
243:
244:
245:def single_literal_yapf_disable():
246:    """Black does not support this."""
247:    BAZ = {(1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12)}  # yapf: disable
248:
249:
250:cfg.rule(
251:    "Default",
252:    "address",
253:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
254:    xxxxxx="xx_xxxxx",
255:    xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
256:    xxxxxxxxx_xxxx=True,
257:    xxxxxxxx_xxxxxxxxxx=False,
258:    xxxxxx_xxxxxx=2,
259:    xxxxxx_xxxxx_xxxxxxxx=70,
260:    xxxxxx_xxxxxx_xxxxx=True,
261:    # fmt: off
262:    xxxxxxx_xxxxxxxxxxxx={
263:        "xxxxxxxx": {
264:            "xxxxxx": False,
265:            "xxxxxxx": False,
266:            "xxxx_xxxxxx": "xxxxx",
267:        },
268:        "xxxxxxxx-xxxxx": {
269:            "xxxxxx": False,
270:            "xxxxxxx": True,
271:            "xxxx_xxxxxx": "xxxxxx",
272:        },
273:    },
274:    # fmt: on
275:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5,
276:)
277:# fmt: off
278:# No formatting to the end of the file
279:l=[1,2,3]
280:d={'a':1,
281:   'b':2}

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), the code trims the original container prefix at the fmt: off location (first.prefix = prefix[comment.consumed:]) and inserts a STANDALONE_COMMENT leaf at the correct index (first_idx) with a prefix that preserves preceding whitespace/newlines (prefix[:previous_consumed] + "\n" * comment.newlines). This ensures indentation/newlines before the block are preserved during replacement.

Todo item 14 of 22 is correct
description: 'Ensure any necessary prefix handling is correct when replacing nodes with a `STANDALONE_COMMENT` leaf so that indentation/newlines before the block are preserved (verify use of prefixes and indices around insertion).'

Validating todo item 15 of 22
description: 'Review `generate_ignored_nodes()` to confirm it stops when encountering `# fmt: on` in the container's prefix and also stops at `token.ENDMARKER` (no unbounded traversal).'

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Reviewed black.py: generate_ignored_nodes() loops while container is not None and not ENDMARKER, and returns immediately upon encountering FMT_ON in the container’s prefix. This satisfies both stopping conditions.

Todo item 15 of 22 is correct
description: 'Review `generate_ignored_nodes()` to confirm it stops when encountering `# fmt: on` in the container's prefix and also stops at `token.ENDMARKER` (no unbounded traversal).'

Validating todo item 16 of 22
description: 'Validate `container_of()` now stops ascending at `syms.file_input`, preventing cross-file or top-level overreach when determining the container, and still respects `SURROUNDED_BY_BRACKETS` boundaries.'

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Validated in black/black.py container_of(): it now breaks when parent.type == syms.file_input (lines ~1852-1854) and still breaks for parent.type in SURROUNDED_BY_BRACKETS (line ~1855). This prevents top-level overreach while respecting bracket boundaries.

Todo item 16 of 22 is correct
description: 'Validate `container_of()` now stops ascending at `syms.file_input`, preventing cross-file or top-level overreach when determining the container, and still respects `SURROUNDED_BY_BRACKETS` boundaries.'

Validating todo item 17 of 22
description: 'Ensure constants and symbols referenced in the new logic are defined/imported: `FMT_ON`, `FMT_OFF`, `STANDALONE_COMMENT`, `WHITESPACE`, `syms`, `SURROUNDED_BY_BRACKETS`.'

Calling tool: grepTool
(?i)^\s*(FMT_ON|FMT_OFF|STANDALONE_COMMENT|WHITESPACE|SURROUNDED_BY_BRACKETS|syms)\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:77:syms = pygram.python_symbols
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:748:    syms.if_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:749:    syms.while_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:750:    syms.for_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:751:    syms.try_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:752:    syms.except_clause,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:753:    syms.with_stmt,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:754:    syms.funcdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:755:    syms.classdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:786:    syms.arglist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:787:    syms.argument,  # double star in arglist
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:788:    syms.trailer,  # single argument to call
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:789:    syms.typedargslist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:790:    syms.varargslist,  # lambdas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:793:    syms.atom,  # single element of a list or set literal
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:794:    syms.dictsetmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:795:    syms.listmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:796:    syms.testlist_gexp,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:797:    syms.testlist_star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:800:    syms.typedargslist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:801:    syms.arglist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:802:    syms.subscriptlist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:803:    syms.vfplist,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:804:    syms.import_as_names,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:805:    syms.yield_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:806:    syms.testlist_gexp,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:807:    syms.testlist_star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:808:    syms.listmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:809:    syms.dictsetmaker,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:812:    syms.test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:813:    syms.lambdef,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:814:    syms.or_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:815:    syms.and_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:816:    syms.not_test,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:817:    syms.comparison,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:818:    syms.star_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:819:    syms.expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:820:    syms.xor_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:821:    syms.and_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:822:    syms.shift_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:823:    syms.arith_expr,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:824:    syms.trailer,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:825:    syms.term,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:826:    syms.power,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1601:        syms.subscript,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1602:        syms.subscriptlist,

Calling tool: grepTool
FMT_ON\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}

Calling tool: grepTool
FMT_OFF\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}

Calling tool: grepTool
pygram\.
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:76:pygram.initialize(CACHE_DIR)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:77:syms = pygram.python_symbols
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:640:    pygram.python_grammar_no_print_statement_no_exec_statement,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:641:    pygram.python_grammar_no_print_statement,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:642:    pygram.python_grammar,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:648:    grammar = pygram.python_grammar_no_print_statement

Calling tool: grepTool
from\s+lib2to3\.(pygram|pgen2|pygram)\s+import|import\s+lib2to3\.pygram
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,
820:    syms.xor_expr,
821:    syms.and_expr,
822:    syms.shift_expr,
823:    syms.arith_expr,
824:    syms.trailer,
825:    syms.term,
826:    syms.power,
827:}
828:ASSIGNMENTS = {
829:    "=",
830:    "+=",
831:    "-=",
832:    "*=",
833:    "@=",
834:    "/=",
835:    "%=",
836:    "&=",
837:    "|=",
838:    "^=",
839:    "<<=",
840:    ">>=",
841:    "**=",
842:    "//=",
843:}
844:COMPREHENSION_PRIORITY = 20
845:COMMA_PRIORITY = 18
846:TERNARY_PRIORITY = 16
847:LOGIC_PRIORITY = 14
848:STRING_PRIORITY = 12
849:COMPARATOR_PRIORITY = 10

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment

Calling tool: grepTool
def\s+list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result

Calling tool: grepTool
def\s+normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified all referenced names exist in black.py: syms defined from blib2to3.pygram; WHITESPACE, STANDALONE_COMMENT, SURROUNDED_BY_BRACKETS constants are defined; FMT_OFF and FMT_ON sets are defined before use. New logic references resolve correctly.

Todo item 17 of 22 is correct
description: 'Ensure constants and symbols referenced in the new logic are defined/imported: `FMT_ON`, `FMT_OFF`, `STANDALONE_COMMENT`, `WHITESPACE`, `syms`, `SURROUNDED_BY_BRACKETS`.'

Validating todo item 18 of 22
description: 'Confirm that converting a `# fmt: off/on` region into a `STANDALONE_COMMENT` results in lines flagged as comments (`line.is_comment == True`) so that later formatting/splitting phases skip them (consistent with `split_line()` behavior).'

Calling tool: grepTool
class Line|def is_comment|is_comment\b|STANDALONE_COMMENT|normalize_fmt_off|convert_one_fmt_off_pair|generate_ignored_nodes|split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2064:    if line.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2559:        try_again = convert_one_fmt_off_pair(node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The fix converts fmt-off/on regions into a single STANDALONE_COMMENT leaf (convert_one_fmt_off_pair inserts Leaf(STANDALONE_COMMENT, ...), lines 2600-2605). Line.is_comment returns True when the line has exactly one STANDALONE_COMMENT leaf (lines 1048-1051). LineGenerator.visit_STANDALONE_COMMENT flushes before appending the comment so it stands alone on its own Line (lines 1544-1547). split_line() now skips such lines by early-return when line.is_comment is True (lines 2064-2066).

Todo item 18 of 22 is correct
description: 'Confirm that converting a `# fmt: off/on` region into a `STANDALONE_COMMENT` results in lines flagged as comments (`line.is_comment == True`) so that later formatting/splitting phases skip them (consistent with `split_line()` behavior).'

Validating todo item 19 of 22
description: 'Check that unmatched `# fmt: off` (no corresponding `# fmt: on`) is handled gracefully: by reading until block end without raising errors (no lingering raises of `SyntaxError` from prior implementation).'

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:

Calling tool: grepTool
SyntaxError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:255:    disagree, a SyntaxError will be raised. If the encoding cookie is an invalid
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:256:    charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:283:            raise SyntaxError("unknown encoding: " + encoding)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/tokenize.py:288:                raise SyntaxError('encoding problem: utf-8')
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/blib2to3/pgen2/pgen.py:334:        raise SyntaxError(msg, (self.filename, self.end[0],

Calling tool: globTool
**/test_fmtonoff2*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: globTool
**/tests/data/fmtonoff2.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
fmt: off
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:9:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:14:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:44:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:48:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:61:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:86:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:103:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:119:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:136:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:141:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:188:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:194:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:214:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:239:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:261:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py:277:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py:6:# fmt: off

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff.py
1:#!/usr/bin/env python3
2:import asyncio
3:import sys
4:
5:from third_party import X, Y, Z
6:
7:from library import some_connection, \
8:                    some_decorator
9:# fmt: off
10:from third_party import (X,
11:                         Y, Z)
12:# fmt: on
13:f'trigger 3.6 mode'
14:# fmt: off
15:def func_no_args():
16:  a; b; c
17:  if True: raise RuntimeError
18:  if False: ...
19:  for i in range(10):
20:    print(i)
21:    continue
22:  exec('new-style exec', {}, {})
23:  return None
24:async def coroutine(arg, exec=False):
25: 'Single-line docstring. Multiline is harder to reformat.'
26: async with some_connection() as conn:
27:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
28: await asyncio.sleep(1)
29:@asyncio.coroutine
30:@some_decorator(
31:with_args=True,
32:many_args=[1,2,3]
33:)
34:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
35: return text[number:-1]
36:# fmt: on
37:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r''):
38: offset = attr.ib(default=attr.Factory( lambda: _r.uniform(10000, 200000)))
39: assert task._cancel_stack[:len(old_stack)] == old_stack
40:def spaces_types(a: int = 1, b: tuple = (), c: list = [], d: dict = {}, e: bool = True, f: int = -1, g: int = 1 if False else 2, h: str = "", i: str = r''): ...
41:def spaces2(result= _core.Value(None)):
42: ...
43:something = {
44:    # fmt: off
45:    key: 'value',
46:}
47:def example(session):
48:    # fmt: off
49:    result = session\
50:        .query(models.Customer.id)\
51:        .filter(models.Customer.account_id == account_id,
52:                models.Customer.email == email_address)\
53:        .order_by(models.Customer.id.asc())\
54:        .all()
55:    # fmt: on
56:def long_lines():
57:    if True:
58:        typedargslist.extend(
59:            gen_annotated_params(ast_args.kwonlyargs, ast_args.kw_defaults, parameters, implicit_default=True)
60:        )
61:        # fmt: off
62:        a = (
63:            unnecessary_bracket()
64:        )
65:        # fmt: on
66:    _type_comment_re = re.compile(
67:        r"""
68:        ^
69:        [\t ]*
70:        \#[ ]type:[ ]*
71:        (?P<type>
72:            [^#\t\n]+?
73:        )
74:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
75:                        # a trailing space which is why we need the silliness below
76:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
77:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
78:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
79:        [\t ]*
80:        (?P<nl>
81:            (?:\#[^\n]*)?
82:            \n?
83:        )
84:        $
85:        """,
86:        # fmt: off
87:        re.MULTILINE|re.VERBOSE
88:        # fmt: on
89:    )
90:def single_literal_yapf_disable():
91:    """Black does not support this."""
92:    BAZ = {
93:        (1, 2, 3, 4),
94:        (5, 6, 7, 8),
95:        (9, 10, 11, 12),
96:    }  # yapf: disable
97:cfg.rule(
98:    "Default", "address",
99:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
100:    xxxxxx="xx_xxxxx", xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
101:    xxxxxxxxx_xxxx=True, xxxxxxxx_xxxxxxxxxx=False,
102:    xxxxxx_xxxxxx=2, xxxxxx_xxxxx_xxxxxxxx=70, xxxxxx_xxxxxx_xxxxx=True,
103:    # fmt: off
104:    xxxxxxx_xxxxxxxxxxxx={
105:        "xxxxxxxx": {
106:            "xxxxxx": False,
107:            "xxxxxxx": False,
108:            "xxxx_xxxxxx": "xxxxx",
109:        },
110:        "xxxxxxxx-xxxxx": {
111:            "xxxxxx": False,
112:            "xxxxxxx": True,
113:            "xxxx_xxxxxx": "xxxxxx",
114:        },
115:    },
116:    # fmt: on
117:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5
118:)
119:# fmt: off
120:# No formatting to the end of the file
121:l=[1,2,3]
122:d={'a':1,
123:   'b':2}
124:
125:# output
126:
127:
128:#!/usr/bin/env python3
129:import asyncio
130:import sys
131:
132:from third_party import X, Y, Z
133:
134:from library import some_connection, some_decorator
135:
136:# fmt: off
137:from third_party import (X,
138:                         Y, Z)
139:# fmt: on
140:f"trigger 3.6 mode"
141:# fmt: off
142:def func_no_args():
143:  a; b; c
144:  if True: raise RuntimeError
145:  if False: ...
146:  for i in range(10):
147:    print(i)
148:    continue
149:  exec('new-style exec', {}, {})
150:  return None
151:async def coroutine(arg, exec=False):
152: 'Single-line docstring. Multiline is harder to reformat.'
153: async with some_connection() as conn:
154:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
155: await asyncio.sleep(1)
156:@asyncio.coroutine
157:@some_decorator(
158:with_args=True,
159:many_args=[1,2,3]
160:)
161:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
162: return text[number:-1]
163:# fmt: on
164:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r""):
165:    offset = attr.ib(default=attr.Factory(lambda: _r.uniform(10000, 200000)))
166:    assert task._cancel_stack[: len(old_stack)] == old_stack
167:
168:
169:def spaces_types(
170:    a: int = 1,
171:    b: tuple = (),
172:    c: list = [],
173:    d: dict = {},
174:    e: bool = True,
175:    f: int = -1,
176:    g: int = 1 if False else 2,
177:    h: str = "",
178:    i: str = r"",
179:):
180:    ...
181:
182:
183:def spaces2(result=_core.Value(None)):
184:    ...
185:
186:
187:something = {
188:    # fmt: off
189:    key: 'value',
190:}
191:
192:
193:def example(session):
194:    # fmt: off
195:    result = session\
196:        .query(models.Customer.id)\
197:        .filter(models.Customer.account_id == account_id,
198:                models.Customer.email == email_address)\
199:        .order_by(models.Customer.id.asc())\
200:        .all()
201:    # fmt: on
202:
203:
204:def long_lines():
205:    if True:
206:        typedargslist.extend(
207:            gen_annotated_params(
208:                ast_args.kwonlyargs,
209:                ast_args.kw_defaults,
210:                parameters,
211:                implicit_default=True,
212:            )
213:        )
214:        # fmt: off
215:        a = (
216:            unnecessary_bracket()
217:        )
218:        # fmt: on
219:    _type_comment_re = re.compile(
220:        r"""
221:        ^
222:        [\t ]*
223:        \#[ ]type:[ ]*
224:        (?P<type>
225:            [^#\t\n]+?
226:        )
227:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
228:                        # a trailing space which is why we need the silliness below
229:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
230:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
231:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
232:        [\t ]*
233:        (?P<nl>
234:            (?:\#[^\n]*)?
235:            \n?
236:        )
237:        $
238:        """,
239:        # fmt: off
240:        re.MULTILINE|re.VERBOSE
241:        # fmt: on
242:    )
243:
244:
245:def single_literal_yapf_disable():
246:    """Black does not support this."""
247:    BAZ = {(1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12)}  # yapf: disable
248:
249:
250:cfg.rule(
251:    "Default",
252:    "address",
253:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
254:    xxxxxx="xx_xxxxx",
255:    xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
256:    xxxxxxxxx_xxxx=True,
257:    xxxxxxxx_xxxxxxxxxx=False,
258:    xxxxxx_xxxxxx=2,
259:    xxxxxx_xxxxx_xxxxxxxx=70,
260:    xxxxxx_xxxxxx_xxxxx=True,
261:    # fmt: off
262:    xxxxxxx_xxxxxxxxxxxx={
263:        "xxxxxxxx": {
264:            "xxxxxx": False,
265:            "xxxxxxx": False,
266:            "xxxx_xxxxxx": "xxxxx",
267:        },
268:        "xxxxxxxx-xxxxx": {
269:            "xxxxxx": False,
270:            "xxxxxxx": True,
271:            "xxxx_xxxxxx": "xxxxxx",
272:        },
273:    },
274:    # fmt: on
275:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5,
276:)
277:# fmt: off
278:# No formatting to the end of the file
279:l=[1,2,3]
280:d={'a':1,
281:   'b':2}

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The new fmt on/off handling no longer raises exceptions. generate_comments no longer raises FormatOff/On, normalize_fmt_off() is called up front and convert_one_fmt_off_pair()/generate_ignored_nodes() convert an unmatched “# fmt: off” into a STANDALONE_COMMENT containing all following nodes until the end of the block or ENDMARKER (see black.py:2555-2613). container_of() was updated to stop at file_input (black.py:1852-1856), so generate_ignored_nodes walks siblings only. No SyntaxError is raised anywhere; unmatched off is handled gracefully to block end, satisfying the todo and matching test_fmtonoff2.

Todo item 19 of 22 is correct
description: 'Check that unmatched `# fmt: off` (no corresponding `# fmt: on`) is handled gracefully: by reading until block end without raising errors (no lingering raises of `SyntaxError` from prior implementation).'

Validating todo item 20 of 22
description: 'Verify `DebugVisitor.show()` signature accepts `Union[str, Leaf, Node]` and properly parses only when input is `str`, without breaking any call sites that used the previous signature.'

Calling tool: grepTool
DebugVisitor\.show\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:102:.. py:function:: black.DebugVisitor.show(code: str) -> None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:752:            black.DebugVisitor.show(source)

Calling tool: grepTool
class DebugVisitor
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py:2:class DebugVisitor(Visitor[T]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:709:class DebugVisitor(Visitor[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):
710:    tree_depth: int = 0
711:
712:    def visit_default(self, node: LN) -> Iterator[T]:
713:        indent = " " * (2 * self.tree_depth)
714:        if isinstance(node, Node):
715:            _type = type_repr(node.type)
716:            out(f"{indent}{_type}", fg="yellow")
717:            self.tree_depth += 1
718:            for child in node.children:
719:                yield from self.visit(child)
720:
721:            self.tree_depth -= 1
722:            out(f"{indent}/{_type}", fg="yellow", bold=False)
723:        else:
724:            _type = token.tok_name.get(node.type, str(node.type))
725:            out(f"{indent}{_type}", fg="blue", nl=False)
726:            if node.prefix:
727:                # We don't have to handle prefixes for `Node` objects since
728:                # that delegates to the first child anyway.
729:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/debug_visitor.py
1:@dataclass
2:class DebugVisitor(Visitor[T]):
3:    tree_depth: int = 0
4:
5:    def visit_default(self, node: LN) -> Iterator[T]:
6:        indent = ' ' * (2 * self.tree_depth)
7:        if isinstance(node, Node):
8:            _type = type_repr(node.type)
9:            out(f'{indent}{_type}', fg='yellow')
10:            self.tree_depth += 1
11:            for child in node.children:
12:                yield from self.visit(child)
13:
14:            self.tree_depth -= 1
15:            out(f'{indent}/{_type}', fg='yellow', bold=False)
16:        else:
17:            _type = token.tok_name.get(node.type, str(node.type))
18:            out(f'{indent}{_type}', fg='blue', nl=False)
19:            if node.prefix:
20:                # We don't have to handle prefixes for `Node` objects since
21:                # that delegates to the first child anyway.
22:                out(f' {node.prefix!r}', fg='green', bold=False, nl=False)
23:            out(f' {node.value!r}', fg='blue', bold=False)
24:
25:    @classmethod
26:    def show(cls, code: str) -> None:
27:        """Pretty-prints a given string of `code`.
28:
29:        Convenience method for debugging.
30:        """
31:        v: DebugVisitor[None] = DebugVisitor()
32:        list(v.visit(lib2to3_parse(code)))

Calling tool: grepTool
\.show\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_functions.rst:102:.. py:function:: black.DebugVisitor.show(code: str) -> None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:752:            black.DebugVisitor.show(source)

Calling tool: grepTool
class Leaf|class Node|from .* import Leaf, Node|Leaf\]|Node\]|Visitor\[
Matched content:
67:LN = Union[Leaf, Node]
709:class DebugVisitor(Visitor[T]):
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
738:        v: DebugVisitor[None] = DebugVisitor()
874:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
876:    previous: Optional[Leaf] = None
987:    def get_open_lsqb(self) -> Optional[Leaf]:
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1394:class LineGenerator(Visitor[Line]):
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2176:    tail_leaves: List[Leaf] = []
2177:    body_leaves: List[Leaf] = []
2178:    head_leaves: List[Leaf] = []
3272:        Callable[[Sequence[Leaf]], Iterator[Tuple[Index, Leaf]]],
3280:        comment: Optional[Leaf]

Calling tool: grepTool
from .* import Leaf, Node
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
pytree import
Matched content:
43:from blib2to3.pytree import Node, Leaf, type_repr

Calling tool: grepTool
class Visitor
Matched content:
682:class Visitor(Generic[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")
680:
681:
682:class Visitor(Generic[T]):
683:    """Basic lib2to3 visitor that yields things of type `T` on `visit()`."""
684:
685:    def visit(self, node: LN) -> Iterator[T]:
686:        """Main method to visit `node` and its children.
687:
688:        It tries to find a `visit_*()` method for the given `node.type`, like
689:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
730:        node = black.lib2to3_parse("# comment\nfrom __future__ import black\n")
731:        self.assertEqual({"black"}, black.get_future_imports(node))
732:        node = black.lib2to3_parse('"""docstring"""\nfrom __future__ import black\n')
733:        self.assertEqual({"black"}, black.get_future_imports(node))
734:        node = black.lib2to3_parse("some(other, code)\nfrom __future__ import black\n")
735:        self.assertEqual(set(), black.get_future_imports(node))
736:        node = black.lib2to3_parse("from some.module import black\n")
737:        self.assertEqual(set(), black.get_future_imports(node))
738:
739:    def test_debug_visitor(self) -> None:
740:        source, _ = read_data("debug_visitor.py")
741:        expected, _ = read_data("debug_visitor.out")
742:        out_lines = []
743:        err_lines = []
744:
745:        def out(msg: str, **kwargs: Any) -> None:
746:            out_lines.append(msg)
747:
748:        def err(msg: str, **kwargs: Any) -> None:
749:            err_lines.append(msg)
750:
751:        with patch("black.out", out), patch("black.err", err):
752:            black.DebugVisitor.show(source)
753:        actual = "\n".join(out_lines) + "\n"
754:        log_name = ""
755:        if expected != actual:
756:            log_name = black.dump_to_file(*out_lines)
757:        self.assertEqual(
758:            expected,
759:            actual,
760:            f"AST print out is different. Actual version dumped to {log_name}",
761:        )
762:
763:    def test_format_file_contents(self) -> None:
764:        empty = ""
765:        with self.assertRaises(black.NothingChanged):
766:            black.format_file_contents(empty, line_length=ll, fast=False)
767:        just_nl = "\n"
768:        with self.assertRaises(black.NothingChanged):
769:            black.format_file_contents(just_nl, line_length=ll, fast=False)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":

Calling tool: grepTool
def lib2to3_parse
Matched content:
646:def lib2to3_parse(src_txt: str) -> Node:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: DebugVisitor.show now accepts Union[str, Leaf, Node] and only calls lib2to3_parse when the input is a str. Existing call sites (tests call with a string) remain valid, so no breakage occurs.

Todo item 20 of 22 is correct
description: 'Verify `DebugVisitor.show()` signature accepts `Union[str, Leaf, Node]` and properly parses only when input is `str`, without breaking any call sites that used the previous signature.'

Validating todo item 21 of 22
description: 'Check typing imports: `Type` was removed from imports; ensure there are no remaining type hints or usages requiring `Type`.'

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
typing\.Type
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
Type\[
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import keyword
9:import logging
10:from multiprocessing import Manager
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tokenize
18:from typing import (
19:    Any,
20:    Callable,
21:    Collection,
22:    Dict,
23:    Generic,
24:    Iterable,
25:    Iterator,
26:    List,
27:    Optional,
28:    Pattern,
29:    Sequence,
30:    Set,
31:    Tuple,
32:    TypeVar,
33:    Union,
34:    cast,
35:)
36:
37:from appdirs import user_cache_dir
38:from attr import dataclass, Factory
39:import click
40:import toml
41:
42:# lib2to3 fork
43:from blib2to3.pytree import Node, Leaf, type_repr
44:from blib2to3 import pygram, pytree
45:from blib2to3.pgen2 import driver, token
46:from blib2to3.pgen2.parse import ParseError
47:
48:
49:__version__ = "18.6b2"
50:DEFAULT_LINE_LENGTH = 88
51:DEFAULT_EXCLUDES = (
52:    r"/(\.git|\.hg|\.mypy_cache|\.tox|\.venv|_build|buck-out|build|dist)/"
53:)
54:DEFAULT_INCLUDES = r"\.pyi?$"
55:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
56:
57:
58:# types
59:FileContent = str
60:Encoding = str
61:NewLine = str
62:Depth = int
63:NodeType = int
64:LeafID = int
65:Priority = int
66:Index = int
67:LN = Union[Leaf, Node]
68:SplitFunc = Callable[["Line", bool], Iterator["Line"]]
69:Timestamp = float
70:FileSize = int
71:CacheInfo = Tuple[Timestamp, FileSize]
72:Cache = Dict[Path, CacheInfo]
73:out = partial(click.secho, bold=True, err=True)
74:err = partial(click.secho, fg="red", err=True)
75:
76:pygram.initialize(CACHE_DIR)
77:syms = pygram.python_symbols
78:
79:
80:class NothingChanged(UserWarning):
81:    """Raised by :func:`format_file` when reformatted code is the same as source."""
82:
83:
84:class CannotSplit(Exception):
85:    """A readable split that fits the allotted line length is impossible.
86:
87:    Raised by :func:`left_hand_split`, :func:`right_hand_split`, and
88:    :func:`delimiter_split`.
89:    """
90:
91:
92:class WriteBack(Enum):
93:    NO = 0
94:    YES = 1
95:    DIFF = 2
96:
97:    @classmethod
98:    def from_configuration(cls, *, check: bool, diff: bool) -> "WriteBack":
99:        if check and not diff:
100:            return cls.NO
101:
102:        return cls.DIFF if diff else cls.YES
103:
104:
105:class Changed(Enum):
106:    NO = 0
107:    CACHED = 1
108:    YES = 2
109:
110:
111:class FileMode(Flag):
112:    AUTO_DETECT = 0
113:    PYTHON36 = 1
114:    PYI = 2
115:    NO_STRING_NORMALIZATION = 4
116:
117:    @classmethod
118:    def from_configuration(
119:        cls, *, py36: bool, pyi: bool, skip_string_normalization: bool
120:    ) -> "FileMode":
121:        mode = cls.AUTO_DETECT
122:        if py36:
123:            mode |= cls.PYTHON36
124:        if pyi:
125:            mode |= cls.PYI
126:        if skip_string_normalization:
127:            mode |= cls.NO_STRING_NORMALIZATION
128:        return mode
129:
130:

Calling tool: grepTool
line\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
from\s+typing\s+import\s+.*\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified that `Type` was removed from typing imports and there are no remaining uses. Grep found no occurrences of `Type` or `typing.Type`, and the only previous usage in `LineGenerator.line` was refactored to remove the `type: Type[Line]` parameter.

Todo item 21 of 22 is correct
description: 'Check typing imports: `Type` was removed from imports; ensure there are no remaining type hints or usages requiring `Type`.'

Validating todo item 22 of 22
description: 'Review test `test_fmtonoff2` to ensure it exercises a top-level `# fmt: off` region spanning multiple statements/functions and asserts that: (a) no extra blank lines are inserted between functions, and (b) code inside the off/on block (e.g., list of tuples) is not reformatted.'

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(
480:                unstyle(str(report)),
481:                "2 files reformatted, 2 files left unchanged, "
482:                "1 file failed to reformat.",
483:            )
484:            self.assertEqual(report.return_code, 123)
485:            report.failed(Path("e2"), "boom")
486:            self.assertEqual(len(out_lines), 4)
487:            self.assertEqual(len(err_lines), 2)
488:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
489:            self.assertEqual(
490:                unstyle(str(report)),
491:                "2 files reformatted, 2 files left unchanged, "
492:                "2 files failed to reformat.",
493:            )
494:            self.assertEqual(report.return_code, 123)
495:            report.path_ignored(Path("wat"), "no match")
496:            self.assertEqual(len(out_lines), 5)
497:            self.assertEqual(len(err_lines), 2)
498:            self.assertEqual(out_lines[-1], "wat ignored: no match")
499:            self.assertEqual(

Calling tool: globTool
**/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: globTool
**/tests/data/fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:
2700:    lpar, expr, rpar = node.children
2701:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2702:        return is_yield(expr)
2703:
2704:    return False
2705:
2706:
2707:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2708:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2709:
2710:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2711:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2712:    extended iterable unpacking (PEP 3132) and additional unpacking
2713:    generalizations (PEP 448).
2714:    """
2715:    if leaf.type not in STARS or not leaf.parent:
2716:        return False
2717:
2718:    p = leaf.parent
2719:    if p.type == syms.star_expr:
2720:        # Star expressions are also used as assignment targets in extended
2721:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2722:        if not p.parent:
2723:            return False
2724:
2725:        p = p.parent
2726:
2727:    return p.type in within
2728:
2729:
2730:def is_multiline_string(leaf: Leaf) -> bool:
2731:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2732:    value = leaf.value.lstrip("furbFURB")
2733:    return value[:3] in {'"""', "'''"} and "\n" in value
2734:
2735:
2736:def is_stub_suite(node: Node) -> bool:
2737:    """Return True if `node` is a suite with a stub body."""
2738:    if (
2739:        len(node.children) != 4
2740:        or node.children[0].type != token.NEWLINE
2741:        or node.children[1].type != token.INDENT
2742:        or node.children[3].type != token.DEDENT
2743:    ):
2744:        return False
2745:
2746:    return is_stub_body(node.children[2])
2747:
2748:
2749:def is_stub_body(node: LN) -> bool:
2750:    """Return True if `node` is a simple statement containing an ellipsis."""
2751:    if not isinstance(node, Node) or node.type != syms.simple_stmt:
2752:        return False
2753:
2754:    if len(node.children) != 2:
2755:        return False
2756:
2757:    child = node.children[0]
2758:    return (
2759:        child.type == syms.atom

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test `test_fmtonoff2` loads `tests/data/fmtonoff2.py` which contains a top-level `# fmt: off` block spanning multiple functions and a list of tuples. Since there is no `# output` marker, the test asserts the formatted output equals the input, ensuring no extra blank lines are inserted and content inside the off/on block is not reformatted.

Todo item 22 of 22 is correct
description: 'Review test `test_fmtonoff2` to ensure it exercises a top-level `# fmt: off` region spanning multiple statements/functions and asserts that: (a) no extra blank lines are inserted between functions, and (b) code inside the off/on block (e.g., list of tuples) is not reformatted.'


=== PHASE 2 COMPLETE ===

