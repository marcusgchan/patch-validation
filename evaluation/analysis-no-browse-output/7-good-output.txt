=== PHASE 1: ANALYSIS ===

Calling tool: createTodo
Todo List Created
Todo List (14 items):
- [ ] In black.py, locate normalize_invisible_parens(). Verify that at the start of the for-loop over node.children, a new condition sets check_lpar = True when index == 0 and child is a Node with type syms.testlist_star_expr. (ID: todo-1)
- [ ] Confirm the new check (index == 0 and child.type == syms.testlist_star_expr) is executed before the subsequent 'if check_lpar:' block so it affects handling of that same first child in the current iteration. (ID: todo-2)
- [ ] Within normalize_invisible_parens(), verify that when wrapping is performed, the code constructs Leaf(token.LPAR, "") and Leaf(token.RPAR, "") and creates new_child = Node(syms.atom, [lpar, child, rpar]). (ID: todo-3)
- [ ] Verify that the child's prefix is preserved correctly when wrapping: the code saves prefix = child.prefix, sets child.prefix = "", sets new_child.prefix = prefix, then inserts new_child back into the parent. (ID: todo-4)
- [ ] Check that node.insert_child() uses the index returned by child.remove() (i.e., index = child.remove() or 0) to reinsert the wrapper at the original position, preserving sibling order. (ID: todo-5)
- [ ] Ensure that the end-of-loop assignment check_lpar = isinstance(child, Leaf) and child.value in parens_after remains, so the special-case change does not alter behavior for subsequent children. (ID: todo-6)
- [ ] Verify that the special-case only triggers for the very first child (index == 0), ensuring the change only targets the LHS of an assignment and not the RHS or later elements. (ID: todo-7)
- [ ] Confirm that if the first child is already an atom (already parenthesized), the code path 'if child.type == syms.atom' calls maybe_make_parens_invisible_in_atom(child, parent=node), preventing double-wrapping. (ID: todo-8)
- [ ] Verify that no new imports are required: syms, token, Node, and Leaf are already defined/imported in black.py and accessible within normalize_invisible_parens(). (ID: todo-9)
- [ ] Open the test test_tuple_assign and confirm it includes a long LHS tuple unpacking assignment case that previously required a backslash continuation and now expects parentheses around the LHS. (ID: todo-10)
- [ ] In test_tuple_assign, verify that the expected formatted output has parentheses around the LHS names and does not rely on a backslash for line continuation. (ID: todo-11)
- [ ] If comments or leading whitespace precede the LHS tuple in the test, verify the expected output preserves them before the opening '(', consistent with moving the prefix to the wrapper node. (ID: todo-12)
- [ ] Scan the modified block to ensure no unrelated formatting is applied to siblings (e.g., RHS or trailing commas). The wrapping should be limited to replacing the first child with an atom node containing invisible parens. (ID: todo-13)
- [ ] Check that shadowing of the 'index' variable inside the wrapping block (index = child.remove() or 0) does not affect subsequent logic in the same iteration (no further reliance on the loop's index variable after this assignment). (ID: todo-14)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 14
description: 'In black.py, locate normalize_invisible_parens(). Verify that at the start of the for-loop over node.children, a new condition sets check_lpar = True when index == 0 and child is a Node with type syms.testlist_star_expr.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s normalize_invisible_parens(), at the beginning of the for-loop (lines 2729-2735), there is an added condition that checks index == 0, child is a Node, and child.type == syms.testlist_star_expr, then sets check_lpar = True. This matches the todo requirement.


Todo item 1 of 14 is correct
description: 'In black.py, locate normalize_invisible_parens(). Verify that at the start of the for-loop over node.children, a new condition sets check_lpar = True when index == 0 and child is a Node with type syms.testlist_star_expr.'
Validating todo item 2 of 14
description: 'Confirm the new check (index == 0 and child.type == syms.testlist_star_expr) is executed before the subsequent 'if check_lpar:' block so it affects handling of that same first child in the current iteration.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2729–2735 set check_lpar=True when index==0 and child.type==syms.testlist_star_expr, and the subsequent if check_lpar: block starts at line 2737 in the same loop iteration, so the first child is handled immediately.


Todo item 2 of 14 is correct
description: 'Confirm the new check (index == 0 and child.type == syms.testlist_star_expr) is executed before the subsequent 'if check_lpar:' block so it affects handling of that same first child in the current iteration.'
Validating todo item 3 of 14
description: 'Within normalize_invisible_parens(), verify that when wrapping is performed, the code constructs Leaf(token.LPAR, "") and Leaf(token.RPAR, "") and creates new_child = Node(syms.atom, [lpar, child, rpar]).'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s normalize_invisible_parens(), the wrapping branch (lines ~2765-2772) constructs lpar = Leaf(token.LPAR, ""), rpar = Leaf(token.RPAR, ""), and creates new_child = Node(syms.atom, [lpar, child, rpar]) before inserting it, satisfying the requirement.


Todo item 3 of 14 is correct
description: 'Within normalize_invisible_parens(), verify that when wrapping is performed, the code constructs Leaf(token.LPAR, "") and Leaf(token.RPAR, "") and creates new_child = Node(syms.atom, [lpar, child, rpar]).'
Validating todo item 4 of 14
description: 'Verify that the child's prefix is preserved correctly when wrapping: the code saves prefix = child.prefix, sets child.prefix = "", sets new_child.prefix = prefix, then inserts new_child back into the parent.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, when wrapping the child (non-multiline string branch), the code saves prefix = child.prefix, sets child.prefix = "", creates new_child, assigns new_child.prefix = prefix, and inserts new_child. Verified at lines 2767-2772.


Todo item 4 of 14 is correct
description: 'Verify that the child's prefix is preserved correctly when wrapping: the code saves prefix = child.prefix, sets child.prefix = "", sets new_child.prefix = prefix, then inserts new_child back into the parent.'
Validating todo item 5 of 14
description: 'Check that node.insert_child() uses the index returned by child.remove() (i.e., index = child.remove() or 0) to reinsert the wrapper at the original position, preserving sibling order.'
Calling tool: grepTool
def normalize_invisible_parens\(node: Node, parens_after: Set\[str\]\) -> None:
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens, the code sets index = child.remove() or 0 and then calls node.insert_child(index, ...) to reinsert the new wrapper node at the original position. Verified at lines 2742-2743 and 2767-2772 of black.py.


Todo item 5 of 14 is correct
description: 'Check that node.insert_child() uses the index returned by child.remove() (i.e., index = child.remove() or 0) to reinsert the wrapper at the original position, preserving sibling order.'
Validating todo item 6 of 14
description: 'Ensure that the end-of-loop assignment check_lpar = isinstance(child, Leaf) and child.value in parens_after remains, so the special-case change does not alter behavior for subsequent children.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: grepTool
check_lpar\s*=\s*isinstance\(child, Leaf\)\s*and\s*child\.value\s*in\s*parens_after
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, the end-of-loop assignment remains: `check_lpar = isinstance(child, Leaf) and child.value in parens_after` (line ~2774). This ensures the special-case addition does not alter behavior for subsequent children.


Todo item 6 of 14 is correct
description: 'Ensure that the end-of-loop assignment check_lpar = isinstance(child, Leaf) and child.value in parens_after remains, so the special-case change does not alter behavior for subsequent children.'
Validating todo item 7 of 14
description: 'Verify that the special-case only triggers for the very first child (index == 0), ensuring the change only targets the LHS of an assignment and not the RHS or later elements.'
Calling tool: grepTool
def normalize_invisible_parens\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens, the new special-case sets check_lpar to True only when index == 0 and child is a testlist_star_expr. The check is evaluated immediately in the same iteration and then check_lpar is reset at the end of the loop based on the current child, preventing it from affecting later children (RHS).


Todo item 7 of 14 is correct
description: 'Verify that the special-case only triggers for the very first child (index == 0), ensuring the change only targets the LHS of an assignment and not the RHS or later elements.'
Validating todo item 8 of 14
description: 'Confirm that if the first child is already an atom (already parenthesized), the code path 'if child.type == syms.atom' calls maybe_make_parens_invisible_in_atom(child, parent=node), preventing double-wrapping.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,

Calling tool: grepTool
def maybe_make_parens_invisible_in_atom\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)
2865:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2866:    ):
2867:        return False
2868:
2869:    first = node.children[0]
2870:    last = node.children[-1]
2871:    if first.type == token.LPAR and last.type == token.RPAR:
2872:        # make parentheses invisible
2873:        first.value = ""  # type: ignore
2874:        last.value = ""  # type: ignore
2875:        if len(node.children) > 1:
2876:            maybe_make_parens_invisible_in_atom(node.children[1], parent=parent)
2877:        return False
2878:
2879:    return True
2880:
2881:
2882:def is_empty_tuple(node: LN) -> bool:
2883:    """Return True if `node` holds an empty tuple."""
2884:    return (
2885:        node.type == syms.atom
2886:        and len(node.children) == 2
2887:        and node.children[0].type == token.LPAR
2888:        and node.children[1].type == token.RPAR
2889:    )
2890:
2891:
2892:def is_one_tuple(node: LN) -> bool:
2893:    """Return True if `node` holds a tuple with one element, with or without parens."""
2894:    if node.type == syms.atom:
2895:        if len(node.children) != 3:
2896:            return False
2897:
2898:        lpar, gexp, rpar = node.children
2899:        if not (
2900:            lpar.type == token.LPAR
2901:            and gexp.type == syms.testlist_gexp
2902:            and rpar.type == token.RPAR
2903:        ):
2904:            return False
2905:
2906:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2907:
2908:    return (
2909:        node.type in IMPLICIT_TUPLE
2910:        and len(node.children) == 2
2911:        and node.children[1].type == token.COMMA
2912:    )
2913:
2914:
2915:def is_yield(node: LN) -> bool:
2916:    """Return True if `node` holds a `yield` or `yield from` expression."""
2917:    if node.type == syms.yield_expr:
2918:        return True
2919:
2920:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2921:        return True
2922:
2923:    if node.type != syms.atom:
2924:        return False
2925:
2926:    if len(node.children) != 3:
2927:        return False
2928:
2929:    lpar, expr, rpar = node.children
2930:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2931:        return is_yield(expr)
2932:
2933:    return False
2934:
2935:
2936:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2937:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2938:
2939:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2940:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2941:    extended iterable unpacking (PEP 3132) and additional unpacking
2942:    generalizations (PEP 448).
2943:    """
2944:    if leaf.type not in STARS or not leaf.parent:
2945:        return False
2946:
2947:    p = leaf.parent
2948:    if p.type == syms.star_expr:
2949:        # Star expressions are also used as assignment targets in extended
2950:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2951:        if not p.parent:
2952:            return False
2953:
2954:        p = p.parent
2955:
2956:    return p.type in within
2957:
2958:
2959:def is_multiline_string(leaf: Leaf) -> bool:
2960:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2961:    value = leaf.value.lstrip("furbFURB")
2962:    return value[:3] in {'"""', "'''"} and "\n" in value
2963:
2964:
2965:def is_stub_suite(node: Node) -> bool:
2966:    """Return True if `node` is a suite with a stub body."""
2967:    if (

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, when check_lpar is True and the current child is an atom, the code calls maybe_make_parens_invisible_in_atom(child, parent=node). That function makes existing parentheses invisible and returns False, so the caller does not wrap again, preventing double-wrapping. Verified at lines 2738–2743 and function definition lines 2854–2879.


Todo item 8 of 14 is correct
description: 'Confirm that if the first child is already an atom (already parenthesized), the code path 'if child.type == syms.atom' calls maybe_make_parens_invisible_in_atom(child, parent=node), preventing double-wrapping.'
Validating todo item 9 of 14
description: 'Verify that no new imports are required: syms, token, Node, and Leaf are already defined/imported in black.py and accessible within normalize_invisible_parens().'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: grepTool
\bsyms\b|\bNode\b|\bLeaf\b|\btoken\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/pyproject.lock:363:description = "Node.js virtual environment builder"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:9:_NL = Union[Node, Leaf]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:21:    parent: Optional[Node]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:39:    def leaves(self) -> Iterator[Leaf]: ...
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:46:class Node(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:53:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:61:    opening_bracket: Leaf
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:7:This is a very concrete parse tree; we need to keep every token and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:26:        # from .pgen2 import token // token.__dict__.items():
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:34:    Abstract base class for Node and Leaf.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:43:    type = None    # int: token number (< 256) or symbol number (>= 256)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:128:        while not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:204:class Node(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:257:        return Node(self.type, [ch.clone() for ch in self.children],
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:331:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:336:    _prefix = ""  # Whitespace and comments preceding this token in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:337:    lineno = 0    # Line where this token starts in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:338:    column = 0    # Column where this token tarts in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:347:        Takes a type constant (a token number < 256), a string value, and an
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:361:        from .pgen2.token import tok_name
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:383:        return Leaf(self.type, self.value,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:401:        The whitespace and comments preceding this token in the input.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:412:    Convert raw node information to a Node or Leaf instance.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:424:        return Node(type, children, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:426:        return Leaf(type, value, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:434:    It looks for a specific node type (token or symbol), and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:446:    type = None     # Node type (token if < 256, symbol if >= 256)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:521:        The type, if given must be a token type (< 256).  If not given,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:539:        if not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/PatternGrammar.txt:6:# - 'TOKEN' stands for any token (leaf node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/Grammar.txt:132:# "test '=' test" is really "keyword '=' test", but we have no such token.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pygram.py:10:from .pgen2 import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:11:    the token type (see token.py)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:12:    the token (a string)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:13:    the starting (row, column) indices of the token (a 2-tuple of ints)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:14:    the ending (row, column) indices of the token (a 2-tuple of ints)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:26:each time a new token is found."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:34:from blib2to3.pgen2.token import *
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:36:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:37:__all__ = [x for x in dir(token) if x[0] != '_'] + ["tokenize",
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:39:del token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:144:def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:148:        (srow, scol, erow, ecol, tok_name[type], repr(token)))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:160:    called once for each token, with five arguments, corresponding to the
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:192:            tok_type, token, start, end, line = t
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:194:            self.tokens.append(token)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:201:    def compat(self, token, iterable):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:205:        toknum, tokval = token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:319:    Each element returned by the iterable must be a token sequence
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:320:    with at least two elements, a token number and token value.  If

Calling tool: grepTool
\bsyms\b|\bNode\b|\bLeaf\b|\btoken\b
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black/black.py: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black/black.py: No such file or directory (os error 2)


Calling tool: grepTool
from .* import (.+\bNode\b.*\bLeaf\b|\bLeaf\b.*\bNode\b)|import .*\bNode\b|import .*\bLeaf\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:45:from blib2to3.pytree import Node, Leaf, type_repr

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum
6:from functools import lru_cache, partial, wraps
7:import io
8:import itertools
9:import logging
10:from multiprocessing import Manager, freeze_support
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tempfile
18:import tokenize
19:from typing import (
20:    Any,
21:    Callable,
22:    Collection,
23:    Dict,
24:    Generator,
25:    Generic,
26:    Iterable,
27:    Iterator,
28:    List,
29:    Optional,
30:    Pattern,
31:    Sequence,
32:    Set,
33:    Tuple,
34:    TypeVar,
35:    Union,
36:    cast,
37:)
38:
39:from appdirs import user_cache_dir
40:from attr import dataclass, evolve, Factory
41:import click
42:import toml
43:
44:# lib2to3 fork
45:from blib2to3.pytree import Node, Leaf, type_repr
46:from blib2to3 import pygram, pytree
47:from blib2to3.pgen2 import driver, token
48:from blib2to3.pgen2.grammar import Grammar
49:from blib2to3.pgen2.parse import ParseError
50:
51:
52:__version__ = "19.3b0"
53:DEFAULT_LINE_LENGTH = 88
54:DEFAULT_EXCLUDES = (
55:    r"/(\.eggs|\.git|\.hg|\.mypy_cache|\.nox|\.tox|\.venv|_build|buck-out|build|dist)/"
56:)
57:DEFAULT_INCLUDES = r"\.pyi?$"
58:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
59:
60:
61:# types
62:FileContent = str
63:Encoding = str
64:NewLine = str
65:Depth = int
66:NodeType = int
67:LeafID = int
68:Priority = int
69:Index = int
70:LN = Union[Leaf, Node]
71:SplitFunc = Callable[["Line", Collection["Feature"]], Iterator["Line"]]
72:Timestamp = float
73:FileSize = int
74:CacheInfo = Tuple[Timestamp, FileSize]
75:Cache = Dict[Path, CacheInfo]
76:out = partial(click.secho, bold=True, err=True)
77:err = partial(click.secho, fg="red", err=True)
78:
79:pygram.initialize(CACHE_DIR)
80:syms = pygram.python_symbols
81:
82:
83:class NothingChanged(UserWarning):
84:    """Raised when reformatted code is the same as source."""
85:
86:
87:class CannotSplit(Exception):
88:    """A readable split that fits the allotted line length is impossible."""
89:
90:
91:class InvalidInput(ValueError):
92:    """Raised when input source code fails all parse attempts."""
93:
94:
95:class WriteBack(Enum):
96:    NO = 0
97:    YES = 1
98:    DIFF = 2
99:    CHECK = 3
100:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2700:        text = format_float_or_int_string(text)
2701:    leaf.value = text
2702:
2703:
2704:def format_float_or_int_string(text: str) -> str:
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue

Calling tool: grepTool
^\s*token\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:482:                        token = line[start:pos]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Confirmed in black.py: Node and Leaf are imported at line 45, token at line 47, and syms is assigned at line 80 from pygram.python_symbols. normalize_invisible_parens uses these names and they are in module scope, so no new imports are required.


Todo item 9 of 14 is correct
description: 'Verify that no new imports are required: syms, token, Node, and Leaf are already defined/imported in black.py and accessible within normalize_invisible_parens().'
Validating todo item 10 of 14
description: 'Open the test test_tuple_assign and confirm it includes a long LHS tuple unpacking assignment case that previously required a backslash continuation and now expects parentheses around the LHS.'
Calling tool: grepTool
test_tuple_assign\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )
600:            report.done(Path("f3"), black.Changed.CACHED)
601:            self.assertEqual(len(out_lines), 3)
602:            self.assertEqual(len(err_lines), 0)
603:            self.assertEqual(
604:                out_lines[-1], "f3 wasn't modified on disk since last run."
605:            )
606:            self.assertEqual(
607:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
608:            )
609:            self.assertEqual(report.return_code, 0)
610:            report.check = True
611:            self.assertEqual(report.return_code, 1)
612:            report.check = False
613:            report.failed(Path("e1"), "boom")
614:            self.assertEqual(len(out_lines), 3)
615:            self.assertEqual(len(err_lines), 1)
616:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
617:            self.assertEqual(
618:                unstyle(str(report)),
619:                "1 file reformatted, 2 files left unchanged, "
620:                "1 file failed to reformat.",
621:            )
622:            self.assertEqual(report.return_code, 123)
623:            report.done(Path("f3"), black.Changed.YES)
624:            self.assertEqual(len(out_lines), 4)
625:            self.assertEqual(len(err_lines), 1)
626:            self.assertEqual(out_lines[-1], "reformatted f3")
627:            self.assertEqual(
628:                unstyle(str(report)),
629:                "2 files reformatted, 2 files left unchanged, "
630:                "1 file failed to reformat.",
631:            )
632:            self.assertEqual(report.return_code, 123)
633:            report.failed(Path("e2"), "boom")
634:            self.assertEqual(len(out_lines), 4)
635:            self.assertEqual(len(err_lines), 2)
636:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
637:            self.assertEqual(
638:                unstyle(str(report)),
639:                "2 files reformatted, 2 files left unchanged, "

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:57:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:import logging
4:from concurrent.futures import ThreadPoolExecutor
5:from contextlib import contextmanager, redirect_stderr
6:from functools import partial, wraps
7:from io import BytesIO, TextIOWrapper
8:import os
9:from pathlib import Path
10:import re
11:import sys
12:from tempfile import TemporaryDirectory
13:from typing import (
14:    Any,
15:    BinaryIO,
16:    Callable,
17:    Coroutine,
18:    Generator,
19:    List,
20:    Tuple,
21:    Iterator,
22:    TypeVar,
23:)
24:import unittest
25:from unittest.mock import patch, MagicMock
26:
27:from click import unstyle
28:from click.testing import CliRunner
29:
30:import black
31:from black import Feature, TargetVersion
32:
33:try:
34:    import blackd
35:    from aiohttp.test_utils import TestClient, TestServer
36:except ImportError:
37:    has_blackd_deps = False
38:else:
39:    has_blackd_deps = True
40:
41:ff = partial(black.format_file_in_place, mode=black.FileMode(), fast=True)
42:fs = partial(black.format_str, mode=black.FileMode())
43:THIS_FILE = Path(__file__)
44:THIS_DIR = THIS_FILE.parent
45:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
46:PY36_ARGS = [
47:    f"--target-version={version.name.lower()}" for version in black.PY36_VERSIONS
48:]
49:T = TypeVar("T")
50:R = TypeVar("R")
51:
52:
53:def dump_to_stderr(*output: str) -> str:
54:    return "\n" + "\n".join(output) + "\n"
55:
56:
57:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
58:    """read_data('test_name') -> 'input', 'output'"""
59:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
60:        name += ".py"
61:    _input: List[str] = []
62:    _output: List[str] = []
63:    base_dir = THIS_DIR / "data" if data else THIS_DIR
64:    with open(base_dir / name, "r", encoding="utf8") as test:
65:        lines = test.readlines()
66:    result = _input
67:    for line in lines:
68:        line = line.replace(EMPTY_LINE, "")
69:        if line.rstrip() == "# output":
70:            result = _output
71:            continue
72:
73:        result.append(line)
74:    if _input and not _output:
75:        # If there's no output marker, treat the entire file as already pre-formatted.
76:        _output = _input[:]
77:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
78:
79:
80:@contextmanager
81:def cache_dir(exists: bool = True) -> Iterator[Path]:
82:    with TemporaryDirectory() as workspace:
83:        cache_dir = Path(workspace)
84:        if not exists:
85:            cache_dir = cache_dir / "new"
86:        with patch("black.CACHE_DIR", cache_dir):
87:            yield cache_dir
88:
89:
90:@contextmanager
91:def event_loop(close: bool) -> Iterator[None]:
92:    policy = asyncio.get_event_loop_policy()
93:    old_loop = policy.get_event_loop()
94:    loop = policy.new_event_loop()
95:    asyncio.set_event_loop(loop)
96:    try:
97:        yield
98:
99:    finally:
100:        policy.set_event_loop(old_loop)

Calling tool: globTool
**/tests/data/tupleassign.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test `tests/test_black.py::test_tuple_assign` reads fixtures from `tests/data/tupleassign.py`, which contains a long LHS tuple assignment. The expected output shows the LHS wrapped in parentheses across lines, confirming the case now expects parentheses around the LHS.


Todo item 10 of 14 is correct
description: 'Open the test test_tuple_assign and confirm it includes a long LHS tuple unpacking assignment case that previously required a backslash continuation and now expects parentheses around the LHS.'
Validating todo item 11 of 14
description: 'In test_tuple_assign, verify that the expected formatted output has parentheses around the LHS names and does not rely on a backslash for line continuation.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: grepTool
test_tuple_assign
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )

Calling tool: globTool
**/*tupleassign*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: grepTool
def maybe_make_parens_invisible_in_atom\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2842:    """
2843:    container: Optional[LN] = container_of(leaf)
2844:    while container is not None and container.type != token.ENDMARKER:
2845:        for comment in list_comments(container.prefix, is_endmarker=False):
2846:            if comment.value in FMT_ON:
2847:                return
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)
2865:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2866:    ):
2867:        return False
2868:
2869:    first = node.children[0]
2870:    last = node.children[-1]
2871:    if first.type == token.LPAR and last.type == token.RPAR:
2872:        # make parentheses invisible
2873:        first.value = ""  # type: ignore
2874:        last.value = ""  # type: ignore
2875:        if len(node.children) > 1:
2876:            maybe_make_parens_invisible_in_atom(node.children[1], parent=parent)
2877:        return False
2878:
2879:    return True
2880:
2881:
2882:def is_empty_tuple(node: LN) -> bool:
2883:    """Return True if `node` holds an empty tuple."""
2884:    return (
2885:        node.type == syms.atom
2886:        and len(node.children) == 2
2887:        and node.children[0].type == token.LPAR
2888:        and node.children[1].type == token.RPAR
2889:    )
2890:
2891:
2892:def is_one_tuple(node: LN) -> bool:
2893:    """Return True if `node` holds a tuple with one element, with or without parens."""
2894:    if node.type == syms.atom:
2895:        if len(node.children) != 3:
2896:            return False
2897:
2898:        lpar, gexp, rpar = node.children
2899:        if not (
2900:            lpar.type == token.LPAR
2901:            and gexp.type == syms.testlist_gexp
2902:            and rpar.type == token.RPAR
2903:        ):
2904:            return False
2905:
2906:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2907:
2908:    return (
2909:        node.type in IMPLICIT_TUPLE
2910:        and len(node.children) == 2
2911:        and node.children[1].type == token.COMMA
2912:    )
2913:
2914:
2915:def is_yield(node: LN) -> bool:
2916:    """Return True if `node` holds a `yield` or `yield from` expression."""
2917:    if node.type == syms.yield_expr:
2918:        return True
2919:
2920:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2921:        return True
2922:
2923:    if node.type != syms.atom:
2924:        return False
2925:
2926:    if len(node.children) != 3:
2927:        return False
2928:
2929:    lpar, expr, rpar = node.children
2930:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2931:        return is_yield(expr)
2932:
2933:    return False
2934:
2935:
2936:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2937:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2938:
2939:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2940:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2941:    extended iterable unpacking (PEP 3132) and additional unpacking
2942:    generalizations (PEP 448).
2943:    """
2944:    if leaf.type not in STARS or not leaf.parent:
2945:        return False
2946:
2947:    p = leaf.parent
2948:    if p.type == syms.star_expr:
2949:        # Star expressions are also used as assignment targets in extended
2950:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2951:        if not p.parent:
2952:            return False
2953:
2954:        p = p.parent
2955:
2956:    return p.type in within
2957:
2958:
2959:def is_multiline_string(leaf: Leaf) -> bool:
2960:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2961:    value = leaf.value.lstrip("furbFURB")

Calling tool: grepTool
def right_hand_split\(|def left_hand_split\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2242:def left_hand_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2278:def right_hand_split(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2215:            split_funcs = [rhs]
2216:    for split_func in split_funcs:
2217:        # We are accumulating lines in `result` because we might want to abort
2218:        # mission and return the original line in the end, or attempt a different
2219:        # split altogether.
2220:        result: List[Line] = []
2221:        try:
2222:            for l in split_func(line, features):
2223:                if str(l).strip("\n") == line_str:
2224:                    raise CannotSplit("Split function returned an unchanged result")
2225:
2226:                result.extend(
2227:                    split_line(
2228:                        l, line_length=line_length, inner=True, features=features
2229:                    )
2230:                )
2231:        except CannotSplit:
2232:            continue
2233:
2234:        else:
2235:            yield from result
2236:            break
2237:
2238:    else:
2239:        yield line
2240:
2241:
2242:def left_hand_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2243:    """Split line into many lines, starting with the first matching bracket pair.
2244:
2245:    Note: this usually looks weird, only use this for function definitions.
2246:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2247:    :func:`right_hand_split` which also handles optional parentheses.
2248:    """
2249:    tail_leaves: List[Leaf] = []
2250:    body_leaves: List[Leaf] = []
2251:    head_leaves: List[Leaf] = []
2252:    current_leaves = head_leaves
2253:    matching_bracket = None
2254:    for leaf in line.leaves:
2255:        if (
2256:            current_leaves is body_leaves
2257:            and leaf.type in CLOSING_BRACKETS
2258:            and leaf.opening_bracket is matching_bracket
2259:        ):
2260:            current_leaves = tail_leaves if body_leaves else head_leaves
2261:        current_leaves.append(leaf)
2262:        if current_leaves is head_leaves:
2263:            if leaf.type in OPENING_BRACKETS:
2264:                matching_bracket = leaf
2265:                current_leaves = body_leaves
2266:    if not matching_bracket:
2267:        raise CannotSplit("No brackets found")
2268:
2269:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2270:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2271:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2272:    bracket_split_succeeded_or_raise(head, body, tail)
2273:    for result in (head, body, tail):
2274:        if result:
2275:            yield result
2276:
2277:
2278:def right_hand_split(
2279:    line: Line,
2280:    line_length: int,
2281:    features: Collection[Feature] = (),
2282:    omit: Collection[LeafID] = (),
2283:) -> Iterator[Line]:
2284:    """Split line into many lines, starting with the last matching bracket pair.
2285:
2286:    If the split was by optional parentheses, attempt splitting without them, too.
2287:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2288:    this split.
2289:
2290:    Note: running this function modifies `bracket_depth` on the leaves of `line`.
2291:    """
2292:    tail_leaves: List[Leaf] = []
2293:    body_leaves: List[Leaf] = []
2294:    head_leaves: List[Leaf] = []
2295:    current_leaves = tail_leaves
2296:    opening_bracket = None
2297:    closing_bracket = None
2298:    for leaf in reversed(line.leaves):
2299:        if current_leaves is body_leaves:
2300:            if leaf is opening_bracket:
2301:                current_leaves = head_leaves if body_leaves else tail_leaves
2302:        current_leaves.append(leaf)
2303:        if current_leaves is tail_leaves:
2304:            if leaf.type in CLOSING_BRACKETS and id(leaf) not in omit:
2305:                opening_bracket = leaf.opening_bracket
2306:                closing_bracket = leaf
2307:                current_leaves = body_leaves
2308:    if not (opening_bracket and closing_bracket and head_leaves):
2309:        # If there is no opening or closing_bracket that means the split failed and
2310:        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means
2311:        # the matching `opening_bracket` wasn't available on `line` anymore.
2312:        raise CannotSplit("No brackets found")
2313:
2314:    tail_leaves.reverse()
2315:    body_leaves.reverse()
2316:    head_leaves.reverse()
2317:    head = bracket_split_build_line(head_leaves, line, opening_bracket)
2318:    body = bracket_split_build_line(body_leaves, line, opening_bracket, is_body=True)
2319:    tail = bracket_split_build_line(tail_leaves, line, opening_bracket)
2320:    bracket_split_succeeded_or_raise(head, body, tail)
2321:    if (
2322:        # the body shouldn't be exploded
2323:        not body.should_explode
2324:        # the opening bracket is an optional paren
2325:        and opening_bracket.type == token.LPAR
2326:        and not opening_bracket.value
2327:        # the closing bracket is an optional paren
2328:        and closing_bracket.type == token.RPAR
2329:        and not closing_bracket.value
2330:        # it's not an import (optional parens are the only thing we can split on
2331:        # in this case; attempting a split without them is a waste of time)
2332:        and not line.is_import
2333:        # there are no standalone comments in the body
2334:        and not body.contains_standalone_comments(0)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2330:        # it's not an import (optional parens are the only thing we can split on
2331:        # in this case; attempting a split without them is a waste of time)
2332:        and not line.is_import
2333:        # there are no standalone comments in the body
2334:        and not body.contains_standalone_comments(0)
2335:        # and we can actually remove the parens
2336:        and can_omit_invisible_parens(body, line_length)
2337:    ):
2338:        omit = {id(closing_bracket), *omit}
2339:        try:
2340:            yield from right_hand_split(line, line_length, features=features, omit=omit)
2341:            return
2342:
2343:        except CannotSplit:
2344:            if not (
2345:                can_be_split(body)
2346:                or is_line_short_enough(body, line_length=line_length)
2347:            ):
2348:                raise CannotSplit(
2349:                    "Splitting failed, body is still too long and can't be split."
2350:                )
2351:
2352:            elif head.contains_multiline_strings() or tail.contains_multiline_strings():
2353:                raise CannotSplit(
2354:                    "The current optional pair of parentheses is bound to fail to "
2355:                    "satisfy the splitting algorithm because the head or the tail "
2356:                    "contains multiline strings which by definition never fit one "
2357:                    "line."
2358:                )
2359:
2360:    ensure_visible(opening_bracket)
2361:    ensure_visible(closing_bracket)
2362:    for result in (head, body, tail):
2363:        if result:
2364:            yield result
2365:
2366:
2367:def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None:
2368:    """Raise :exc:`CannotSplit` if the last left- or right-hand split failed.
2369:
2370:    Do nothing otherwise.
2371:
2372:    A left- or right-hand split is based on a pair of brackets. Content before
2373:    (and including) the opening bracket is left on one line, content inside the
2374:    brackets is put on a separate line, and finally content starting with and
2375:    following the closing bracket is put on a separate line.
2376:
2377:    Those are called `head`, `body`, and `tail`, respectively. If the split
2378:    produced the same line (all content in `head`) or ended up with an empty `body`
2379:    and the `tail` is just the closing bracket, then it's considered failed.
2380:    """
2381:    tail_len = len(str(tail).strip())
2382:    if not body:
2383:        if tail_len == 0:
2384:            raise CannotSplit("Splitting brackets produced the same line")
2385:
2386:        elif tail_len < 3:
2387:            raise CannotSplit(
2388:                f"Splitting brackets on an empty body to save "
2389:                f"{tail_len} characters is not worth it"
2390:            )
2391:
2392:
2393:def bracket_split_build_line(
2394:    leaves: List[Leaf], original: Line, opening_bracket: Leaf, *, is_body: bool = False
2395:) -> Line:
2396:    """Return a new line with given `leaves` and respective comments from `original`.
2397:
2398:    If `is_body` is True, the result line is one-indented inside brackets and as such
2399:    has its first leaf's prefix normalized and a trailing comma added when expected.
2400:    """
2401:    result = Line(depth=original.depth)
2402:    if is_body:
2403:        result.inside_brackets = True
2404:        result.depth += 1
2405:        if leaves:
2406:            # Since body is a new indent level, remove spurious leading whitespace.
2407:            normalize_prefix(leaves[0], inside_brackets=True)
2408:            # Ensure a trailing comma for imports, but be careful not to add one after
2409:            # any comments.
2410:            if original.is_import:
2411:                for i in range(len(leaves) - 1, -1, -1):
2412:                    if leaves[i].type == STANDALONE_COMMENT:
2413:                        continue
2414:                    elif leaves[i].type == token.COMMA:
2415:                        break
2416:                    else:
2417:                        leaves.insert(i + 1, Leaf(token.COMMA, ","))
2418:                        break
2419:    # Populate the line
2420:    for leaf in leaves:
2421:        result.append(leaf, preformatted=True)
2422:        for comment_after in original.comments_after(leaf):
2423:            result.append(comment_after, preformatted=True)
2424:    if is_body:
2425:        result.should_explode = should_explode(result, opening_bracket)
2426:    return result
2427:
2428:
2429:def dont_increase_indentation(split_func: SplitFunc) -> SplitFunc:
2430:    """Normalize prefix of the first leaf in every line returned by `split_func`.
2431:
2432:    This is a decorator over relevant split functions.
2433:    """
2434:
2435:    @wraps(split_func)
2436:    def split_wrapper(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2437:        for l in split_func(line, features):
2438:            normalize_prefix(l.leaves[0], inside_brackets=True)
2439:            yield l
2440:
2441:    return split_wrapper
2442:
2443:
2444:@dont_increase_indentation
2445:def delimiter_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2446:    """Split according to delimiters of the highest priority.
2447:
2448:    If the appropriate Features are given, the split will add trailing commas
2449:    also in function signatures and calls that contain `*` and `**`.
2450:    """
2451:    try:
2452:        last_leaf = line.leaves[-1]
2453:    except IndexError:
2454:        raise CannotSplit("Line empty")
2455:
2456:    bt = line.bracket_tracker
2457:    try:
2458:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2459:    except ValueError:
2460:        raise CannotSplit("No delimiters found")
2461:
2462:    if delimiter_priority == DOT_PRIORITY:
2463:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2464:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2465:
2466:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2467:    lowest_depth = sys.maxsize
2468:    trailing_comma_safe = True
2469:

Calling tool: grepTool
normalize_invisible_parens\([^)]*\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1582:        normalize_invisible_parens(node, parens_after=parens)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1540:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1541:                normalize_string_quotes(node)
1542:            if node.type == token.NUMBER:
1543:                normalize_numeric_literal(node)
1544:            if node.type not in WHITESPACE:
1545:                self.current_line.append(node)
1546:        yield from super().visit_default(node)
1547:
1548:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1549:        """Increase indentation level, maybe yield a line."""
1550:        # In blib2to3 INDENT never holds comments.
1551:        yield from self.line(+1)
1552:        yield from self.visit_default(node)
1553:
1554:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1555:        """Decrease indentation level, maybe yield a line."""
1556:        # The current line might still wait for trailing comments.  At DEDENT time
1557:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1558:        # Emit the line then.
1559:        yield from self.line()
1560:
1561:        # While DEDENT has no value, its prefix may contain standalone comments
1562:        # that belong to the current indentation level.  Get 'em.
1563:        yield from self.visit_default(node)
1564:
1565:        # Finally, emit the dedent.
1566:        yield from self.line(-1)
1567:
1568:    def visit_stmt(
1569:        self, node: Node, keywords: Set[str], parens: Set[str]
1570:    ) -> Iterator[Line]:
1571:        """Visit a statement.
1572:
1573:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1574:        `def`, `with`, `class`, `assert` and assignments.
1575:
1576:        The relevant Python language `keywords` for a given statement will be
1577:        NAME leaves within it. This methods puts those on a separate line.
1578:
1579:        `parens` holds a set of string leaf values immediately after which
1580:        invisible parens should be put.
1581:        """
1582:        normalize_invisible_parens(node, parens_after=parens)
1583:        for child in node.children:
1584:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1585:                yield from self.line()
1586:
1587:            yield from self.visit(child)
1588:
1589:    def visit_suite(self, node: Node) -> Iterator[Line]:
1590:        """Visit a suite."""
1591:        if self.is_pyi and is_stub_suite(node):
1592:            yield from self.visit(node.children[2])
1593:        else:
1594:            yield from self.visit_default(node)
1595:
1596:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1597:        """Visit a statement without nested statements."""
1598:        is_suite_like = node.parent and node.parent.type in STATEMENT
1599:        if is_suite_like:
1600:            if self.is_pyi and is_stub_body(node):
1601:                yield from self.visit_default(node)
1602:            else:
1603:                yield from self.line(+1)
1604:                yield from self.visit_default(node)
1605:                yield from self.line(-1)
1606:
1607:        else:
1608:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1609:                yield from self.line()
1610:            yield from self.visit_default(node)
1611:
1612:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1613:        """Visit `async def`, `async for`, `async with`."""
1614:        yield from self.line()
1615:
1616:        children = iter(node.children)
1617:        for child in children:
1618:            yield from self.visit(child)
1619:

Calling tool: grepTool
def visit_.*expr_stmt|visit_stmt\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1568:    def visit_stmt(

Calling tool: grepTool
visit_stmt\(self, node: Node, keywords: Set\[str\], parens: Set\[str\]\)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_.*\(self, node: Node.*parens.*Set\[str\]
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def visit_[a-z_]*\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:798:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:809:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1518:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1568:    def visit_stmt(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1589:    def visit_suite(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1596:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1612:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1627:    def visit_decorators(self, node: Node) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1620:            if child.type == token.ASYNC:
1621:                break
1622:
1623:        internal_stmt = next(children)
1624:        for child in internal_stmt.children:
1625:            yield from self.visit(child)
1626:
1627:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1628:        """Visit decorators."""
1629:        for child in node.children:
1630:            yield from self.line()
1631:            yield from self.visit(child)
1632:
1633:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1634:        """Remove a semicolon and put the other statement on a separate line."""
1635:        yield from self.line()
1636:
1637:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1638:        """End of file. Process outstanding comments and end with a newline."""
1639:        yield from self.visit_default(leaf)
1640:        yield from self.line()
1641:
1642:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1643:        if not self.current_line.bracket_tracker.any_open_brackets():
1644:            yield from self.line()
1645:        yield from self.visit_default(leaf)
1646:
1647:    def __attrs_post_init__(self) -> None:
1648:        """You are in a twisty little maze of passages."""
1649:        v = self.visit_stmt
1650:        Ø: Set[str] = set()
1651:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1652:        self.visit_if_stmt = partial(
1653:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1654:        )
1655:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1656:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1657:        self.visit_try_stmt = partial(
1658:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1659:        )
1660:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1661:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1662:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1663:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1664:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1665:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1666:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1667:        self.visit_del_stmt = partial(v, keywords=Ø, parens={"del"})
1668:        self.visit_async_funcdef = self.visit_async_stmt
1669:        self.visit_decorated = self.visit_decorators
1670:
1671:
1672:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1673:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1674:OPENING_BRACKETS = set(BRACKET.keys())
1675:CLOSING_BRACKETS = set(BRACKET.values())
1676:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1677:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1678:
1679:
1680:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa: C901
1681:    """Return whitespace prefix if needed for the given `leaf`.
1682:
1683:    `complex_subscript` signals whether the given leaf is part of a subscription
1684:    which has non-trivial arguments, like arithmetic expressions or function calls.
1685:    """
1686:    NO = ""
1687:    SPACE = " "
1688:    DOUBLESPACE = "  "
1689:    t = leaf.type
1690:    p = leaf.parent
1691:    v = leaf.value
1692:    if t in ALWAYS_NO_SPACE:
1693:        return NO
1694:
1695:    if t == token.COMMENT:
1696:        return DOUBLESPACE
1697:
1698:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1699:    if t == token.COLON and p.type not in {
1700:        syms.subscript,
1701:        syms.subscriptlist,
1702:        syms.sliceop,
1703:    }:
1704:        return NO
1705:
1706:    prev = leaf.prev_sibling
1707:    if not prev:
1708:        prevp = preceding_leaf(p)
1709:        if not prevp or prevp.type in OPENING_BRACKETS:
1710:            return NO
1711:
1712:        if t == token.COLON:
1713:            if prevp.type == token.COLON:
1714:                return NO
1715:
1716:            elif prevp.type != token.COMMA and not complex_subscript:
1717:                return NO
1718:
1719:            return SPACE
1720:
1721:        if prevp.type == token.EQUAL:
1722:            if prevp.parent:
1723:                if prevp.parent.type in {
1724:                    syms.arglist,
1725:                    syms.argument,
1726:                    syms.parameters,
1727:                    syms.varargslist,
1728:                }:
1729:                    return NO
1730:
1731:                elif prevp.parent.type == syms.typedargslist:
1732:                    # A bit hacky: if the equal sign has whitespace, it means we
1733:                    # previously found it's a typed argument.  So, we're using
1734:                    # that, too.
1735:                    return prevp.prefix
1736:
1737:        elif prevp.type in STARS:
1738:            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1739:                return NO
1740:
1741:        elif prevp.type == token.COLON:
1742:            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:
1743:                return SPACE if complex_subscript else NO
1744:
1745:        elif (
1746:            prevp.parent
1747:            and prevp.parent.type == syms.factor
1748:            and prevp.type in MATH_OPERATORS
1749:        ):
1750:            return NO
1751:
1752:        elif (
1753:            prevp.type == token.RIGHTSHIFT
1754:            and prevp.parent
1755:            and prevp.parent.type == syms.shift_expr
1756:            and prevp.prev_sibling
1757:            and prevp.prev_sibling.type == token.NAME
1758:            and prevp.prev_sibling.value == "print"  # type: ignore
1759:        ):
1760:            # Python 2 print chevron
1761:            return NO
1762:
1763:    elif prev.type in OPENING_BRACKETS:
1764:        return NO
1765:
1766:    if p.type in {syms.parameters, syms.arglist}:
1767:        # untyped function signatures or calls
1768:        if not prev or prev.type != token.COMMA:
1769:            return NO
1770:
1771:    elif p.type == syms.varargslist:
1772:        # lambdas
1773:        if prev and prev.type != token.COMMA:
1774:            return NO
1775:
1776:    elif p.type == syms.typedargslist:
1777:        # typed function signatures
1778:        if not prev:
1779:            return NO
1780:
1781:        if t == token.EQUAL:
1782:            if prev.type != syms.tname:
1783:                return NO
1784:
1785:        elif prev.type == token.EQUAL:
1786:            # A bit hacky: if the equal sign has whitespace, it means we
1787:            # previously found it's a typed argument.  So, we're using that, too.
1788:            return prev.prefix
1789:
1790:        elif prev.type != token.COMMA:
1791:            return NO
1792:
1793:    elif p.type == syms.tname:
1794:        # type names
1795:        if not prev:
1796:            prevp = preceding_leaf(p)
1797:            if not prevp or prevp.type != token.COMMA:
1798:                return NO
1799:
1800:    elif p.type == syms.trailer:
1801:        # attributes and calls
1802:        if t == token.LPAR or t == token.RPAR:
1803:            return NO
1804:
1805:        if not prev:
1806:            if t == token.DOT:
1807:                prevp = preceding_leaf(p)
1808:                if not prevp or prevp.type != token.NUMBER:
1809:                    return NO
1810:
1811:            elif t == token.LSQB:
1812:                return NO
1813:
1814:        elif prev.type != token.COMMA:
1815:            return NO
1816:
1817:    elif p.type == syms.argument:
1818:        # single argument
1819:        if t == token.EQUAL:
1820:            return NO
1821:
1822:        if not prev:
1823:            prevp = preceding_leaf(p)
1824:            if not prevp or prevp.type == token.LPAR:
1825:                return NO
1826:
1827:        elif prev.type in {token.EQUAL} | STARS:
1828:            return NO
1829:
1830:    elif p.type == syms.decorator:
1831:        # decorators
1832:        return NO
1833:
1834:    elif p.type == syms.dotted_name:
1835:        if prev:
1836:            return NO
1837:
1838:        prevp = preceding_leaf(p)
1839:        if not prevp or prevp.type == token.AT or prevp.type == token.DOT:
1840:            return NO
1841:
1842:    elif p.type == syms.classdef:
1843:        if t == token.LPAR:
1844:            return NO
1845:
1846:        if prev and prev.type == token.LPAR:
1847:            return NO
1848:
1849:    elif p.type in {syms.subscript, syms.sliceop}:
1850:        # indexing
1851:        if not prev:
1852:            assert p.parent is not None, "subscripts are always parented"
1853:            if p.parent.type == syms.subscriptlist:
1854:                return SPACE
1855:
1856:            return NO
1857:
1858:        elif not complex_subscript:
1859:            return NO
1860:
1861:    elif p.type == syms.atom:
1862:        if prev and t == token.DOT:
1863:            # dots, but not the first one.
1864:            return NO
1865:
1866:    elif p.type == syms.dictsetmaker:
1867:        # dict unpacking
1868:        if prev and prev.type == token.DOUBLESTAR:
1869:            return NO
1870:
1871:    elif p.type in {syms.factor, syms.star_expr}:
1872:        # unary ops
1873:        if not prev:
1874:            prevp = preceding_leaf(p)
1875:            if not prevp or prevp.type in OPENING_BRACKETS:
1876:                return NO
1877:
1878:            prevp_parent = prevp.parent
1879:            assert prevp_parent is not None
1880:            if prevp.type == token.COLON and prevp_parent.type in {
1881:                syms.subscript,
1882:                syms.sliceop,
1883:            }:
1884:                return NO
1885:
1886:            elif prevp.type == token.EQUAL and prevp_parent.type == syms.argument:
1887:                return NO
1888:
1889:        elif t in {token.NAME, token.NUMBER, token.STRING}:
1890:            return NO
1891:
1892:    elif p.type == syms.import_from:
1893:        if t == token.DOT:
1894:            if prev and prev.type == token.DOT:
1895:                return NO
1896:
1897:        elif t == token.NAME:
1898:            if v == "import":
1899:                return SPACE
1900:
1901:            if prev and prev.type == token.DOT:
1902:                return NO
1903:
1904:    elif p.type == syms.sliceop:
1905:        return NO
1906:
1907:    return SPACE
1908:
1909:
1910:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1911:    """Return the first leaf that precedes `node`, if any."""
1912:    while node:
1913:        res = node.prev_sibling
1914:        if res:
1915:            if isinstance(res, Leaf):
1916:                return res
1917:
1918:            try:
1919:                return list(res.leaves())[-1]

Calling tool: grepTool
ASSIGNMENTS\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:911:ASSIGNMENTS = {

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
900:    syms.comparison,
901:    syms.star_expr,
902:    syms.expr,
903:    syms.xor_expr,
904:    syms.and_expr,
905:    syms.shift_expr,
906:    syms.arith_expr,
907:    syms.trailer,
908:    syms.term,
909:    syms.power,
910:}
911:ASSIGNMENTS = {
912:    "=",
913:    "+=",
914:    "-=",
915:    "*=",
916:    "@=",
917:    "/=",
918:    "%=",
919:    "&=",
920:    "|=",
921:    "^=",
922:    "<<=",
923:    ">>=",
924:    "**=",
925:    "//=",
926:}
927:COMPREHENSION_PRIORITY = 20
928:COMMA_PRIORITY = 18
929:TERNARY_PRIORITY = 16
930:LOGIC_PRIORITY = 14
931:STRING_PRIORITY = 12
932:COMPARATOR_PRIORITY = 10
933:MATH_PRIORITIES = {
934:    token.VBAR: 9,
935:    token.CIRCUMFLEX: 8,
936:    token.AMPER: 7,
937:    token.LEFTSHIFT: 6,
938:    token.RIGHTSHIFT: 6,
939:    token.PLUS: 5,
940:    token.MINUS: 5,
941:    token.STAR: 4,
942:    token.SLASH: 4,
943:    token.DOUBLESLASH: 4,
944:    token.PERCENT: 4,
945:    token.AT: 4,
946:    token.TILDE: 3,
947:    token.DOUBLESTAR: 2,
948:}
949:DOT_PRIORITY = 1
950:
951:
952:@dataclass
953:class BracketTracker:
954:    """Keeps track of brackets on a line."""
955:
956:    depth: int = 0
957:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
958:    delimiters: Dict[LeafID, Priority] = Factory(dict)
959:    previous: Optional[Leaf] = None

Calling tool: grepTool
trailing comma|trailing_comma|should_explode
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/README:6:- backport of BPO-33064 that fixes parsing files with trailing commas after
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/Grammar.txt:151:# contains comma which clashes with trailing comma in arglist.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:81:                                  input files.  This will put trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:233:that a trailing comma is always added.  Such formatting produces smaller
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:253:include_trailing_comma=True
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:331:*Black* will add trailing commas to expressions that are split
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:335:Unnecessary trailing commas are removed if an expression fits in one
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:341:One exception to removing trailing commas is tuple expressions with
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:347:One exception to adding trailing commas is function signatures
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:348:containing `*`, `*args`, or `**kwargs`.  In this case a trailing comma
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:350:already 3.6+ only and use trailing commas in this situation.  If you
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:353:if you'd like a trailing comma in this situation and *Black* didn't
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:961:* fix feature detection for trailing commas in function definitions and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1012:* trailing comma is now added to single imports that don't fit on a line (#250)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1180:* fixed an invalid trailing comma sometimes left in imports (#185)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1191:  unpacking. This fixed non-deterministic formatting if trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1216:  fixes multiplication making expressions "unsafe" for trailing commas (#132)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1221:* *Black* now splits imports like "Mode 3 + trailing comma" of isort (#127)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1302:* don't remove single trailing commas from square bracket indexing
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1336:* remove a trailing comma if there is a single argument to a call
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1355:* only put trailing commas in function signatures and calls if it's
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:258:        "trailing commas in function signatures and calls also after *args and "
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1093:    should_explode: bool = False
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1119:            self.maybe_remove_trailing_comma(leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1229:                # When trailing commas are inserted by Black for consistency, comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1231:                # rendering will still be correct).  So we ignore trailing commas.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1254:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1255:        """Remove trailing comma if there is one and it's safe."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1264:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1270:                self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1276:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1303:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1332:    def remove_trailing_comma(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1333:        """Remove the trailing comma and moves the comments attached to it."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1334:        trailing_comma = self.leaves.pop()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1335:        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1337:            trailing_comma_comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2189:        and not line.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2323:        not body.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2399:    has its first leaf's prefix normalized and a trailing comma added when expected.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2408:            # Ensure a trailing comma for imports, but be careful not to add one after
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2425:        result.should_explode = should_explode(result, opening_bracket)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2448:    If the appropriate Features are given, the split will add trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2468:    trailing_comma_safe = True
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2490:                trailing_comma_safe = (
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2491:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_DEF in features
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2494:                trailing_comma_safe = (
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2495:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_CALL in features
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2505:            trailing_comma_safe
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
3008:    bt = BracketTracker()
3009:    for c in node.children[1:-1]:
3010:        if isinstance(c, Leaf):
3011:            bt.mark(c)
3012:        else:
3013:            for leaf in c.leaves():
3014:                bt.mark(leaf)
3015:    try:
3016:        return bt.max_delimiter_priority()
3017:
3018:    except ValueError:
3019:        return 0
3020:
3021:
3022:def ensure_visible(leaf: Leaf) -> None:
3023:    """Make sure parentheses are visible.
3024:
3025:    They could be invisible as part of some statements (see
3026:    :func:`normalize_invible_parens` and :func:`visit_import_from`).
3027:    """
3028:    if leaf.type == token.LPAR:
3029:        leaf.value = "("
3030:    elif leaf.type == token.RPAR:
3031:        leaf.value = ")"
3032:
3033:
3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:
3035:    """Should `line` immediately be split with `delimiter_split()` after RHS?"""
3036:
3037:    if not (
3038:        opening_bracket.parent
3039:        and opening_bracket.parent.type in {syms.atom, syms.import_from}
3040:        and opening_bracket.value in "[{("
3041:    ):
3042:        return False
3043:
3044:    try:
3045:        last_leaf = line.leaves[-1]
3046:        exclude = {id(last_leaf)} if last_leaf.type == token.COMMA else set()
3047:        max_priority = line.bracket_tracker.max_delimiter_priority(exclude=exclude)
3048:    except (IndexError, ValueError):
3049:        return False
3050:
3051:    return max_priority == COMMA_PRIORITY
3052:
3053:
3054:def get_features_used(node: Node) -> Set[Feature]:
3055:    """Return a set of (relatively) new Python features used in this file.
3056:
3057:    Currently looking for:
3058:    - f-strings;
3059:    - underscores in numeric literals; and
3060:    - trailing commas after * or ** in function signatures and calls.
3061:    """
3062:    features: Set[Feature] = set()
3063:    for n in node.pre_order():
3064:        if n.type == token.STRING:
3065:            value_head = n.value[:2]  # type: ignore
3066:            if value_head in {'f"', 'F"', "f'", "F'", "rf", "fr", "RF", "FR"}:
3067:                features.add(Feature.F_STRINGS)
3068:
3069:        elif n.type == token.NUMBER:
3070:            if "_" in n.value:  # type: ignore
3071:                features.add(Feature.NUMERIC_UNDERSCORES)
3072:
3073:        elif (
3074:            n.type in {syms.typedargslist, syms.arglist}
3075:            and n.children
3076:            and n.children[-1].type == token.COMMA
3077:        ):
3078:            if n.type == syms.typedargslist:
3079:                feature = Feature.TRAILING_COMMA_IN_DEF
3080:            else:
3081:                feature = Feature.TRAILING_COMMA_IN_CALL
3082:
3083:            for ch in n.children:
3084:                if ch.type in STARS:
3085:                    features.add(feature)
3086:
3087:                if ch.type == syms.argument:
3088:                    for argch in ch.children:
3089:                        if argch.type in STARS:
3090:                            features.add(feature)
3091:
3092:    return features
3093:
3094:
3095:def detect_target_versions(node: Node) -> Set[TargetVersion]:
3096:    """Detect the version to target based on the nodes used."""
3097:    features = get_features_used(node)
3098:    return {
3099:        version for version in TargetVersion if features <= VERSION_TO_FEATURES[version]
3100:    }
3101:
3102:
3103:def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[Set[LeafID]]:
3104:    """Generate sets of closing bracket IDs that should be omitted in a RHS.
3105:
3106:    Brackets can be omitted if the entire trailer up to and including
3107:    a preceding closing bracket fits in one line.

Calling tool: grepTool
add trailing comma|trailing comma is now added|insert.*trailing comma|ensure a trailing comma|should_explode
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:331:*Black* will add trailing commas to expressions that are split
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1012:* trailing comma is now added to single imports that don't fit on a line (#250)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1093:    should_explode: bool = False
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2189:        and not line.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2323:        not body.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2425:        result.should_explode = should_explode(result, opening_bracket)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2448:    If the appropriate Features are given, the split will add trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/docs/reference/reference_functions.rst:172:.. autofunction:: black.should_explode

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2440:
2441:    return split_wrapper
2442:
2443:
2444:@dont_increase_indentation
2445:def delimiter_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2446:    """Split according to delimiters of the highest priority.
2447:
2448:    If the appropriate Features are given, the split will add trailing commas
2449:    also in function signatures and calls that contain `*` and `**`.
2450:    """
2451:    try:
2452:        last_leaf = line.leaves[-1]
2453:    except IndexError:
2454:        raise CannotSplit("Line empty")
2455:
2456:    bt = line.bracket_tracker
2457:    try:
2458:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2459:    except ValueError:
2460:        raise CannotSplit("No delimiters found")
2461:
2462:    if delimiter_priority == DOT_PRIORITY:
2463:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2464:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2465:
2466:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2467:    lowest_depth = sys.maxsize
2468:    trailing_comma_safe = True
2469:
2470:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2471:        """Append `leaf` to current line or to new line if appending impossible."""
2472:        nonlocal current_line
2473:        try:
2474:            current_line.append_safe(leaf, preformatted=True)
2475:        except ValueError:
2476:            yield current_line
2477:
2478:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2479:            current_line.append(leaf)
2480:
2481:    for leaf in line.leaves:
2482:        yield from append_to_line(leaf)
2483:
2484:        for comment_after in line.comments_after(leaf):
2485:            yield from append_to_line(comment_after)
2486:
2487:        lowest_depth = min(lowest_depth, leaf.bracket_depth)
2488:        if leaf.bracket_depth == lowest_depth:
2489:            if is_vararg(leaf, within={syms.typedargslist}):
2490:                trailing_comma_safe = (
2491:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_DEF in features
2492:                )
2493:            elif is_vararg(leaf, within={syms.arglist, syms.argument}):
2494:                trailing_comma_safe = (
2495:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_CALL in features
2496:                )
2497:
2498:        leaf_priority = bt.delimiters.get(id(leaf))
2499:        if leaf_priority == delimiter_priority:
2500:            yield current_line
2501:
2502:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2503:    if current_line:
2504:        if (
2505:            trailing_comma_safe
2506:            and delimiter_priority == COMMA_PRIORITY
2507:            and current_line.leaves[-1].type != token.COMMA
2508:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2509:        ):
2510:            current_line.append(Leaf(token.COMMA, ","))
2511:        yield current_line
2512:
2513:
2514:@dont_increase_indentation
2515:def standalone_comment_split(
2516:    line: Line, features: Collection[Feature] = ()
2517:) -> Iterator[Line]:
2518:    """Split standalone comments from the rest of the line."""
2519:    if not line.contains_standalone_comments(0):
2520:        raise CannotSplit("Line does not have any standalone comments")
2521:
2522:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2523:
2524:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2525:        """Append `leaf` to current line or to new line if appending impossible."""
2526:        nonlocal current_line
2527:        try:
2528:            current_line.append_safe(leaf, preformatted=True)
2529:        except ValueError:
2530:            yield current_line
2531:
2532:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2533:            current_line.append(leaf)
2534:
2535:    for leaf in line.leaves:
2536:        yield from append_to_line(leaf)
2537:
2538:        for comment_after in line.comments_after(leaf):
2539:            yield from append_to_line(comment_after)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test data `tests/data/tupleassign.py` expects visible parentheses around the LHS tuple and no backslash. The code change in `normalize_invisible_parens` adds optional parentheses around the LHS (testlist_star_expr) and right-hand splitting ensures they become visible when splitting, matching the expected output in `test_tuple_assign`. Prefix handling is also correctly preserved.


Todo item 11 of 14 is correct
description: 'In test_tuple_assign, verify that the expected formatted output has parentheses around the LHS names and does not rely on a backslash for line continuation.'
Validating todo item 12 of 14
description: 'If comments or leading whitespace precede the LHS tuple in the test, verify the expected output preserves them before the opening '(', consistent with moving the prefix to the wrapper node.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: globTool
**/*test*tuple*assign*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: grepTool
test_tuple_assign
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )

Calling tool: globTool
**/*tupleassign*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: grepTool
elif not \(isinstance\(child, Leaf\) and is_multiline_string\(child\)\):
Matched content:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py normalize_invisible_parens(), when wrapping the LHS testlist_star_expr (index==0) the code now moves the child prefix to the new wrapper Node (lines ~2768–2772). This ensures any leading comments/whitespace on the LHS appear before the inserted '(' as required.


Todo item 12 of 14 is correct
description: 'If comments or leading whitespace precede the LHS tuple in the test, verify the expected output preserves them before the opening '(', consistent with moving the prefix to the wrapper node.'
Validating todo item 13 of 14
description: 'Scan the modified block to ensure no unrelated formatting is applied to siblings (e.g., RHS or trailing commas). The wrapping should be limited to replacing the first child with an atom node containing invisible parens.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2700:        text = format_float_or_int_string(text)
2701:    leaf.value = text
2702:
2703:
2704:def format_float_or_int_string(text: str) -> str:
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens(), check_lpar is only set when index==0 and the child is a testlist_star_expr. The subsequent wrap replaces only that first child with an atom containing invisible parens, preserving the original prefix on the new wrapper. After this iteration, check_lpar resets to False (child is a Node, not a Leaf), so siblings (RHS, trailing commas) are untouched.


Todo item 13 of 14 is correct
description: 'Scan the modified block to ensure no unrelated formatting is applied to siblings (e.g., RHS or trailing commas). The wrapping should be limited to replacing the first child with an atom node containing invisible parens.'
Validating todo item 14 of 14
description: 'Check that shadowing of the 'index' variable inside the wrapping block (index = child.remove() or 0) does not affect subsequent logic in the same iteration (no further reliance on the loop's index variable after this assignment).'
Calling tool: grepTool
def normalize_invisible_parens\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:
2833:            previous_consumed = comment.consumed
2834:
2835:    return False
2836:
2837:
2838:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2839:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2840:
2841:    Stops at the end of the block.
2842:    """
2843:    container: Optional[LN] = container_of(leaf)
2844:    while container is not None and container.type != token.ENDMARKER:
2845:        for comment in list_comments(container.prefix, is_endmarker=False):
2846:            if comment.value in FMT_ON:
2847:                return
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Reviewed normalize_invisible_parens: after reassigning `index = child.remove() or 0`, the only subsequent use of `index` is the immediate insert. The remaining logic in that iteration doesn’t reference `index` (the if/elif chain is exclusive, ends with setting `check_lpar` based on `child`), and the next loop iteration resets `index`. No reliance on the original loop index after reassignment.


Todo item 14 of 14 is correct
description: 'Check that shadowing of the 'index' variable inside the wrapping block (index = child.remove() or 0) does not affect subsequent logic in the same iteration (no further reliance on the loop's index variable after this assignment).'
Validating todo item 1 of 14
description: 'In black.py, locate normalize_invisible_parens(). Verify that at the start of the for-loop over node.children, a new condition sets check_lpar = True when index == 0 and child is a Node with type syms.testlist_star_expr.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s normalize_invisible_parens(), at the beginning of the for-loop (lines 2729-2735), there is an added condition that checks index == 0, child is a Node, and child.type == syms.testlist_star_expr, then sets check_lpar = True. This matches the todo requirement.

Todo item 1 of 14 is correct
description: 'In black.py, locate normalize_invisible_parens(). Verify that at the start of the for-loop over node.children, a new condition sets check_lpar = True when index == 0 and child is a Node with type syms.testlist_star_expr.'

Validating todo item 2 of 14
description: 'Confirm the new check (index == 0 and child.type == syms.testlist_star_expr) is executed before the subsequent 'if check_lpar:' block so it affects handling of that same first child in the current iteration.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2729–2735 set check_lpar=True when index==0 and child.type==syms.testlist_star_expr, and the subsequent if check_lpar: block starts at line 2737 in the same loop iteration, so the first child is handled immediately.

Todo item 2 of 14 is correct
description: 'Confirm the new check (index == 0 and child.type == syms.testlist_star_expr) is executed before the subsequent 'if check_lpar:' block so it affects handling of that same first child in the current iteration.'

Validating todo item 3 of 14
description: 'Within normalize_invisible_parens(), verify that when wrapping is performed, the code constructs Leaf(token.LPAR, "") and Leaf(token.RPAR, "") and creates new_child = Node(syms.atom, [lpar, child, rpar]).'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s normalize_invisible_parens(), the wrapping branch (lines ~2765-2772) constructs lpar = Leaf(token.LPAR, ""), rpar = Leaf(token.RPAR, ""), and creates new_child = Node(syms.atom, [lpar, child, rpar]) before inserting it, satisfying the requirement.

Todo item 3 of 14 is correct
description: 'Within normalize_invisible_parens(), verify that when wrapping is performed, the code constructs Leaf(token.LPAR, "") and Leaf(token.RPAR, "") and creates new_child = Node(syms.atom, [lpar, child, rpar]).'

Validating todo item 4 of 14
description: 'Verify that the child's prefix is preserved correctly when wrapping: the code saves prefix = child.prefix, sets child.prefix = "", sets new_child.prefix = prefix, then inserts new_child back into the parent.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, when wrapping the child (non-multiline string branch), the code saves prefix = child.prefix, sets child.prefix = "", creates new_child, assigns new_child.prefix = prefix, and inserts new_child. Verified at lines 2767-2772.

Todo item 4 of 14 is correct
description: 'Verify that the child's prefix is preserved correctly when wrapping: the code saves prefix = child.prefix, sets child.prefix = "", sets new_child.prefix = prefix, then inserts new_child back into the parent.'

Validating todo item 5 of 14
description: 'Check that node.insert_child() uses the index returned by child.remove() (i.e., index = child.remove() or 0) to reinsert the wrapper at the original position, preserving sibling order.'

Calling tool: grepTool
def normalize_invisible_parens\(node: Node, parens_after: Set\[str\]\) -> None:
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens, the code sets index = child.remove() or 0 and then calls node.insert_child(index, ...) to reinsert the new wrapper node at the original position. Verified at lines 2742-2743 and 2767-2772 of black.py.

Todo item 5 of 14 is correct
description: 'Check that node.insert_child() uses the index returned by child.remove() (i.e., index = child.remove() or 0) to reinsert the wrapper at the original position, preserving sibling order.'

Validating todo item 6 of 14
description: 'Ensure that the end-of-loop assignment check_lpar = isinstance(child, Leaf) and child.value in parens_after remains, so the special-case change does not alter behavior for subsequent children.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: grepTool
check_lpar\s*=\s*isinstance\(child, Leaf\)\s*and\s*child\.value\s*in\s*parens_after
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, the end-of-loop assignment remains: `check_lpar = isinstance(child, Leaf) and child.value in parens_after` (line ~2774). This ensures the special-case addition does not alter behavior for subsequent children.

Todo item 6 of 14 is correct
description: 'Ensure that the end-of-loop assignment check_lpar = isinstance(child, Leaf) and child.value in parens_after remains, so the special-case change does not alter behavior for subsequent children.'

Validating todo item 7 of 14
description: 'Verify that the special-case only triggers for the very first child (index == 0), ensuring the change only targets the LHS of an assignment and not the RHS or later elements.'

Calling tool: grepTool
def normalize_invisible_parens\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens, the new special-case sets check_lpar to True only when index == 0 and child is a testlist_star_expr. The check is evaluated immediately in the same iteration and then check_lpar is reset at the end of the loop based on the current child, preventing it from affecting later children (RHS).

Todo item 7 of 14 is correct
description: 'Verify that the special-case only triggers for the very first child (index == 0), ensuring the change only targets the LHS of an assignment and not the RHS or later elements.'

Validating todo item 8 of 14
description: 'Confirm that if the first child is already an atom (already parenthesized), the code path 'if child.type == syms.atom' calls maybe_make_parens_invisible_in_atom(child, parent=node), preventing double-wrapping.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,

Calling tool: grepTool
def maybe_make_parens_invisible_in_atom\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)
2865:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2866:    ):
2867:        return False
2868:
2869:    first = node.children[0]
2870:    last = node.children[-1]
2871:    if first.type == token.LPAR and last.type == token.RPAR:
2872:        # make parentheses invisible
2873:        first.value = ""  # type: ignore
2874:        last.value = ""  # type: ignore
2875:        if len(node.children) > 1:
2876:            maybe_make_parens_invisible_in_atom(node.children[1], parent=parent)
2877:        return False
2878:
2879:    return True
2880:
2881:
2882:def is_empty_tuple(node: LN) -> bool:
2883:    """Return True if `node` holds an empty tuple."""
2884:    return (
2885:        node.type == syms.atom
2886:        and len(node.children) == 2
2887:        and node.children[0].type == token.LPAR
2888:        and node.children[1].type == token.RPAR
2889:    )
2890:
2891:
2892:def is_one_tuple(node: LN) -> bool:
2893:    """Return True if `node` holds a tuple with one element, with or without parens."""
2894:    if node.type == syms.atom:
2895:        if len(node.children) != 3:
2896:            return False
2897:
2898:        lpar, gexp, rpar = node.children
2899:        if not (
2900:            lpar.type == token.LPAR
2901:            and gexp.type == syms.testlist_gexp
2902:            and rpar.type == token.RPAR
2903:        ):
2904:            return False
2905:
2906:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2907:
2908:    return (
2909:        node.type in IMPLICIT_TUPLE
2910:        and len(node.children) == 2
2911:        and node.children[1].type == token.COMMA
2912:    )
2913:
2914:
2915:def is_yield(node: LN) -> bool:
2916:    """Return True if `node` holds a `yield` or `yield from` expression."""
2917:    if node.type == syms.yield_expr:
2918:        return True
2919:
2920:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2921:        return True
2922:
2923:    if node.type != syms.atom:
2924:        return False
2925:
2926:    if len(node.children) != 3:
2927:        return False
2928:
2929:    lpar, expr, rpar = node.children
2930:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2931:        return is_yield(expr)
2932:
2933:    return False
2934:
2935:
2936:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2937:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2938:
2939:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2940:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2941:    extended iterable unpacking (PEP 3132) and additional unpacking
2942:    generalizations (PEP 448).
2943:    """
2944:    if leaf.type not in STARS or not leaf.parent:
2945:        return False
2946:
2947:    p = leaf.parent
2948:    if p.type == syms.star_expr:
2949:        # Star expressions are also used as assignment targets in extended
2950:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2951:        if not p.parent:
2952:            return False
2953:
2954:        p = p.parent
2955:
2956:    return p.type in within
2957:
2958:
2959:def is_multiline_string(leaf: Leaf) -> bool:
2960:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2961:    value = leaf.value.lstrip("furbFURB")
2962:    return value[:3] in {'"""', "'''"} and "\n" in value
2963:
2964:
2965:def is_stub_suite(node: Node) -> bool:
2966:    """Return True if `node` is a suite with a stub body."""
2967:    if (

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py within normalize_invisible_parens, when check_lpar is True and the current child is an atom, the code calls maybe_make_parens_invisible_in_atom(child, parent=node). That function makes existing parentheses invisible and returns False, so the caller does not wrap again, preventing double-wrapping. Verified at lines 2738–2743 and function definition lines 2854–2879.

Todo item 8 of 14 is correct
description: 'Confirm that if the first child is already an atom (already parenthesized), the code path 'if child.type == syms.atom' calls maybe_make_parens_invisible_in_atom(child, parent=node), preventing double-wrapping.'

Validating todo item 9 of 14
description: 'Verify that no new imports are required: syms, token, Node, and Leaf are already defined/imported in black.py and accessible within normalize_invisible_parens().'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: grepTool
\bsyms\b|\bNode\b|\bLeaf\b|\btoken\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/pyproject.lock:363:description = "Node.js virtual environment builder"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:9:_NL = Union[Node, Leaf]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:21:    parent: Optional[Node]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:39:    def leaves(self) -> Iterator[Leaf]: ...
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:46:class Node(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:53:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.pyi:61:    opening_bracket: Leaf
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:7:This is a very concrete parse tree; we need to keep every token and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:26:        # from .pgen2 import token // token.__dict__.items():
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:34:    Abstract base class for Node and Leaf.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:43:    type = None    # int: token number (< 256) or symbol number (>= 256)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:128:        while not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:204:class Node(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:257:        return Node(self.type, [ch.clone() for ch in self.children],
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:331:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:336:    _prefix = ""  # Whitespace and comments preceding this token in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:337:    lineno = 0    # Line where this token starts in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:338:    column = 0    # Column where this token tarts in the input
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:347:        Takes a type constant (a token number < 256), a string value, and an
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:361:        from .pgen2.token import tok_name
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:383:        return Leaf(self.type, self.value,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:401:        The whitespace and comments preceding this token in the input.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:412:    Convert raw node information to a Node or Leaf instance.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:424:        return Node(type, children, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:426:        return Leaf(type, value, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:434:    It looks for a specific node type (token or symbol), and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:446:    type = None     # Node type (token if < 256, symbol if >= 256)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:521:        The type, if given must be a token type (< 256).  If not given,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pytree.py:539:        if not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/PatternGrammar.txt:6:# - 'TOKEN' stands for any token (leaf node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/Grammar.txt:132:# "test '=' test" is really "keyword '=' test", but we have no such token.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pygram.py:10:from .pgen2 import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:11:    the token type (see token.py)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:12:    the token (a string)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:13:    the starting (row, column) indices of the token (a 2-tuple of ints)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:14:    the ending (row, column) indices of the token (a 2-tuple of ints)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:26:each time a new token is found."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:34:from blib2to3.pgen2.token import *
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:36:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:37:__all__ = [x for x in dir(token) if x[0] != '_'] + ["tokenize",
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:39:del token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:144:def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:148:        (srow, scol, erow, ecol, tok_name[type], repr(token)))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:160:    called once for each token, with five arguments, corresponding to the
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:192:            tok_type, token, start, end, line = t
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:194:            self.tokens.append(token)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:201:    def compat(self, token, iterable):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:205:        toknum, tokval = token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:319:    Each element returned by the iterable must be a token sequence
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:320:    with at least two elements, a token number and token value.  If

Calling tool: grepTool
\bsyms\b|\bNode\b|\bLeaf\b|\btoken\b
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black/black.py: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black/black.py: No such file or directory (os error 2)


Calling tool: grepTool
from .* import (.+\bNode\b.*\bLeaf\b|\bLeaf\b.*\bNode\b)|import .*\bNode\b|import .*\bLeaf\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:45:from blib2to3.pytree import Node, Leaf, type_repr

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum
6:from functools import lru_cache, partial, wraps
7:import io
8:import itertools
9:import logging
10:from multiprocessing import Manager, freeze_support
11:import os
12:from pathlib import Path
13:import pickle
14:import re
15:import signal
16:import sys
17:import tempfile
18:import tokenize
19:from typing import (
20:    Any,
21:    Callable,
22:    Collection,
23:    Dict,
24:    Generator,
25:    Generic,
26:    Iterable,
27:    Iterator,
28:    List,
29:    Optional,
30:    Pattern,
31:    Sequence,
32:    Set,
33:    Tuple,
34:    TypeVar,
35:    Union,
36:    cast,
37:)
38:
39:from appdirs import user_cache_dir
40:from attr import dataclass, evolve, Factory
41:import click
42:import toml
43:
44:# lib2to3 fork
45:from blib2to3.pytree import Node, Leaf, type_repr
46:from blib2to3 import pygram, pytree
47:from blib2to3.pgen2 import driver, token
48:from blib2to3.pgen2.grammar import Grammar
49:from blib2to3.pgen2.parse import ParseError
50:
51:
52:__version__ = "19.3b0"
53:DEFAULT_LINE_LENGTH = 88
54:DEFAULT_EXCLUDES = (
55:    r"/(\.eggs|\.git|\.hg|\.mypy_cache|\.nox|\.tox|\.venv|_build|buck-out|build|dist)/"
56:)
57:DEFAULT_INCLUDES = r"\.pyi?$"
58:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
59:
60:
61:# types
62:FileContent = str
63:Encoding = str
64:NewLine = str
65:Depth = int
66:NodeType = int
67:LeafID = int
68:Priority = int
69:Index = int
70:LN = Union[Leaf, Node]
71:SplitFunc = Callable[["Line", Collection["Feature"]], Iterator["Line"]]
72:Timestamp = float
73:FileSize = int
74:CacheInfo = Tuple[Timestamp, FileSize]
75:Cache = Dict[Path, CacheInfo]
76:out = partial(click.secho, bold=True, err=True)
77:err = partial(click.secho, fg="red", err=True)
78:
79:pygram.initialize(CACHE_DIR)
80:syms = pygram.python_symbols
81:
82:
83:class NothingChanged(UserWarning):
84:    """Raised when reformatted code is the same as source."""
85:
86:
87:class CannotSplit(Exception):
88:    """A readable split that fits the allotted line length is impossible."""
89:
90:
91:class InvalidInput(ValueError):
92:    """Raised when input source code fails all parse attempts."""
93:
94:
95:class WriteBack(Enum):
96:    NO = 0
97:    YES = 1
98:    DIFF = 2
99:    CHECK = 3
100:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2700:        text = format_float_or_int_string(text)
2701:    leaf.value = text
2702:
2703:
2704:def format_float_or_int_string(text: str) -> str:
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue

Calling tool: grepTool
^\s*token\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/pgen2/tokenize.py:482:                        token = line[start:pos]

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Confirmed in black.py: Node and Leaf are imported at line 45, token at line 47, and syms is assigned at line 80 from pygram.python_symbols. normalize_invisible_parens uses these names and they are in module scope, so no new imports are required.

Todo item 9 of 14 is correct
description: 'Verify that no new imports are required: syms, token, Node, and Leaf are already defined/imported in black.py and accessible within normalize_invisible_parens().'

Validating todo item 10 of 14
description: 'Open the test test_tuple_assign and confirm it includes a long LHS tuple unpacking assignment case that previously required a backslash continuation and now expects parentheses around the LHS.'

Calling tool: grepTool
test_tuple_assign\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )
600:            report.done(Path("f3"), black.Changed.CACHED)
601:            self.assertEqual(len(out_lines), 3)
602:            self.assertEqual(len(err_lines), 0)
603:            self.assertEqual(
604:                out_lines[-1], "f3 wasn't modified on disk since last run."
605:            )
606:            self.assertEqual(
607:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
608:            )
609:            self.assertEqual(report.return_code, 0)
610:            report.check = True
611:            self.assertEqual(report.return_code, 1)
612:            report.check = False
613:            report.failed(Path("e1"), "boom")
614:            self.assertEqual(len(out_lines), 3)
615:            self.assertEqual(len(err_lines), 1)
616:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
617:            self.assertEqual(
618:                unstyle(str(report)),
619:                "1 file reformatted, 2 files left unchanged, "
620:                "1 file failed to reformat.",
621:            )
622:            self.assertEqual(report.return_code, 123)
623:            report.done(Path("f3"), black.Changed.YES)
624:            self.assertEqual(len(out_lines), 4)
625:            self.assertEqual(len(err_lines), 1)
626:            self.assertEqual(out_lines[-1], "reformatted f3")
627:            self.assertEqual(
628:                unstyle(str(report)),
629:                "2 files reformatted, 2 files left unchanged, "
630:                "1 file failed to reformat.",
631:            )
632:            self.assertEqual(report.return_code, 123)
633:            report.failed(Path("e2"), "boom")
634:            self.assertEqual(len(out_lines), 4)
635:            self.assertEqual(len(err_lines), 2)
636:            self.assertEqual(err_lines[-1], "error: cannot format e2: boom")
637:            self.assertEqual(
638:                unstyle(str(report)),
639:                "2 files reformatted, 2 files left unchanged, "

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:57:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:import logging
4:from concurrent.futures import ThreadPoolExecutor
5:from contextlib import contextmanager, redirect_stderr
6:from functools import partial, wraps
7:from io import BytesIO, TextIOWrapper
8:import os
9:from pathlib import Path
10:import re
11:import sys
12:from tempfile import TemporaryDirectory
13:from typing import (
14:    Any,
15:    BinaryIO,
16:    Callable,
17:    Coroutine,
18:    Generator,
19:    List,
20:    Tuple,
21:    Iterator,
22:    TypeVar,
23:)
24:import unittest
25:from unittest.mock import patch, MagicMock
26:
27:from click import unstyle
28:from click.testing import CliRunner
29:
30:import black
31:from black import Feature, TargetVersion
32:
33:try:
34:    import blackd
35:    from aiohttp.test_utils import TestClient, TestServer
36:except ImportError:
37:    has_blackd_deps = False
38:else:
39:    has_blackd_deps = True
40:
41:ff = partial(black.format_file_in_place, mode=black.FileMode(), fast=True)
42:fs = partial(black.format_str, mode=black.FileMode())
43:THIS_FILE = Path(__file__)
44:THIS_DIR = THIS_FILE.parent
45:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
46:PY36_ARGS = [
47:    f"--target-version={version.name.lower()}" for version in black.PY36_VERSIONS
48:]
49:T = TypeVar("T")
50:R = TypeVar("R")
51:
52:
53:def dump_to_stderr(*output: str) -> str:
54:    return "\n" + "\n".join(output) + "\n"
55:
56:
57:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
58:    """read_data('test_name') -> 'input', 'output'"""
59:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
60:        name += ".py"
61:    _input: List[str] = []
62:    _output: List[str] = []
63:    base_dir = THIS_DIR / "data" if data else THIS_DIR
64:    with open(base_dir / name, "r", encoding="utf8") as test:
65:        lines = test.readlines()
66:    result = _input
67:    for line in lines:
68:        line = line.replace(EMPTY_LINE, "")
69:        if line.rstrip() == "# output":
70:            result = _output
71:            continue
72:
73:        result.append(line)
74:    if _input and not _output:
75:        # If there's no output marker, treat the entire file as already pre-formatted.
76:        _output = _input[:]
77:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
78:
79:
80:@contextmanager
81:def cache_dir(exists: bool = True) -> Iterator[Path]:
82:    with TemporaryDirectory() as workspace:
83:        cache_dir = Path(workspace)
84:        if not exists:
85:            cache_dir = cache_dir / "new"
86:        with patch("black.CACHE_DIR", cache_dir):
87:            yield cache_dir
88:
89:
90:@contextmanager
91:def event_loop(close: bool) -> Iterator[None]:
92:    policy = asyncio.get_event_loop_policy()
93:    old_loop = policy.get_event_loop()
94:    loop = policy.new_event_loop()
95:    asyncio.set_event_loop(loop)
96:    try:
97:        yield
98:
99:    finally:
100:        policy.set_event_loop(old_loop)

Calling tool: globTool
**/tests/data/tupleassign.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test `tests/test_black.py::test_tuple_assign` reads fixtures from `tests/data/tupleassign.py`, which contains a long LHS tuple assignment. The expected output shows the LHS wrapped in parentheses across lines, confirming the case now expects parentheses around the LHS.

Todo item 10 of 14 is correct
description: 'Open the test test_tuple_assign and confirm it includes a long LHS tuple unpacking assignment case that previously required a backslash continuation and now expects parentheses around the LHS.'

Validating todo item 11 of 14
description: 'In test_tuple_assign, verify that the expected formatted output has parentheses around the LHS names and does not rely on a backslash for line continuation.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: grepTool
test_tuple_assign
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )

Calling tool: globTool
**/*tupleassign*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: grepTool
def maybe_make_parens_invisible_in_atom\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2842:    """
2843:    container: Optional[LN] = container_of(leaf)
2844:    while container is not None and container.type != token.ENDMARKER:
2845:        for comment in list_comments(container.prefix, is_endmarker=False):
2846:            if comment.value in FMT_ON:
2847:                return
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)
2865:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2866:    ):
2867:        return False
2868:
2869:    first = node.children[0]
2870:    last = node.children[-1]
2871:    if first.type == token.LPAR and last.type == token.RPAR:
2872:        # make parentheses invisible
2873:        first.value = ""  # type: ignore
2874:        last.value = ""  # type: ignore
2875:        if len(node.children) > 1:
2876:            maybe_make_parens_invisible_in_atom(node.children[1], parent=parent)
2877:        return False
2878:
2879:    return True
2880:
2881:
2882:def is_empty_tuple(node: LN) -> bool:
2883:    """Return True if `node` holds an empty tuple."""
2884:    return (
2885:        node.type == syms.atom
2886:        and len(node.children) == 2
2887:        and node.children[0].type == token.LPAR
2888:        and node.children[1].type == token.RPAR
2889:    )
2890:
2891:
2892:def is_one_tuple(node: LN) -> bool:
2893:    """Return True if `node` holds a tuple with one element, with or without parens."""
2894:    if node.type == syms.atom:
2895:        if len(node.children) != 3:
2896:            return False
2897:
2898:        lpar, gexp, rpar = node.children
2899:        if not (
2900:            lpar.type == token.LPAR
2901:            and gexp.type == syms.testlist_gexp
2902:            and rpar.type == token.RPAR
2903:        ):
2904:            return False
2905:
2906:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2907:
2908:    return (
2909:        node.type in IMPLICIT_TUPLE
2910:        and len(node.children) == 2
2911:        and node.children[1].type == token.COMMA
2912:    )
2913:
2914:
2915:def is_yield(node: LN) -> bool:
2916:    """Return True if `node` holds a `yield` or `yield from` expression."""
2917:    if node.type == syms.yield_expr:
2918:        return True
2919:
2920:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2921:        return True
2922:
2923:    if node.type != syms.atom:
2924:        return False
2925:
2926:    if len(node.children) != 3:
2927:        return False
2928:
2929:    lpar, expr, rpar = node.children
2930:    if lpar.type == token.LPAR and rpar.type == token.RPAR:
2931:        return is_yield(expr)
2932:
2933:    return False
2934:
2935:
2936:def is_vararg(leaf: Leaf, within: Set[NodeType]) -> bool:
2937:    """Return True if `leaf` is a star or double star in a vararg or kwarg.
2938:
2939:    If `within` includes VARARGS_PARENTS, this applies to function signatures.
2940:    If `within` includes UNPACKING_PARENTS, it applies to right hand-side
2941:    extended iterable unpacking (PEP 3132) and additional unpacking
2942:    generalizations (PEP 448).
2943:    """
2944:    if leaf.type not in STARS or not leaf.parent:
2945:        return False
2946:
2947:    p = leaf.parent
2948:    if p.type == syms.star_expr:
2949:        # Star expressions are also used as assignment targets in extended
2950:        # iterable unpacking (PEP 3132).  See what its parent is instead.
2951:        if not p.parent:
2952:            return False
2953:
2954:        p = p.parent
2955:
2956:    return p.type in within
2957:
2958:
2959:def is_multiline_string(leaf: Leaf) -> bool:
2960:    """Return True if `leaf` is a multiline string that actually spans many lines."""
2961:    value = leaf.value.lstrip("furbFURB")

Calling tool: grepTool
def right_hand_split\(|def left_hand_split\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2242:def left_hand_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2278:def right_hand_split(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2215:            split_funcs = [rhs]
2216:    for split_func in split_funcs:
2217:        # We are accumulating lines in `result` because we might want to abort
2218:        # mission and return the original line in the end, or attempt a different
2219:        # split altogether.
2220:        result: List[Line] = []
2221:        try:
2222:            for l in split_func(line, features):
2223:                if str(l).strip("\n") == line_str:
2224:                    raise CannotSplit("Split function returned an unchanged result")
2225:
2226:                result.extend(
2227:                    split_line(
2228:                        l, line_length=line_length, inner=True, features=features
2229:                    )
2230:                )
2231:        except CannotSplit:
2232:            continue
2233:
2234:        else:
2235:            yield from result
2236:            break
2237:
2238:    else:
2239:        yield line
2240:
2241:
2242:def left_hand_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2243:    """Split line into many lines, starting with the first matching bracket pair.
2244:
2245:    Note: this usually looks weird, only use this for function definitions.
2246:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2247:    :func:`right_hand_split` which also handles optional parentheses.
2248:    """
2249:    tail_leaves: List[Leaf] = []
2250:    body_leaves: List[Leaf] = []
2251:    head_leaves: List[Leaf] = []
2252:    current_leaves = head_leaves
2253:    matching_bracket = None
2254:    for leaf in line.leaves:
2255:        if (
2256:            current_leaves is body_leaves
2257:            and leaf.type in CLOSING_BRACKETS
2258:            and leaf.opening_bracket is matching_bracket
2259:        ):
2260:            current_leaves = tail_leaves if body_leaves else head_leaves
2261:        current_leaves.append(leaf)
2262:        if current_leaves is head_leaves:
2263:            if leaf.type in OPENING_BRACKETS:
2264:                matching_bracket = leaf
2265:                current_leaves = body_leaves
2266:    if not matching_bracket:
2267:        raise CannotSplit("No brackets found")
2268:
2269:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2270:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2271:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2272:    bracket_split_succeeded_or_raise(head, body, tail)
2273:    for result in (head, body, tail):
2274:        if result:
2275:            yield result
2276:
2277:
2278:def right_hand_split(
2279:    line: Line,
2280:    line_length: int,
2281:    features: Collection[Feature] = (),
2282:    omit: Collection[LeafID] = (),
2283:) -> Iterator[Line]:
2284:    """Split line into many lines, starting with the last matching bracket pair.
2285:
2286:    If the split was by optional parentheses, attempt splitting without them, too.
2287:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2288:    this split.
2289:
2290:    Note: running this function modifies `bracket_depth` on the leaves of `line`.
2291:    """
2292:    tail_leaves: List[Leaf] = []
2293:    body_leaves: List[Leaf] = []
2294:    head_leaves: List[Leaf] = []
2295:    current_leaves = tail_leaves
2296:    opening_bracket = None
2297:    closing_bracket = None
2298:    for leaf in reversed(line.leaves):
2299:        if current_leaves is body_leaves:
2300:            if leaf is opening_bracket:
2301:                current_leaves = head_leaves if body_leaves else tail_leaves
2302:        current_leaves.append(leaf)
2303:        if current_leaves is tail_leaves:
2304:            if leaf.type in CLOSING_BRACKETS and id(leaf) not in omit:
2305:                opening_bracket = leaf.opening_bracket
2306:                closing_bracket = leaf
2307:                current_leaves = body_leaves
2308:    if not (opening_bracket and closing_bracket and head_leaves):
2309:        # If there is no opening or closing_bracket that means the split failed and
2310:        # all content is in the tail.  Otherwise, if `head_leaves` are empty, it means
2311:        # the matching `opening_bracket` wasn't available on `line` anymore.
2312:        raise CannotSplit("No brackets found")
2313:
2314:    tail_leaves.reverse()
2315:    body_leaves.reverse()
2316:    head_leaves.reverse()
2317:    head = bracket_split_build_line(head_leaves, line, opening_bracket)
2318:    body = bracket_split_build_line(body_leaves, line, opening_bracket, is_body=True)
2319:    tail = bracket_split_build_line(tail_leaves, line, opening_bracket)
2320:    bracket_split_succeeded_or_raise(head, body, tail)
2321:    if (
2322:        # the body shouldn't be exploded
2323:        not body.should_explode
2324:        # the opening bracket is an optional paren
2325:        and opening_bracket.type == token.LPAR
2326:        and not opening_bracket.value
2327:        # the closing bracket is an optional paren
2328:        and closing_bracket.type == token.RPAR
2329:        and not closing_bracket.value
2330:        # it's not an import (optional parens are the only thing we can split on
2331:        # in this case; attempting a split without them is a waste of time)
2332:        and not line.is_import
2333:        # there are no standalone comments in the body
2334:        and not body.contains_standalone_comments(0)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2330:        # it's not an import (optional parens are the only thing we can split on
2331:        # in this case; attempting a split without them is a waste of time)
2332:        and not line.is_import
2333:        # there are no standalone comments in the body
2334:        and not body.contains_standalone_comments(0)
2335:        # and we can actually remove the parens
2336:        and can_omit_invisible_parens(body, line_length)
2337:    ):
2338:        omit = {id(closing_bracket), *omit}
2339:        try:
2340:            yield from right_hand_split(line, line_length, features=features, omit=omit)
2341:            return
2342:
2343:        except CannotSplit:
2344:            if not (
2345:                can_be_split(body)
2346:                or is_line_short_enough(body, line_length=line_length)
2347:            ):
2348:                raise CannotSplit(
2349:                    "Splitting failed, body is still too long and can't be split."
2350:                )
2351:
2352:            elif head.contains_multiline_strings() or tail.contains_multiline_strings():
2353:                raise CannotSplit(
2354:                    "The current optional pair of parentheses is bound to fail to "
2355:                    "satisfy the splitting algorithm because the head or the tail "
2356:                    "contains multiline strings which by definition never fit one "
2357:                    "line."
2358:                )
2359:
2360:    ensure_visible(opening_bracket)
2361:    ensure_visible(closing_bracket)
2362:    for result in (head, body, tail):
2363:        if result:
2364:            yield result
2365:
2366:
2367:def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None:
2368:    """Raise :exc:`CannotSplit` if the last left- or right-hand split failed.
2369:
2370:    Do nothing otherwise.
2371:
2372:    A left- or right-hand split is based on a pair of brackets. Content before
2373:    (and including) the opening bracket is left on one line, content inside the
2374:    brackets is put on a separate line, and finally content starting with and
2375:    following the closing bracket is put on a separate line.
2376:
2377:    Those are called `head`, `body`, and `tail`, respectively. If the split
2378:    produced the same line (all content in `head`) or ended up with an empty `body`
2379:    and the `tail` is just the closing bracket, then it's considered failed.
2380:    """
2381:    tail_len = len(str(tail).strip())
2382:    if not body:
2383:        if tail_len == 0:
2384:            raise CannotSplit("Splitting brackets produced the same line")
2385:
2386:        elif tail_len < 3:
2387:            raise CannotSplit(
2388:                f"Splitting brackets on an empty body to save "
2389:                f"{tail_len} characters is not worth it"
2390:            )
2391:
2392:
2393:def bracket_split_build_line(
2394:    leaves: List[Leaf], original: Line, opening_bracket: Leaf, *, is_body: bool = False
2395:) -> Line:
2396:    """Return a new line with given `leaves` and respective comments from `original`.
2397:
2398:    If `is_body` is True, the result line is one-indented inside brackets and as such
2399:    has its first leaf's prefix normalized and a trailing comma added when expected.
2400:    """
2401:    result = Line(depth=original.depth)
2402:    if is_body:
2403:        result.inside_brackets = True
2404:        result.depth += 1
2405:        if leaves:
2406:            # Since body is a new indent level, remove spurious leading whitespace.
2407:            normalize_prefix(leaves[0], inside_brackets=True)
2408:            # Ensure a trailing comma for imports, but be careful not to add one after
2409:            # any comments.
2410:            if original.is_import:
2411:                for i in range(len(leaves) - 1, -1, -1):
2412:                    if leaves[i].type == STANDALONE_COMMENT:
2413:                        continue
2414:                    elif leaves[i].type == token.COMMA:
2415:                        break
2416:                    else:
2417:                        leaves.insert(i + 1, Leaf(token.COMMA, ","))
2418:                        break
2419:    # Populate the line
2420:    for leaf in leaves:
2421:        result.append(leaf, preformatted=True)
2422:        for comment_after in original.comments_after(leaf):
2423:            result.append(comment_after, preformatted=True)
2424:    if is_body:
2425:        result.should_explode = should_explode(result, opening_bracket)
2426:    return result
2427:
2428:
2429:def dont_increase_indentation(split_func: SplitFunc) -> SplitFunc:
2430:    """Normalize prefix of the first leaf in every line returned by `split_func`.
2431:
2432:    This is a decorator over relevant split functions.
2433:    """
2434:
2435:    @wraps(split_func)
2436:    def split_wrapper(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2437:        for l in split_func(line, features):
2438:            normalize_prefix(l.leaves[0], inside_brackets=True)
2439:            yield l
2440:
2441:    return split_wrapper
2442:
2443:
2444:@dont_increase_indentation
2445:def delimiter_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2446:    """Split according to delimiters of the highest priority.
2447:
2448:    If the appropriate Features are given, the split will add trailing commas
2449:    also in function signatures and calls that contain `*` and `**`.
2450:    """
2451:    try:
2452:        last_leaf = line.leaves[-1]
2453:    except IndexError:
2454:        raise CannotSplit("Line empty")
2455:
2456:    bt = line.bracket_tracker
2457:    try:
2458:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2459:    except ValueError:
2460:        raise CannotSplit("No delimiters found")
2461:
2462:    if delimiter_priority == DOT_PRIORITY:
2463:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2464:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2465:
2466:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2467:    lowest_depth = sys.maxsize
2468:    trailing_comma_safe = True
2469:

Calling tool: grepTool
normalize_invisible_parens\([^)]*\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1582:        normalize_invisible_parens(node, parens_after=parens)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1540:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1541:                normalize_string_quotes(node)
1542:            if node.type == token.NUMBER:
1543:                normalize_numeric_literal(node)
1544:            if node.type not in WHITESPACE:
1545:                self.current_line.append(node)
1546:        yield from super().visit_default(node)
1547:
1548:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1549:        """Increase indentation level, maybe yield a line."""
1550:        # In blib2to3 INDENT never holds comments.
1551:        yield from self.line(+1)
1552:        yield from self.visit_default(node)
1553:
1554:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1555:        """Decrease indentation level, maybe yield a line."""
1556:        # The current line might still wait for trailing comments.  At DEDENT time
1557:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1558:        # Emit the line then.
1559:        yield from self.line()
1560:
1561:        # While DEDENT has no value, its prefix may contain standalone comments
1562:        # that belong to the current indentation level.  Get 'em.
1563:        yield from self.visit_default(node)
1564:
1565:        # Finally, emit the dedent.
1566:        yield from self.line(-1)
1567:
1568:    def visit_stmt(
1569:        self, node: Node, keywords: Set[str], parens: Set[str]
1570:    ) -> Iterator[Line]:
1571:        """Visit a statement.
1572:
1573:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1574:        `def`, `with`, `class`, `assert` and assignments.
1575:
1576:        The relevant Python language `keywords` for a given statement will be
1577:        NAME leaves within it. This methods puts those on a separate line.
1578:
1579:        `parens` holds a set of string leaf values immediately after which
1580:        invisible parens should be put.
1581:        """
1582:        normalize_invisible_parens(node, parens_after=parens)
1583:        for child in node.children:
1584:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1585:                yield from self.line()
1586:
1587:            yield from self.visit(child)
1588:
1589:    def visit_suite(self, node: Node) -> Iterator[Line]:
1590:        """Visit a suite."""
1591:        if self.is_pyi and is_stub_suite(node):
1592:            yield from self.visit(node.children[2])
1593:        else:
1594:            yield from self.visit_default(node)
1595:
1596:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1597:        """Visit a statement without nested statements."""
1598:        is_suite_like = node.parent and node.parent.type in STATEMENT
1599:        if is_suite_like:
1600:            if self.is_pyi and is_stub_body(node):
1601:                yield from self.visit_default(node)
1602:            else:
1603:                yield from self.line(+1)
1604:                yield from self.visit_default(node)
1605:                yield from self.line(-1)
1606:
1607:        else:
1608:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1609:                yield from self.line()
1610:            yield from self.visit_default(node)
1611:
1612:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1613:        """Visit `async def`, `async for`, `async with`."""
1614:        yield from self.line()
1615:
1616:        children = iter(node.children)
1617:        for child in children:
1618:            yield from self.visit(child)
1619:

Calling tool: grepTool
def visit_.*expr_stmt|visit_stmt\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1568:    def visit_stmt(

Calling tool: grepTool
visit_stmt\(self, node: Node, keywords: Set\[str\], parens: Set\[str\]\)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_.*\(self, node: Node.*parens.*Set\[str\]
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def visit_[a-z_]*\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/debug_visitor.py:5:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:798:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:809:    def visit_default(self, node: LN) -> Iterator[T]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1518:    def visit_default(self, node: LN) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1568:    def visit_stmt(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1589:    def visit_suite(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1596:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1612:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1627:    def visit_decorators(self, node: Node) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
1620:            if child.type == token.ASYNC:
1621:                break
1622:
1623:        internal_stmt = next(children)
1624:        for child in internal_stmt.children:
1625:            yield from self.visit(child)
1626:
1627:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1628:        """Visit decorators."""
1629:        for child in node.children:
1630:            yield from self.line()
1631:            yield from self.visit(child)
1632:
1633:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1634:        """Remove a semicolon and put the other statement on a separate line."""
1635:        yield from self.line()
1636:
1637:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1638:        """End of file. Process outstanding comments and end with a newline."""
1639:        yield from self.visit_default(leaf)
1640:        yield from self.line()
1641:
1642:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1643:        if not self.current_line.bracket_tracker.any_open_brackets():
1644:            yield from self.line()
1645:        yield from self.visit_default(leaf)
1646:
1647:    def __attrs_post_init__(self) -> None:
1648:        """You are in a twisty little maze of passages."""
1649:        v = self.visit_stmt
1650:        Ø: Set[str] = set()
1651:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1652:        self.visit_if_stmt = partial(
1653:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1654:        )
1655:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1656:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1657:        self.visit_try_stmt = partial(
1658:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1659:        )
1660:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1661:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1662:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1663:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1664:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1665:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1666:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1667:        self.visit_del_stmt = partial(v, keywords=Ø, parens={"del"})
1668:        self.visit_async_funcdef = self.visit_async_stmt
1669:        self.visit_decorated = self.visit_decorators
1670:
1671:
1672:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1673:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1674:OPENING_BRACKETS = set(BRACKET.keys())
1675:CLOSING_BRACKETS = set(BRACKET.values())
1676:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1677:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1678:
1679:
1680:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa: C901
1681:    """Return whitespace prefix if needed for the given `leaf`.
1682:
1683:    `complex_subscript` signals whether the given leaf is part of a subscription
1684:    which has non-trivial arguments, like arithmetic expressions or function calls.
1685:    """
1686:    NO = ""
1687:    SPACE = " "
1688:    DOUBLESPACE = "  "
1689:    t = leaf.type
1690:    p = leaf.parent
1691:    v = leaf.value
1692:    if t in ALWAYS_NO_SPACE:
1693:        return NO
1694:
1695:    if t == token.COMMENT:
1696:        return DOUBLESPACE
1697:
1698:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1699:    if t == token.COLON and p.type not in {
1700:        syms.subscript,
1701:        syms.subscriptlist,
1702:        syms.sliceop,
1703:    }:
1704:        return NO
1705:
1706:    prev = leaf.prev_sibling
1707:    if not prev:
1708:        prevp = preceding_leaf(p)
1709:        if not prevp or prevp.type in OPENING_BRACKETS:
1710:            return NO
1711:
1712:        if t == token.COLON:
1713:            if prevp.type == token.COLON:
1714:                return NO
1715:
1716:            elif prevp.type != token.COMMA and not complex_subscript:
1717:                return NO
1718:
1719:            return SPACE
1720:
1721:        if prevp.type == token.EQUAL:
1722:            if prevp.parent:
1723:                if prevp.parent.type in {
1724:                    syms.arglist,
1725:                    syms.argument,
1726:                    syms.parameters,
1727:                    syms.varargslist,
1728:                }:
1729:                    return NO
1730:
1731:                elif prevp.parent.type == syms.typedargslist:
1732:                    # A bit hacky: if the equal sign has whitespace, it means we
1733:                    # previously found it's a typed argument.  So, we're using
1734:                    # that, too.
1735:                    return prevp.prefix
1736:
1737:        elif prevp.type in STARS:
1738:            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1739:                return NO
1740:
1741:        elif prevp.type == token.COLON:
1742:            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:
1743:                return SPACE if complex_subscript else NO
1744:
1745:        elif (
1746:            prevp.parent
1747:            and prevp.parent.type == syms.factor
1748:            and prevp.type in MATH_OPERATORS
1749:        ):
1750:            return NO
1751:
1752:        elif (
1753:            prevp.type == token.RIGHTSHIFT
1754:            and prevp.parent
1755:            and prevp.parent.type == syms.shift_expr
1756:            and prevp.prev_sibling
1757:            and prevp.prev_sibling.type == token.NAME
1758:            and prevp.prev_sibling.value == "print"  # type: ignore
1759:        ):
1760:            # Python 2 print chevron
1761:            return NO
1762:
1763:    elif prev.type in OPENING_BRACKETS:
1764:        return NO
1765:
1766:    if p.type in {syms.parameters, syms.arglist}:
1767:        # untyped function signatures or calls
1768:        if not prev or prev.type != token.COMMA:
1769:            return NO
1770:
1771:    elif p.type == syms.varargslist:
1772:        # lambdas
1773:        if prev and prev.type != token.COMMA:
1774:            return NO
1775:
1776:    elif p.type == syms.typedargslist:
1777:        # typed function signatures
1778:        if not prev:
1779:            return NO
1780:
1781:        if t == token.EQUAL:
1782:            if prev.type != syms.tname:
1783:                return NO
1784:
1785:        elif prev.type == token.EQUAL:
1786:            # A bit hacky: if the equal sign has whitespace, it means we
1787:            # previously found it's a typed argument.  So, we're using that, too.
1788:            return prev.prefix
1789:
1790:        elif prev.type != token.COMMA:
1791:            return NO
1792:
1793:    elif p.type == syms.tname:
1794:        # type names
1795:        if not prev:
1796:            prevp = preceding_leaf(p)
1797:            if not prevp or prevp.type != token.COMMA:
1798:                return NO
1799:
1800:    elif p.type == syms.trailer:
1801:        # attributes and calls
1802:        if t == token.LPAR or t == token.RPAR:
1803:            return NO
1804:
1805:        if not prev:
1806:            if t == token.DOT:
1807:                prevp = preceding_leaf(p)
1808:                if not prevp or prevp.type != token.NUMBER:
1809:                    return NO
1810:
1811:            elif t == token.LSQB:
1812:                return NO
1813:
1814:        elif prev.type != token.COMMA:
1815:            return NO
1816:
1817:    elif p.type == syms.argument:
1818:        # single argument
1819:        if t == token.EQUAL:
1820:            return NO
1821:
1822:        if not prev:
1823:            prevp = preceding_leaf(p)
1824:            if not prevp or prevp.type == token.LPAR:
1825:                return NO
1826:
1827:        elif prev.type in {token.EQUAL} | STARS:
1828:            return NO
1829:
1830:    elif p.type == syms.decorator:
1831:        # decorators
1832:        return NO
1833:
1834:    elif p.type == syms.dotted_name:
1835:        if prev:
1836:            return NO
1837:
1838:        prevp = preceding_leaf(p)
1839:        if not prevp or prevp.type == token.AT or prevp.type == token.DOT:
1840:            return NO
1841:
1842:    elif p.type == syms.classdef:
1843:        if t == token.LPAR:
1844:            return NO
1845:
1846:        if prev and prev.type == token.LPAR:
1847:            return NO
1848:
1849:    elif p.type in {syms.subscript, syms.sliceop}:
1850:        # indexing
1851:        if not prev:
1852:            assert p.parent is not None, "subscripts are always parented"
1853:            if p.parent.type == syms.subscriptlist:
1854:                return SPACE
1855:
1856:            return NO
1857:
1858:        elif not complex_subscript:
1859:            return NO
1860:
1861:    elif p.type == syms.atom:
1862:        if prev and t == token.DOT:
1863:            # dots, but not the first one.
1864:            return NO
1865:
1866:    elif p.type == syms.dictsetmaker:
1867:        # dict unpacking
1868:        if prev and prev.type == token.DOUBLESTAR:
1869:            return NO
1870:
1871:    elif p.type in {syms.factor, syms.star_expr}:
1872:        # unary ops
1873:        if not prev:
1874:            prevp = preceding_leaf(p)
1875:            if not prevp or prevp.type in OPENING_BRACKETS:
1876:                return NO
1877:
1878:            prevp_parent = prevp.parent
1879:            assert prevp_parent is not None
1880:            if prevp.type == token.COLON and prevp_parent.type in {
1881:                syms.subscript,
1882:                syms.sliceop,
1883:            }:
1884:                return NO
1885:
1886:            elif prevp.type == token.EQUAL and prevp_parent.type == syms.argument:
1887:                return NO
1888:
1889:        elif t in {token.NAME, token.NUMBER, token.STRING}:
1890:            return NO
1891:
1892:    elif p.type == syms.import_from:
1893:        if t == token.DOT:
1894:            if prev and prev.type == token.DOT:
1895:                return NO
1896:
1897:        elif t == token.NAME:
1898:            if v == "import":
1899:                return SPACE
1900:
1901:            if prev and prev.type == token.DOT:
1902:                return NO
1903:
1904:    elif p.type == syms.sliceop:
1905:        return NO
1906:
1907:    return SPACE
1908:
1909:
1910:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1911:    """Return the first leaf that precedes `node`, if any."""
1912:    while node:
1913:        res = node.prev_sibling
1914:        if res:
1915:            if isinstance(res, Leaf):
1916:                return res
1917:
1918:            try:
1919:                return list(res.leaves())[-1]

Calling tool: grepTool
ASSIGNMENTS\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:911:ASSIGNMENTS = {

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
900:    syms.comparison,
901:    syms.star_expr,
902:    syms.expr,
903:    syms.xor_expr,
904:    syms.and_expr,
905:    syms.shift_expr,
906:    syms.arith_expr,
907:    syms.trailer,
908:    syms.term,
909:    syms.power,
910:}
911:ASSIGNMENTS = {
912:    "=",
913:    "+=",
914:    "-=",
915:    "*=",
916:    "@=",
917:    "/=",
918:    "%=",
919:    "&=",
920:    "|=",
921:    "^=",
922:    "<<=",
923:    ">>=",
924:    "**=",
925:    "//=",
926:}
927:COMPREHENSION_PRIORITY = 20
928:COMMA_PRIORITY = 18
929:TERNARY_PRIORITY = 16
930:LOGIC_PRIORITY = 14
931:STRING_PRIORITY = 12
932:COMPARATOR_PRIORITY = 10
933:MATH_PRIORITIES = {
934:    token.VBAR: 9,
935:    token.CIRCUMFLEX: 8,
936:    token.AMPER: 7,
937:    token.LEFTSHIFT: 6,
938:    token.RIGHTSHIFT: 6,
939:    token.PLUS: 5,
940:    token.MINUS: 5,
941:    token.STAR: 4,
942:    token.SLASH: 4,
943:    token.DOUBLESLASH: 4,
944:    token.PERCENT: 4,
945:    token.AT: 4,
946:    token.TILDE: 3,
947:    token.DOUBLESTAR: 2,
948:}
949:DOT_PRIORITY = 1
950:
951:
952:@dataclass
953:class BracketTracker:
954:    """Keeps track of brackets on a line."""
955:
956:    depth: int = 0
957:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
958:    delimiters: Dict[LeafID, Priority] = Factory(dict)
959:    previous: Optional[Leaf] = None

Calling tool: grepTool
trailing comma|trailing_comma|should_explode
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/README:6:- backport of BPO-33064 that fixes parsing files with trailing commas after
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/blib2to3/Grammar.txt:151:# contains comma which clashes with trailing comma in arglist.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:81:                                  input files.  This will put trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:233:that a trailing comma is always added.  Such formatting produces smaller
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:253:include_trailing_comma=True
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:331:*Black* will add trailing commas to expressions that are split
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:335:Unnecessary trailing commas are removed if an expression fits in one
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:341:One exception to removing trailing commas is tuple expressions with
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:347:One exception to adding trailing commas is function signatures
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:348:containing `*`, `*args`, or `**kwargs`.  In this case a trailing comma
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:350:already 3.6+ only and use trailing commas in this situation.  If you
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:353:if you'd like a trailing comma in this situation and *Black* didn't
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:961:* fix feature detection for trailing commas in function definitions and
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1012:* trailing comma is now added to single imports that don't fit on a line (#250)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1180:* fixed an invalid trailing comma sometimes left in imports (#185)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1191:  unpacking. This fixed non-deterministic formatting if trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1216:  fixes multiplication making expressions "unsafe" for trailing commas (#132)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1221:* *Black* now splits imports like "Mode 3 + trailing comma" of isort (#127)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1302:* don't remove single trailing commas from square bracket indexing
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1336:* remove a trailing comma if there is a single argument to a call
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1355:* only put trailing commas in function signatures and calls if it's
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:258:        "trailing commas in function signatures and calls also after *args and "
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1093:    should_explode: bool = False
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1119:            self.maybe_remove_trailing_comma(leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1229:                # When trailing commas are inserted by Black for consistency, comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1231:                # rendering will still be correct).  So we ignore trailing commas.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1254:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1255:        """Remove trailing comma if there is one and it's safe."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1264:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1270:                self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1276:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1303:            self.remove_trailing_comma()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1332:    def remove_trailing_comma(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1333:        """Remove the trailing comma and moves the comments attached to it."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1334:        trailing_comma = self.leaves.pop()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1335:        trailing_comma_comments = self.comments.pop(id(trailing_comma), [])
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1337:            trailing_comma_comments
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2189:        and not line.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2323:        not body.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2399:    has its first leaf's prefix normalized and a trailing comma added when expected.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2408:            # Ensure a trailing comma for imports, but be careful not to add one after
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2425:        result.should_explode = should_explode(result, opening_bracket)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2448:    If the appropriate Features are given, the split will add trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2468:    trailing_comma_safe = True
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2490:                trailing_comma_safe = (
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2491:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_DEF in features
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2494:                trailing_comma_safe = (
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2495:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_CALL in features
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2505:            trailing_comma_safe
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
3008:    bt = BracketTracker()
3009:    for c in node.children[1:-1]:
3010:        if isinstance(c, Leaf):
3011:            bt.mark(c)
3012:        else:
3013:            for leaf in c.leaves():
3014:                bt.mark(leaf)
3015:    try:
3016:        return bt.max_delimiter_priority()
3017:
3018:    except ValueError:
3019:        return 0
3020:
3021:
3022:def ensure_visible(leaf: Leaf) -> None:
3023:    """Make sure parentheses are visible.
3024:
3025:    They could be invisible as part of some statements (see
3026:    :func:`normalize_invible_parens` and :func:`visit_import_from`).
3027:    """
3028:    if leaf.type == token.LPAR:
3029:        leaf.value = "("
3030:    elif leaf.type == token.RPAR:
3031:        leaf.value = ")"
3032:
3033:
3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:
3035:    """Should `line` immediately be split with `delimiter_split()` after RHS?"""
3036:
3037:    if not (
3038:        opening_bracket.parent
3039:        and opening_bracket.parent.type in {syms.atom, syms.import_from}
3040:        and opening_bracket.value in "[{("
3041:    ):
3042:        return False
3043:
3044:    try:
3045:        last_leaf = line.leaves[-1]
3046:        exclude = {id(last_leaf)} if last_leaf.type == token.COMMA else set()
3047:        max_priority = line.bracket_tracker.max_delimiter_priority(exclude=exclude)
3048:    except (IndexError, ValueError):
3049:        return False
3050:
3051:    return max_priority == COMMA_PRIORITY
3052:
3053:
3054:def get_features_used(node: Node) -> Set[Feature]:
3055:    """Return a set of (relatively) new Python features used in this file.
3056:
3057:    Currently looking for:
3058:    - f-strings;
3059:    - underscores in numeric literals; and
3060:    - trailing commas after * or ** in function signatures and calls.
3061:    """
3062:    features: Set[Feature] = set()
3063:    for n in node.pre_order():
3064:        if n.type == token.STRING:
3065:            value_head = n.value[:2]  # type: ignore
3066:            if value_head in {'f"', 'F"', "f'", "F'", "rf", "fr", "RF", "FR"}:
3067:                features.add(Feature.F_STRINGS)
3068:
3069:        elif n.type == token.NUMBER:
3070:            if "_" in n.value:  # type: ignore
3071:                features.add(Feature.NUMERIC_UNDERSCORES)
3072:
3073:        elif (
3074:            n.type in {syms.typedargslist, syms.arglist}
3075:            and n.children
3076:            and n.children[-1].type == token.COMMA
3077:        ):
3078:            if n.type == syms.typedargslist:
3079:                feature = Feature.TRAILING_COMMA_IN_DEF
3080:            else:
3081:                feature = Feature.TRAILING_COMMA_IN_CALL
3082:
3083:            for ch in n.children:
3084:                if ch.type in STARS:
3085:                    features.add(feature)
3086:
3087:                if ch.type == syms.argument:
3088:                    for argch in ch.children:
3089:                        if argch.type in STARS:
3090:                            features.add(feature)
3091:
3092:    return features
3093:
3094:
3095:def detect_target_versions(node: Node) -> Set[TargetVersion]:
3096:    """Detect the version to target based on the nodes used."""
3097:    features = get_features_used(node)
3098:    return {
3099:        version for version in TargetVersion if features <= VERSION_TO_FEATURES[version]
3100:    }
3101:
3102:
3103:def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[Set[LeafID]]:
3104:    """Generate sets of closing bracket IDs that should be omitted in a RHS.
3105:
3106:    Brackets can be omitted if the entire trailer up to and including
3107:    a preceding closing bracket fits in one line.

Calling tool: grepTool
add trailing comma|trailing comma is now added|insert.*trailing comma|ensure a trailing comma|should_explode
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:331:*Black* will add trailing commas to expressions that are split
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/README.md:1012:* trailing comma is now added to single imports that don't fit on a line (#250)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:1093:    should_explode: bool = False
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2189:        and not line.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2323:        not body.should_explode
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2425:        result.should_explode = should_explode(result, opening_bracket)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2448:    If the appropriate Features are given, the split will add trailing commas
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:3034:def should_explode(line: Line, opening_bracket: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/docs/reference/reference_functions.rst:172:.. autofunction:: black.should_explode

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2440:
2441:    return split_wrapper
2442:
2443:
2444:@dont_increase_indentation
2445:def delimiter_split(line: Line, features: Collection[Feature] = ()) -> Iterator[Line]:
2446:    """Split according to delimiters of the highest priority.
2447:
2448:    If the appropriate Features are given, the split will add trailing commas
2449:    also in function signatures and calls that contain `*` and `**`.
2450:    """
2451:    try:
2452:        last_leaf = line.leaves[-1]
2453:    except IndexError:
2454:        raise CannotSplit("Line empty")
2455:
2456:    bt = line.bracket_tracker
2457:    try:
2458:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2459:    except ValueError:
2460:        raise CannotSplit("No delimiters found")
2461:
2462:    if delimiter_priority == DOT_PRIORITY:
2463:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2464:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2465:
2466:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2467:    lowest_depth = sys.maxsize
2468:    trailing_comma_safe = True
2469:
2470:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2471:        """Append `leaf` to current line or to new line if appending impossible."""
2472:        nonlocal current_line
2473:        try:
2474:            current_line.append_safe(leaf, preformatted=True)
2475:        except ValueError:
2476:            yield current_line
2477:
2478:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2479:            current_line.append(leaf)
2480:
2481:    for leaf in line.leaves:
2482:        yield from append_to_line(leaf)
2483:
2484:        for comment_after in line.comments_after(leaf):
2485:            yield from append_to_line(comment_after)
2486:
2487:        lowest_depth = min(lowest_depth, leaf.bracket_depth)
2488:        if leaf.bracket_depth == lowest_depth:
2489:            if is_vararg(leaf, within={syms.typedargslist}):
2490:                trailing_comma_safe = (
2491:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_DEF in features
2492:                )
2493:            elif is_vararg(leaf, within={syms.arglist, syms.argument}):
2494:                trailing_comma_safe = (
2495:                    trailing_comma_safe and Feature.TRAILING_COMMA_IN_CALL in features
2496:                )
2497:
2498:        leaf_priority = bt.delimiters.get(id(leaf))
2499:        if leaf_priority == delimiter_priority:
2500:            yield current_line
2501:
2502:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2503:    if current_line:
2504:        if (
2505:            trailing_comma_safe
2506:            and delimiter_priority == COMMA_PRIORITY
2507:            and current_line.leaves[-1].type != token.COMMA
2508:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2509:        ):
2510:            current_line.append(Leaf(token.COMMA, ","))
2511:        yield current_line
2512:
2513:
2514:@dont_increase_indentation
2515:def standalone_comment_split(
2516:    line: Line, features: Collection[Feature] = ()
2517:) -> Iterator[Line]:
2518:    """Split standalone comments from the rest of the line."""
2519:    if not line.contains_standalone_comments(0):
2520:        raise CannotSplit("Line does not have any standalone comments")
2521:
2522:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2523:
2524:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2525:        """Append `leaf` to current line or to new line if appending impossible."""
2526:        nonlocal current_line
2527:        try:
2528:            current_line.append_safe(leaf, preformatted=True)
2529:        except ValueError:
2530:            yield current_line
2531:
2532:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2533:            current_line.append(leaf)
2534:
2535:    for leaf in line.leaves:
2536:        yield from append_to_line(leaf)
2537:
2538:        for comment_after in line.comments_after(leaf):
2539:            yield from append_to_line(comment_after)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The test data `tests/data/tupleassign.py` expects visible parentheses around the LHS tuple and no backslash. The code change in `normalize_invisible_parens` adds optional parentheses around the LHS (testlist_star_expr) and right-hand splitting ensures they become visible when splitting, matching the expected output in `test_tuple_assign`. Prefix handling is also correctly preserved.

Todo item 11 of 14 is correct
description: 'In test_tuple_assign, verify that the expected formatted output has parentheses around the LHS names and does not rely on a backslash for line continuation.'

Validating todo item 12 of 14
description: 'If comments or leading whitespace precede the LHS tuple in the test, verify the expected output preserves them before the opening '(', consistent with moving the prefix to the wrapper node.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,

Calling tool: globTool
**/*test*tuple*assign*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: grepTool
test_tuple_assign
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_tuple_assign
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py:546:    def test_tuple_assign(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/test_black.py
520:
521:    @patch("black.dump_to_file", dump_to_stderr)
522:    def test_remove_empty_parentheses_after_class(self) -> None:
523:        source, expected = read_data("class_blank_parentheses")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        black.assert_equivalent(source, actual)
527:        black.assert_stable(source, actual, black.FileMode())
528:
529:    @patch("black.dump_to_file", dump_to_stderr)
530:    def test_new_line_between_class_and_code(self) -> None:
531:        source, expected = read_data("class_methods_new_line")
532:        actual = fs(source)
533:        self.assertFormatEqual(expected, actual)
534:        black.assert_equivalent(source, actual)
535:        black.assert_stable(source, actual, black.FileMode())
536:
537:    @patch("black.dump_to_file", dump_to_stderr)
538:    def test_bracket_match(self) -> None:
539:        source, expected = read_data("bracketmatch")
540:        actual = fs(source)
541:        self.assertFormatEqual(expected, actual)
542:        black.assert_equivalent(source, actual)
543:        black.assert_stable(source, actual, black.FileMode())
544:
545:    @patch("black.dump_to_file", dump_to_stderr)
546:    def test_tuple_assign(self) -> None:
547:        source, expected = read_data("tupleassign")
548:        actual = fs(source)
549:        self.assertFormatEqual(expected, actual)
550:        black.assert_equivalent(source, actual)
551:        black.assert_stable(source, actual, black.FileMode())
552:
553:    def test_tab_comment_indentation(self) -> None:
554:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t# comment\n\tpass\n"
555:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
556:        self.assertFormatEqual(contents_spc, fs(contents_spc))
557:        self.assertFormatEqual(contents_spc, fs(contents_tab))
558:
559:        contents_tab = "if 1:\n\tif 2:\n\t\tpass\n\t\t# comment\n\tpass\n"
560:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
561:        self.assertFormatEqual(contents_spc, fs(contents_spc))
562:        self.assertFormatEqual(contents_spc, fs(contents_tab))
563:
564:        # mixed tabs and spaces (valid Python 2 code)
565:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t# comment\n        pass\n"
566:        contents_spc = "if 1:\n    if 2:\n        pass\n    # comment\n    pass\n"
567:        self.assertFormatEqual(contents_spc, fs(contents_spc))
568:        self.assertFormatEqual(contents_spc, fs(contents_tab))
569:
570:        contents_tab = "if 1:\n        if 2:\n\t\tpass\n\t\t# comment\n        pass\n"
571:        contents_spc = "if 1:\n    if 2:\n        pass\n        # comment\n    pass\n"
572:        self.assertFormatEqual(contents_spc, fs(contents_spc))
573:        self.assertFormatEqual(contents_spc, fs(contents_tab))
574:
575:    def test_report_verbose(self) -> None:
576:        report = black.Report(verbose=True)
577:        out_lines = []
578:        err_lines = []
579:
580:        def out(msg: str, **kwargs: Any) -> None:
581:            out_lines.append(msg)
582:
583:        def err(msg: str, **kwargs: Any) -> None:
584:            err_lines.append(msg)
585:
586:        with patch("black.out", out), patch("black.err", err):
587:            report.done(Path("f1"), black.Changed.NO)
588:            self.assertEqual(len(out_lines), 1)
589:            self.assertEqual(len(err_lines), 0)
590:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
591:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
592:            self.assertEqual(report.return_code, 0)
593:            report.done(Path("f2"), black.Changed.YES)
594:            self.assertEqual(len(out_lines), 2)
595:            self.assertEqual(len(err_lines), 0)
596:            self.assertEqual(out_lines[-1], "reformatted f2")
597:            self.assertEqual(
598:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
599:            )

Calling tool: globTool
**/*tupleassign*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/tests/data/tupleassign.py
1:sdfjklsdfsjldkflkjsf, sdfjsdfjlksdljkfsdlkf, sdfsdjfklsdfjlksdljkf, sdsfsdfjskdflsfsdf = 1, 2, 3
2:
3:
4:# output
5:(
6:    sdfjklsdfsjldkflkjsf,
7:    sdfjsdfjlksdljkfsdlkf,
8:    sdfsdjfklsdfjlksdljkf,
9:    sdsfsdfjskdflsfsdf,
10:) = (1, 2, 3)

Calling tool: grepTool
elif not \(isinstance\(child, Leaf\) and is_multiline_string\(child\)\):
Matched content:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py normalize_invisible_parens(), when wrapping the LHS testlist_star_expr (index==0) the code now moves the child prefix to the new wrapper Node (lines ~2768–2772). This ensures any leading comments/whitespace on the LHS appear before the inserted '(' as required.

Todo item 12 of 14 is correct
description: 'If comments or leading whitespace precede the LHS tuple in the test, verify the expected output preserves them before the opening '(', consistent with moving the prefix to the wrapper node.'

Validating todo item 13 of 14
description: 'Scan the modified block to ensure no unrelated formatting is applied to siblings (e.g., RHS or trailing commas). The wrapping should be limited to replacing the first child with an atom node containing invisible parens.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2700:        text = format_float_or_int_string(text)
2701:    leaf.value = text
2702:
2703:
2704:def format_float_or_int_string(text: str) -> str:
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In normalize_invisible_parens(), check_lpar is only set when index==0 and the child is a testlist_star_expr. The subsequent wrap replaces only that first child with an atom containing invisible parens, preserving the original prefix on the new wrapper. After this iteration, check_lpar resets to False (child is a Node, not a Leaf), so siblings (RHS, trailing commas) are untouched.

Todo item 13 of 14 is correct
description: 'Scan the modified block to ensure no unrelated formatting is applied to siblings (e.g., RHS or trailing commas). The wrapping should be limited to replacing the first child with an atom node containing invisible parens.'

Validating todo item 14 of 14
description: 'Check that shadowing of the 'index' variable inside the wrapping block (index = child.remove() or 0) does not affect subsequent logic in the same iteration (no further reliance on the loop's index variable after this assignment).'

Calling tool: grepTool
def normalize_invisible_parens\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py:2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2705:    """Formats a float string like "1.0"."""
2706:    if "." not in text:
2707:        return text
2708:
2709:    before, after = text.split(".")
2710:    return f"{before or 0}.{after or 0}"
2711:
2712:
2713:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2714:    """Make existing optional parentheses invisible or create new ones.
2715:
2716:    `parens_after` is a set of string leaf values immeditely after which parens
2717:    should be put.
2718:
2719:    Standardizes on visible parentheses for single-element tuples, and keeps
2720:    existing visible parentheses for other tuples and generator expressions.
2721:    """
2722:    for pc in list_comments(node.prefix, is_endmarker=False):
2723:        if pc.value in FMT_OFF:
2724:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2725:            return
2726:
2727:    check_lpar = False
2728:    for index, child in enumerate(list(node.children)):
2729:        # Add parentheses around long tuple unpacking in assignments.
2730:        if (
2731:            index == 0
2732:            and isinstance(child, Node)
2733:            and child.type == syms.testlist_star_expr
2734:        ):
2735:            check_lpar = True
2736:
2737:        if check_lpar:
2738:            if child.type == syms.atom:
2739:                if maybe_make_parens_invisible_in_atom(child, parent=node):
2740:                    lpar = Leaf(token.LPAR, "")
2741:                    rpar = Leaf(token.RPAR, "")
2742:                    index = child.remove() or 0
2743:                    node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2744:            elif is_one_tuple(child):
2745:                # wrap child in visible parentheses
2746:                lpar = Leaf(token.LPAR, "(")
2747:                rpar = Leaf(token.RPAR, ")")
2748:                child.remove()
2749:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2750:            elif node.type == syms.import_from:
2751:                # "import from" nodes store parentheses directly as part of
2752:                # the statement
2753:                if child.type == token.LPAR:
2754:                    # make parentheses invisible
2755:                    child.value = ""  # type: ignore
2756:                    node.children[-1].value = ""  # type: ignore
2757:                elif child.type != token.STAR:
2758:                    # insert invisible parentheses
2759:                    node.insert_child(index, Leaf(token.LPAR, ""))
2760:                    node.append_child(Leaf(token.RPAR, ""))
2761:                break
2762:
2763:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2764:                # wrap child in invisible parentheses
2765:                lpar = Leaf(token.LPAR, "")
2766:                rpar = Leaf(token.RPAR, "")
2767:                index = child.remove() or 0
2768:                prefix = child.prefix
2769:                child.prefix = ""
2770:                new_child = Node(syms.atom, [lpar, child, rpar])
2771:                new_child.prefix = prefix
2772:                node.insert_child(index, new_child)
2773:
2774:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2775:
2776:
2777:def normalize_fmt_off(node: Node) -> None:
2778:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2779:    try_again = True
2780:    while try_again:
2781:        try_again = convert_one_fmt_off_pair(node)
2782:
2783:
2784:def convert_one_fmt_off_pair(node: Node) -> bool:
2785:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2786:
2787:    Returns True if a pair was converted.
2788:    """
2789:    for leaf in node.leaves():
2790:        previous_consumed = 0
2791:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2792:            if comment.value in FMT_OFF:
2793:                # We only want standalone comments. If there's no previous leaf or
2794:                # the previous leaf is indentation, it's a standalone comment in
2795:                # disguise.
2796:                if comment.type != STANDALONE_COMMENT:
2797:                    prev = preceding_leaf(leaf)
2798:                    if prev and prev.type not in WHITESPACE:
2799:                        continue
2800:
2801:                ignored_nodes = list(generate_ignored_nodes(leaf))
2802:                if not ignored_nodes:
2803:                    continue
2804:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-7/good/black/black.py
2805:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2806:                parent = first.parent
2807:                prefix = first.prefix
2808:                first.prefix = prefix[comment.consumed :]
2809:                hidden_value = (
2810:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2811:                )
2812:                if hidden_value.endswith("\n"):
2813:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2814:                    # leaf (possibly followed by a DEDENT).
2815:                    hidden_value = hidden_value[:-1]
2816:                first_idx = None
2817:                for ignored in ignored_nodes:
2818:                    index = ignored.remove()
2819:                    if first_idx is None:
2820:                        first_idx = index
2821:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2822:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2823:                parent.insert_child(
2824:                    first_idx,
2825:                    Leaf(
2826:                        STANDALONE_COMMENT,
2827:                        hidden_value,
2828:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2829:                    ),
2830:                )
2831:                return True
2832:
2833:            previous_consumed = comment.consumed
2834:
2835:    return False
2836:
2837:
2838:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2839:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2840:
2841:    Stops at the end of the block.
2842:    """
2843:    container: Optional[LN] = container_of(leaf)
2844:    while container is not None and container.type != token.ENDMARKER:
2845:        for comment in list_comments(container.prefix, is_endmarker=False):
2846:            if comment.value in FMT_ON:
2847:                return
2848:
2849:        yield container
2850:
2851:        container = container.next_sibling
2852:
2853:
2854:def maybe_make_parens_invisible_in_atom(node: LN, parent: LN) -> bool:
2855:    """If it's safe, make the parens in the atom `node` invisible, recursively.
2856:
2857:    Returns whether the node should itself be wrapped in invisible parentheses.
2858:
2859:    """
2860:    if (
2861:        node.type != syms.atom
2862:        or is_empty_tuple(node)
2863:        or is_one_tuple(node)
2864:        or (is_yield(node) and parent.type != syms.expr_stmt)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Reviewed normalize_invisible_parens: after reassigning `index = child.remove() or 0`, the only subsequent use of `index` is the immediate insert. The remaining logic in that iteration doesn’t reference `index` (the if/elif chain is exclusive, ends with setting `check_lpar` based on `child`), and the next loop iteration resets `index`. No reliance on the original loop index after reassignment.

Todo item 14 of 14 is correct
description: 'Check that shadowing of the 'index' variable inside the wrapping block (index = child.remove() or 0) does not affect subsequent logic in the same iteration (no further reliance on the loop's index variable after this assignment).'


=== PHASE 2 COMPLETE ===

