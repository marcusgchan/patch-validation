=== PHASE 1: ANALYSIS ===

Calling tool: createTodo
Todo List Created
Todo List (10 items):
- [ ] In `split_line()`, verify the new early-return condition includes `not has_special_comment` along with `not line.should_explode` and `is_line_short_enough(...)`, ensuring lines with special comments are not returned unmodified. (ID: todo-1)
- [ ] Confirm the scanning logic for `has_special_comment` iterates all `line.leaves` and, for each, all `line.comments_after(leaf)`, and sets `has_special_comment = True` only when `leaf.type == token.COMMA` and `is_special_comment(comment)` is True. (ID: todo-2)
- [ ] Check that `is_special_comment()` is defined and returns True only for leaves where `(leaf.type == token.COMMENT or leaf.type == STANDALONE_COMMENT)` and `leaf.value.startswith('# type:')`. (ID: todo-3)
- [ ] Verify that `STANDALONE_COMMENT` is defined in the module and corresponds to the token type used elsewhere for standalone comments to avoid a NameError at runtime. (ID: todo-4)
- [ ] Verify `token` is imported in the module and that `token.COMMENT` is a valid token type used elsewhere in the file (consistency check). (ID: todo-5)
- [ ] Ensure that objects yielded by `line.comments_after(leaf)` are `Leaf` instances (or have `.type` and `.value` attributes), so they are compatible with `is_special_comment()` usage. (ID: todo-6)
- [ ] Confirm that the new logic only treats comments beginning exactly with `'# type:'` as special; comments with other prefixes (e.g., `# foo`) do not set `has_special_comment` to True. (ID: todo-7)
- [ ] Validate that the added logic does not change behavior for lines without special comments: when `has_special_comment` remains False, the original short-line early return still triggers unchanged. (ID: todo-8)
- [ ] Review that `is_special_comment()` is declared at module scope before any potential use at import time (it is only called within `split_line()` during execution, so definition order is safe). (ID: todo-9)
- [ ] Inspect `tests` for `test_comments6` to ensure it exercises a multiline function with per-parameter `# type:` comments (and a trailing return type comment) and asserts formatting is not collapsed into a single line containing multiple `# type:` comments, matching the PR intent to preserve multiline in this case. (ID: todo-10)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 10
description: 'In `split_line()`, verify the new early-return condition includes `not has_special_comment` along with `not line.should_explode` and `is_line_short_enough(...)`, ensuring lines with special comments are not returned unmodified.'
Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)
2208:    for result in (head, body, tail):
2209:        if result:
2210:            yield result
2211:
2212:
2213:def right_hand_split(
2214:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2215:) -> Iterator[Line]:
2216:    """Split line into many lines, starting with the last matching bracket pair.

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s split_line(), lines 2124–2129 show the early-return condition now includes `not has_special_comment` alongside `not line.should_explode` and `is_line_short_enough(...)`. The detection of special comments is implemented above, ensuring such lines aren’t returned unmodified.


Todo item 1 of 10 is correct
description: 'In `split_line()`, verify the new early-return condition includes `not has_special_comment` along with `not line.should_explode` and `is_line_short_enough(...)`, ensuring lines with special comments are not returned unmodified.'
Validating todo item 2 of 10
description: 'Confirm the scanning logic for `has_special_comment` iterates all `line.leaves` and, for each, all `line.comments_after(leaf)`, and sets `has_special_comment = True` only when `leaf.type == token.COMMA` and `is_special_comment(comment)` is True.'
Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py

Calling tool: grepTool
def split_line\(
Matched content:
2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)
2208:    for result in (head, body, tail):
2209:        if result:
2210:            yield result
2211:
2212:
2213:def right_hand_split(
2214:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2215:) -> Iterator[Line]:
2216:    """Split line into many lines, starting with the last matching bracket pair.

Calling tool: grepTool
def is_special_comment\(
Matched content:
2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: grepTool
has_special_comment
Matched content:
2118:    has_special_comment = False
2122:                has_special_comment = True
2125:        not has_special_comment

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2118-2126, the code iterates over all line.leaves and for each leaf over line.comments_after(leaf), setting has_special_comment = True only when leaf.type == token.COMMA and is_special_comment(comment) returns True.


Todo item 2 of 10 is correct
description: 'Confirm the scanning logic for `has_special_comment` iterates all `line.leaves` and, for each, all `line.comments_after(leaf)`, and sets `has_special_comment = True` only when `leaf.type == token.COMMA` and `is_special_comment(comment)` is True.'
Validating todo item 3 of 10
description: 'Check that `is_special_comment()` is defined and returns True only for leaves where `(leaf.type == token.COMMENT or leaf.type == STANDALONE_COMMENT)` and `leaf.value.startswith('# type:')`.'
Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.
2510:    """
2511:    match = re.match(r"^([furbFURB]*)(.*)$", leaf.value, re.DOTALL)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Found is_special_comment in black.py at lines 2476-2483. It returns bool((t == token.COMMENT or t == STANDALONE_COMMENT) and v.startswith("# type:")), matching the requirement exactly.


Todo item 3 of 10 is correct
description: 'Check that `is_special_comment()` is defined and returns True only for leaves where `(leaf.type == token.COMMENT or leaf.type == STANDALONE_COMMENT)` and `leaf.value.startswith('# type:')`.'
Validating todo item 4 of 10
description: 'Verify that `STANDALONE_COMMENT` is defined in the module and corresponds to the token type used elsewhere for standalone comments to avoid a NameError at runtime.'
Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:793:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1161:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1231:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1241:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2067:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2735:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2765:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
780:KEYWORDS = set(keyword.kwlist)
781:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
782:FLOW_CONTROL = {"return", "raise", "break", "continue"}
783:STATEMENT = {
784:    syms.if_stmt,
785:    syms.while_stmt,
786:    syms.for_stmt,
787:    syms.try_stmt,
788:    syms.except_clause,
789:    syms.with_stmt,
790:    syms.funcdef,
791:    syms.classdef,
792:}
793:STANDALONE_COMMENT = 153
794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
795:LOGIC_OPERATORS = {"and", "or"}
796:COMPARATORS = {
797:    token.LESS,
798:    token.GREATER,
799:    token.EQEQUAL,
800:    token.NOTEQUAL,
801:    token.LESSEQUAL,
802:    token.GREATEREQUAL,
803:}
804:MATH_OPERATORS = {
805:    token.VBAR,
806:    token.CIRCUMFLEX,
807:    token.AMPER,
808:    token.LEFTSHIFT,
809:    token.RIGHTSHIFT,
810:    token.PLUS,
811:    token.MINUS,
812:    token.STAR,
813:    token.SLASH,
814:    token.DOUBLESLASH,
815:    token.PERCENT,
816:    token.AT,
817:    token.TILDE,
818:    token.DOUBLESTAR,
819:}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2000:
2001:
2002:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
2003:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
2004:
2005:
2006:def generate_comments(leaf: LN) -> Iterator[Leaf]:
2007:    """Clean the prefix of the `leaf` and generate comments from it, if any.
2008:
2009:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
2010:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
2011:    move because it does away with modifying the grammar to include all the
2012:    possible places in which comments can be placed.
2013:
2014:    The sad consequence for us though is that comments don't "belong" anywhere.
2015:    This is why this function generates simple parentless Leaf objects for
2016:    comments.  We simply don't know what the correct parent should be.
2017:
2018:    No matter though, we can live without this.  We really only need to
2019:    differentiate between inline and standalone comments.  The latter don't
2020:    share the line with any code.
2021:
2022:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
2024:    """
2025:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
2026:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
2027:
2028:
2029:@dataclass
2030:class ProtoComment:
2031:    """Describes a piece of syntax that is a comment.
2032:
2033:    It's not a :class:`blib2to3.pytree.Leaf` so that:
2034:
2035:    * it can be cached (`Leaf` objects should not be reused more than once as
2036:      they store their lineno, column, prefix, and parent information);
2037:    * `newlines` and `consumed` fields are kept separate from the `value`. This
2038:      simplifies handling of special marker comments like ``# fmt: off/on``.
2039:    """
2040:
2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
2042:    value: str  # content of the comment
2043:    newlines: int  # how many newlines before the comment
2044:    consumed: int  # how many characters of the original leaf's prefix did we consume
2045:
2046:
2047:@lru_cache(maxsize=4096)
2048:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2049:    """Return a list of :class:`ProtoComment` objects parsed from the given `prefix`."""
2050:    result: List[ProtoComment] = []
2051:    if not prefix or "#" not in prefix:
2052:        return result
2053:
2054:    consumed = 0
2055:    nlines = 0
2056:    for index, line in enumerate(prefix.split("\n")):
2057:        consumed += len(line) + 1  # adding the length of the split '\n'
2058:        line = line.lstrip()
2059:        if not line:
2060:            nlines += 1
2061:        if not line.startswith("#"):
2062:            continue
2063:
2064:        if index == 0 and not is_endmarker:
2065:            comment_type = token.COMMENT  # simple trailing comment
2066:        else:
2067:            comment_type = STANDALONE_COMMENT
2068:        comment = make_comment(line)
2069:        result.append(
2070:            ProtoComment(
2071:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2072:            )
2073:        )
2074:        nlines = 0
2075:    return result
2076:
2077:
2078:def make_comment(content: str) -> str:
2079:    """Return a consistently formatted comment from the given `content` string.
2080:
2081:    All comments (except for "##", "#!", "#:", '#'", "#%%") should have a single
2082:    space between the hash sign and the content.
2083:
2084:    If `content` didn't start with a hash sign, one is provided.
2085:    """
2086:    content = content.rstrip()
2087:    if not content:
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2450:            current_line.append(leaf)
2451:
2452:    for leaf in line.leaves:
2453:        yield from append_to_line(leaf)
2454:
2455:        for comment_after in line.comments_after(leaf):
2456:            yield from append_to_line(comment_after)
2457:
2458:    if current_line:
2459:        yield current_line
2460:
2461:
2462:def is_import(leaf: Leaf) -> bool:
2463:    """Return True if the given leaf starts an import statement."""
2464:    p = leaf.parent
2465:    t = leaf.type
2466:    v = leaf.value
2467:    return bool(
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1558:
1559:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1560:        """Visit decorators."""
1561:        for child in node.children:
1562:            yield from self.line()
1563:            yield from self.visit(child)
1564:
1565:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1566:        """Remove a semicolon and put the other statement on a separate line."""
1567:        yield from self.line()
1568:
1569:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1570:        """End of file. Process outstanding comments and end with a newline."""
1571:        yield from self.visit_default(leaf)
1572:        yield from self.line()
1573:
1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1575:        if not self.current_line.bracket_tracker.any_open_brackets():
1576:            yield from self.line()
1577:        yield from self.visit_default(leaf)
1578:
1579:    def __attrs_post_init__(self) -> None:
1580:        """You are in a twisty little maze of passages."""
1581:        v = self.visit_stmt
1582:        Ø: Set[str] = set()
1583:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1584:        self.visit_if_stmt = partial(
1585:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1586:        )
1587:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1588:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1589:        self.visit_try_stmt = partial(
1590:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1591:        )
1592:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1593:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1594:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1595:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1596:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1597:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: STANDALONE_COMMENT is defined at module level (black.py:793) and registered in token.tok_name. It is used elsewhere as the token type for standalone comments (e.g., in list_comments setting comment_type=STANDALONE_COMMENT and visit_STANDALONE_COMMENT). The new is_special_comment correctly references it, so no NameError will occur.


Todo item 4 of 10 is correct
description: 'Verify that `STANDALONE_COMMENT` is defined in the module and corresponds to the token type used elsewhere for standalone comments to avoid a NameError at runtime.'
Validating todo item 5 of 10
description: 'Verify `token` is imported in the module and that `token.COMMENT` is a valid token type used elsewhere in the file (consistency check).'
Calling tool: grepTool
(?i)^import token|from .* import token|pgen2\.token|blib2to3.*token
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:18:import tokenize
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:47:from blib2to3.pgen2 import driver, token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:26:        # from .pgen2 import token // token.__dict__.items():
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:361:        from .pgen2.token import tok_name
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.py:34:from blib2to3.pgen2.token import *
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.py:36:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/pgen.pyi:7:from blib2to3.pgen2.tokenize import _TokenInfo
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/grammar.py:19:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/parse.py:14:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.py:4:#   originally monkeypatched in by pgen2.tokenize
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.pyi:1:# Stubs for lib2to3.pgen2.tokenize (Python 3.6)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.pyi:5:from blib2to3.pgen2.token import *  # noqa
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.pyi:1:# Stubs for lib2to3.pgen2.token (Python 3.6)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pygram.py:10:from .pgen2 import token

Calling tool: grepTool
token\.COMMENT|token\.COMMA|STANDALONE_COMMENT
Matched content:
793:STANDALONE_COMMENT = 153
794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
919:        if leaf.type == token.COMMENT:
1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1161:            if leaf.type == STANDALONE_COMMENT:
1178:            and self.leaves[-1].type == token.COMMA
1216:            if bracket_depth == depth and leaf.type == token.COMMA:
1231:            comment.type == STANDALONE_COMMENT
1237:        if comment.type != token.COMMENT:
1241:            comment.type = STANDALONE_COMMENT
1458:                elif comment.type == token.COMMENT:
1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1626:    if t == token.COMMENT:
1647:            elif prevp.type != token.COMMA and not complex_subscript:
1699:        if not prev or prev.type != token.COMMA:
1704:        if prev and prev.type != token.COMMA:
1721:        elif prev.type != token.COMMA:
1728:            if not prevp or prevp.type != token.COMMA:
1745:        elif prev.type != token.COMMA:
1900:    if leaf.type == token.COMMA:
2022:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
2065:            comment_type = token.COMMENT  # simple trailing comment
2067:            comment_type = STANDALONE_COMMENT
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2342:                if leaves[-1].type != token.COMMA:
2343:                    leaves.append(Leaf(token.COMMA, ","))
2426:            and current_line.leaves[-1].type != token.COMMA
2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2429:            current_line.append(Leaf(token.COMMA, ","))
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2735:                if comment.type != STANDALONE_COMMENT:
2765:                        STANDALONE_COMMENT,
2845:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2850:        and node.children[1].type == token.COMMA
2985:        exclude = {id(last_leaf)} if last_leaf.type == token.COMMA else set()
3014:            and n.children[-1].type == token.COMMA
3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import itertools
9:import keyword
10:import logging
11:from multiprocessing import Manager, freeze_support
12:import os
13:from pathlib import Path
14:import pickle
15:import re
16:import signal
17:import sys
18:import tokenize
19:from typing import (
20:    Any,
21:    Callable,
22:    Collection,
23:    Dict,
24:    Generator,
25:    Generic,
26:    Iterable,
27:    Iterator,
28:    List,
29:    Optional,
30:    Pattern,
31:    Sequence,
32:    Set,
33:    Tuple,
34:    TypeVar,
35:    Union,
36:    cast,
37:)
38:
39:from appdirs import user_cache_dir
40:from attr import dataclass, Factory
41:import click
42:import toml
43:
44:# lib2to3 fork
45:from blib2to3.pytree import Node, Leaf, type_repr
46:from blib2to3 import pygram, pytree
47:from blib2to3.pgen2 import driver, token
48:from blib2to3.pgen2.parse import ParseError
49:
50:
51:__version__ = "18.9b0"
52:DEFAULT_LINE_LENGTH = 88
53:DEFAULT_EXCLUDES = (
54:    r"/(\.eggs|\.git|\.hg|\.mypy_cache|\.nox|\.tox|\.venv|_build|buck-out|build|dist)/"
55:)
56:DEFAULT_INCLUDES = r"\.pyi?$"
57:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
58:
59:
60:# types
61:FileContent = str
62:Encoding = str
63:NewLine = str
64:Depth = int
65:NodeType = int
66:LeafID = int
67:Priority = int
68:Index = int
69:LN = Union[Leaf, Node]
70:SplitFunc = Callable[["Line", bool], Iterator["Line"]]

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.py
1:"""Token constants (from "token.h")."""
2:
3:#  Taken from Python (r53757) and modified to include some tokens
4:#   originally monkeypatched in by pgen2.tokenize
5:
6:#--start constants--
7:ENDMARKER = 0
8:NAME = 1
9:NUMBER = 2
10:STRING = 3
11:NEWLINE = 4
12:INDENT = 5
13:DEDENT = 6
14:LPAR = 7
15:RPAR = 8
16:LSQB = 9
17:RSQB = 10
18:COLON = 11
19:COMMA = 12
20:SEMI = 13
21:PLUS = 14
22:MINUS = 15
23:STAR = 16
24:SLASH = 17
25:VBAR = 18
26:AMPER = 19
27:LESS = 20
28:GREATER = 21
29:EQUAL = 22
30:DOT = 23
31:PERCENT = 24
32:BACKQUOTE = 25
33:LBRACE = 26
34:RBRACE = 27
35:EQEQUAL = 28
36:NOTEQUAL = 29
37:LESSEQUAL = 30
38:GREATEREQUAL = 31
39:TILDE = 32
40:CIRCUMFLEX = 33
41:LEFTSHIFT = 34
42:RIGHTSHIFT = 35
43:DOUBLESTAR = 36
44:PLUSEQUAL = 37
45:MINEQUAL = 38
46:STAREQUAL = 39
47:SLASHEQUAL = 40
48:PERCENTEQUAL = 41
49:AMPEREQUAL = 42
50:VBAREQUAL = 43
51:CIRCUMFLEXEQUAL = 44
52:LEFTSHIFTEQUAL = 45
53:RIGHTSHIFTEQUAL = 46
54:DOUBLESTAREQUAL = 47
55:DOUBLESLASH = 48
56:DOUBLESLASHEQUAL = 49
57:AT = 50
58:ATEQUAL = 51
59:OP = 52
60:COMMENT = 53
61:NL = 54
62:RARROW = 55
63:AWAIT = 56
64:ASYNC = 57
65:ERRORTOKEN = 58
66:N_TOKENS = 59
67:NT_OFFSET = 256
68:#--end constants--
69:
70:tok_name = {}
71:for _name, _value in list(globals().items()):
72:    if type(_value) is type(0):
73:        tok_name[_value] = _name
74:
75:
76:def ISTERMINAL(x):
77:    return x < NT_OFFSET
78:
79:def ISNONTERMINAL(x):
80:    return x >= NT_OFFSET
81:
82:def ISEOF(x):
83:    return x == ENDMARKER

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `black.py` imports `token` from blib2to3.pgen2 (line 47) and `token.COMMENT` is a defined token (blib2to3/pgen2/token.py line 60) and already used multiple times within `black.py` (e.g., lines 919, 1237, 1458, 1626), confirming consistency.


Todo item 5 of 10 is correct
description: 'Verify `token` is imported in the module and that `token.COMMENT` is a valid token type used elsewhere in the file (consistency check).'
Validating todo item 6 of 10
description: 'Ensure that objects yielded by `line.comments_after(leaf)` are `Leaf` instances (or have `.type` and `.value` attributes), so they are compatible with `is_special_comment()` usage.'
Calling tool: grepTool
class Line\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1026:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1000:        if leaf.type == token.NAME and leaf.value == "lambda":
1001:            self.depth += 1
1002:            self._lambda_argument_depths.append(self.depth)
1003:            return True
1004:
1005:        return False
1006:
1007:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
1008:        """See `maybe_increment_lambda_arguments` above for explanation."""
1009:        if (
1010:            self._lambda_argument_depths
1011:            and self._lambda_argument_depths[-1] == self.depth
1012:            and leaf.type == token.COLON
1013:        ):
1014:            self.depth -= 1
1015:            self._lambda_argument_depths.pop()
1016:            return True
1017:
1018:        return False
1019:
1020:    def get_open_lsqb(self) -> Optional[Leaf]:
1021:        """Return the most recent opening square bracket (if any)."""
1022:        return self.bracket_match.get((self.depth - 1, token.RSQB))
1023:
1024:
1025:@dataclass
1026:class Line:
1027:    """Holds leaves and comments. Can be printed with `str(line)`."""
1028:
1029:    depth: int = 0
1030:    leaves: List[Leaf] = Factory(list)
1031:    # The LeafID keys of comments must remain ordered by the corresponding leaf's index
1032:    # in leaves
1033:    comments: Dict[LeafID, List[Leaf]] = Factory(dict)
1034:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1035:    inside_brackets: bool = False
1036:    should_explode: bool = False
1037:
1038:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1039:        """Add a new `leaf` to the end of the line.
1040:
1041:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1042:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1043:        Trailing commas are maybe removed, unpacked for loop variables are
1044:        demoted from being delimiters.
1045:
1046:        Inline comments are put aside.
1047:        """
1048:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1049:        if not has_value:
1050:            return
1051:
1052:        if token.COLON == leaf.type and self.is_class_paren_empty:
1053:            del self.leaves[-2:]
1054:        if self.leaves and not preformatted:
1055:            # Note: at this point leaf.prefix should be empty except for
1056:            # imports, for which we only preserve newlines.
1057:            leaf.prefix += whitespace(
1058:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1059:            )
1060:        if self.inside_brackets or not preformatted:
1061:            self.bracket_tracker.mark(leaf)
1062:            self.maybe_remove_trailing_comma(leaf)
1063:        if not self.append_comment(leaf):
1064:            self.leaves.append(leaf)
1065:
1066:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1067:        """Like :func:`append()` but disallow invalid standalone comment structure.
1068:
1069:        Raises ValueError when any `leaf` is appended after a standalone comment
1070:        or when a standalone comment is not the first leaf on the line.
1071:        """
1072:        if self.bracket_tracker.depth == 0:
1073:            if self.is_comment:
1074:                raise ValueError("cannot append to standalone comments")
1075:
1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1077:                raise ValueError(
1078:                    "cannot append standalone comments to a populated line"
1079:                )
1080:
1081:        self.append(leaf, preformatted=preformatted)
1082:
1083:    @property
1084:    def is_comment(self) -> bool:
1085:        """Is this line a standalone comment?"""
1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1087:
1088:    @property
1089:    def is_decorator(self) -> bool:
1090:        """Is this line a decorator?"""
1091:        return bool(self) and self.leaves[0].type == token.AT
1092:
1093:    @property
1094:    def is_import(self) -> bool:
1095:        """Is this an import line?"""
1096:        return bool(self) and is_import(self.leaves[0])
1097:
1098:    @property
1099:    def is_class(self) -> bool:
1100:        """Is this line a class definition?"""
1101:        return (
1102:            bool(self)
1103:            and self.leaves[0].type == token.NAME
1104:            and self.leaves[0].value == "class"
1105:        )
1106:
1107:    @property
1108:    def is_stub_class(self) -> bool:
1109:        """Is this line a class definition with a body consisting only of "..."?"""
1110:        return self.is_class and self.leaves[-3:] == [
1111:            Leaf(token.DOT, ".") for _ in range(3)
1112:        ]
1113:
1114:    @property
1115:    def is_def(self) -> bool:
1116:        """Is this a function definition? (Also returns True for async defs.)"""
1117:        try:
1118:            first_leaf = self.leaves[0]
1119:        except IndexError:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1120:            return False
1121:
1122:        try:
1123:            second_leaf: Optional[Leaf] = self.leaves[1]
1124:        except IndexError:
1125:            second_leaf = None
1126:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1127:            first_leaf.type == token.ASYNC
1128:            and second_leaf is not None
1129:            and second_leaf.type == token.NAME
1130:            and second_leaf.value == "def"
1131:        )
1132:
1133:    @property
1134:    def is_class_paren_empty(self) -> bool:
1135:        """Is this a class with no base classes but using parentheses?
1136:
1137:        Those are unnecessary and should be removed.
1138:        """
1139:        return (
1140:            bool(self)
1141:            and len(self.leaves) == 4
1142:            and self.is_class
1143:            and self.leaves[2].type == token.LPAR
1144:            and self.leaves[2].value == "("
1145:            and self.leaves[3].type == token.RPAR
1146:            and self.leaves[3].value == ")"
1147:        )
1148:
1149:    @property
1150:    def is_triple_quoted_string(self) -> bool:
1151:        """Is the line a triple quoted string?"""
1152:        return (
1153:            bool(self)
1154:            and self.leaves[0].type == token.STRING
1155:            and self.leaves[0].value.startswith(('"""', "'''"))
1156:        )
1157:
1158:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1159:        """If so, needs to be split before emitting."""
1160:        for leaf in self.leaves:
1161:            if leaf.type == STANDALONE_COMMENT:
1162:                if leaf.bracket_depth <= depth_limit:
1163:                    return True
1164:
1165:        return False
1166:
1167:    def contains_multiline_strings(self) -> bool:
1168:        for leaf in self.leaves:
1169:            if is_multiline_string(leaf):
1170:                return True
1171:
1172:        return False
1173:
1174:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1175:        """Remove trailing comma if there is one and it's safe."""
1176:        if not (
1177:            self.leaves
1178:            and self.leaves[-1].type == token.COMMA
1179:            and closing.type in CLOSING_BRACKETS
1180:        ):
1181:            return False
1182:
1183:        if closing.type == token.RBRACE:
1184:            self.remove_trailing_comma()
1185:            return True
1186:
1187:        if closing.type == token.RSQB:
1188:            comma = self.leaves[-1]
1189:            if comma.parent and comma.parent.type == syms.listmaker:
1190:                self.remove_trailing_comma()
1191:                return True
1192:
1193:        # For parens let's check if it's safe to remove the comma.
1194:        # Imports are always safe.
1195:        if self.is_import:
1196:            self.remove_trailing_comma()
1197:            return True
1198:
1199:        # Otherwise, if the trailing one is the only one, we might mistakenly
1200:        # change a tuple into a different type by removing the comma.
1201:        depth = closing.bracket_depth + 1
1202:        commas = 0
1203:        opening = closing.opening_bracket
1204:        for _opening_index, leaf in enumerate(self.leaves):
1205:            if leaf is opening:
1206:                break
1207:
1208:        else:
1209:            return False
1210:
1211:        for leaf in self.leaves[_opening_index + 1 :]:
1212:            if leaf is closing:
1213:                break
1214:
1215:            bracket_depth = leaf.bracket_depth
1216:            if bracket_depth == depth and leaf.type == token.COMMA:
1217:                commas += 1
1218:                if leaf.parent and leaf.parent.type == syms.arglist:
1219:                    commas += 1
1220:                    break
1221:
1222:        if commas > 1:
1223:            self.remove_trailing_comma()
1224:            return True
1225:
1226:        return False
1227:
1228:    def append_comment(self, comment: Leaf) -> bool:
1229:        """Add an inline or standalone comment to the line."""
1230:        if (
1231:            comment.type == STANDALONE_COMMENT
1232:            and self.bracket_tracker.any_open_brackets()
1233:        ):
1234:            comment.prefix = ""
1235:            return False
1236:
1237:        if comment.type != token.COMMENT:
1238:            return False
1239:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1240:        if not self.leaves:
1241:            comment.type = STANDALONE_COMMENT
1242:            comment.prefix = ""
1243:            return False
1244:
1245:        else:
1246:            leaf_id = id(self.leaves[-1])
1247:            if leaf_id not in self.comments:
1248:                self.comments[leaf_id] = [comment]
1249:            else:
1250:                self.comments[leaf_id].append(comment)
1251:            return True
1252:
1253:    def comments_after(self, leaf: Leaf) -> List[Leaf]:
1254:        """Generate comments that should appear directly after `leaf`."""
1255:        return self.comments.get(id(leaf), [])
1256:
1257:    def remove_trailing_comma(self) -> None:
1258:        """Remove the trailing comma and moves the comments attached to it."""
1259:        # Remember, the LeafID keys of self.comments are ordered by the
1260:        # corresponding leaf's index in self.leaves
1261:        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.
1262:        # Otherwise, we insert it into self.comments, and it becomes the last entry.
1263:        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant
1264:        # is maintained
1265:        self.comments.setdefault(id(self.leaves[-2]), []).extend(
1266:            self.comments.get(id(self.leaves[-1]), [])
1267:        )
1268:        self.comments.pop(id(self.leaves[-1]), None)
1269:        self.leaves.pop()
1270:
1271:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1272:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1273:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1274:        if open_lsqb is None:
1275:            return False
1276:
1277:        subscript_start = open_lsqb.next_sibling
1278:
1279:        if isinstance(subscript_start, Node):
1280:            if subscript_start.type == syms.listmaker:
1281:                return False
1282:
1283:            if subscript_start.type == syms.subscriptlist:
1284:                subscript_start = child_towards(subscript_start, leaf)
1285:        return subscript_start is not None and any(
1286:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1287:        )
1288:
1289:    def __str__(self) -> str:
1290:        """Render the line."""
1291:        if not self:
1292:            return "\n"
1293:
1294:        indent = "    " * self.depth
1295:        leaves = iter(self.leaves)
1296:        first = next(leaves)
1297:        res = f"{first.prefix}{indent}{first.value}"
1298:        for leaf in leaves:
1299:            res += str(leaf)
1300:        for comment in itertools.chain.from_iterable(self.comments.values()):
1301:            res += str(comment)
1302:        return res + "\n"
1303:
1304:    def __bool__(self) -> bool:
1305:        """Return True if the line has leaves or comments."""
1306:        return bool(self.leaves or self.comments)
1307:
1308:
1309:@dataclass
1310:class EmptyLineTracker:
1311:    """Provides a stateful method that returns the number of potential extra
1312:    empty lines needed before and after the currently processed line.
1313:
1314:    Note: this tracker works on lines that haven't been split yet.  It assumes
1315:    the prefix of the first leaf consists of optional newlines.  Those newlines
1316:    are consumed by `maybe_empty_lines()` and included in the computation.
1317:    """
1318:
1319:    is_pyi: bool = False
1320:    previous_line: Optional[Line] = None
1321:    previous_after: int = 0
1322:    previous_defs: List[int] = Factory(list)
1323:
1324:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1325:        """Return the number of extra empty lines before and after the `current_line`.
1326:
1327:        This is for separating `def`, `async def` and `class` with extra empty
1328:        lines (two on module-level).
1329:        """
1330:        before, after = self._maybe_empty_lines(current_line)
1331:        before -= self.previous_after
1332:        self.previous_after = after
1333:        self.previous_line = current_line
1334:        return before, after
1335:
1336:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1337:        max_allowed = 1
1338:        if current_line.depth == 0:
1339:            max_allowed = 1 if self.is_pyi else 2
1340:        if current_line.leaves:
1341:            # Consume the first leaf's extra newlines.
1342:            first_leaf = current_line.leaves[0]
1343:            before = first_leaf.prefix.count("\n")
1344:            before = min(before, max_allowed)
1345:            first_leaf.prefix = ""
1346:        else:
1347:            before = 0
1348:        depth = current_line.depth
1349:        while self.previous_defs and self.previous_defs[-1] >= depth:
1350:            self.previous_defs.pop()
1351:            if self.is_pyi:
1352:                before = 0 if depth else 1
1353:            else:
1354:                before = 1 if depth else 2
1355:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1356:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1357:
1358:        if (
1359:            self.previous_line

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2450:            current_line.append(leaf)
2451:
2452:    for leaf in line.leaves:
2453:        yield from append_to_line(leaf)
2454:
2455:        for comment_after in line.comments_after(leaf):
2456:            yield from append_to_line(comment_after)
2457:
2458:    if current_line:
2459:        yield current_line
2460:
2461:
2462:def is_import(leaf: Leaf) -> bool:
2463:    """Return True if the given leaf starts an import statement."""
2464:    p = leaf.parent
2465:    t = leaf.type
2466:    v = leaf.value
2467:    return bool(
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2085:    """
2086:    content = content.rstrip()
2087:    if not content:
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `Line.comments_after()` returns values from `self.comments`, which is a Dict[LeafID, List[Leaf>] populated by `append_comment()` with `Leaf` instances. Thus, items yielded are `Leaf`s with `.type` and `.value`, compatible with `is_special_comment()`.


Todo item 6 of 10 is correct
description: 'Ensure that objects yielded by `line.comments_after(leaf)` are `Leaf` instances (or have `.type` and `.value` attributes), so they are compatible with `is_special_comment()` usage.'
Validating todo item 7 of 10
description: 'Confirm that the new logic only treats comments beginning exactly with `'# type:'` as special; comments with other prefixes (e.g., `# foo`) do not set `has_special_comment` to True.'
Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:

Calling tool: grepTool
is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2121:            if leaf.type == token.COMMA and is_special_comment(comment):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The implementation uses is_special_comment() which returns True only if the comment leaf’s value starts with the exact prefix "# type:". In split_line(), has_special_comment is set only when such a comment appears after a comma. Comments like "# foo" don’t match startswith("# type:") and therefore won’t set has_special_comment to True.


Todo item 7 of 10 is correct
description: 'Confirm that the new logic only treats comments beginning exactly with `'# type:'` as special; comments with other prefixes (e.g., `# foo`) do not set `has_special_comment` to True.'
Validating todo item 8 of 10
description: 'Validate that the added logic does not change behavior for lines without special comments: when `has_special_comment` remains False, the original short-line early return still triggers unchanged.'
Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In split_line(), the early return condition was extended to include “not has_special_comment”. For lines without special comments, has_special_comment remains False, so the condition reduces to the original (not line.should_explode and is_line_short_enough(...)). The added scanning loop is read-only and doesn’t alter line state, preserving behavior.


Todo item 8 of 10 is correct
description: 'Validate that the added logic does not change behavior for lines without special comments: when `has_special_comment` remains False, the original short-line early return still triggers unchanged.'
Validating todo item 9 of 10
description: 'Review that `is_special_comment()` is declared at module scope before any potential use at import time (it is only called within `split_line()` during execution, so definition order is safe).'
Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: grepTool
is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2121:            if leaf.type == token.COMMA and is_special_comment(comment):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: grepTool
def split_line\(|split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:654:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
620:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
621:    return dst_contents
622:
623:
624:def format_str(
625:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
626:) -> FileContent:
627:    """Reformat a string and return new contents.
628:
629:    `line_length` determines how many characters per line are allowed.
630:    """
631:    src_node = lib2to3_parse(src_contents.lstrip())
632:    dst_contents = ""
633:    future_imports = get_future_imports(src_node)
634:    is_pyi = bool(mode & FileMode.PYI)
635:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
636:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
637:    normalize_fmt_off(src_node)
638:    lines = LineGenerator(
639:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
640:        is_pyi=is_pyi,
641:        normalize_strings=normalize_strings,
642:        allow_underscores=py36
643:        and not bool(mode & FileMode.NO_NUMERIC_UNDERSCORE_NORMALIZATION),
644:    )
645:    elt = EmptyLineTracker(is_pyi=is_pyi)
646:    empty_line = Line()
647:    after = 0
648:    for current_line in lines.visit(src_node):
649:        for _ in range(after):
650:            dst_contents += str(empty_line)
651:        before, after = elt.maybe_empty_lines(current_line)
652:        for _ in range(before):
653:            dst_contents += str(empty_line)
654:        for line in split_line(current_line, line_length=line_length, py36=py36):
655:            dst_contents += str(line)
656:    return dst_contents
657:
658:
659:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
660:    """Return a tuple of (decoded_contents, encoding, newline).
661:
662:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
663:    universal newlines (i.e. only contains LF).
664:    """
665:    srcbuf = io.BytesIO(src)
666:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
667:    if not lines:
668:        return "", encoding, "\n"
669:
670:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
671:    srcbuf.seek(0)
672:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
673:        return tiow.read(), encoding, newline
674:
675:
676:GRAMMARS = [
677:    pygram.python_grammar_no_print_statement_no_exec_statement,
678:    pygram.python_grammar_no_print_statement,
679:    pygram.python_grammar,
680:]
681:
682:
683:def lib2to3_parse(src_txt: str) -> Node:
684:    """Given a string with source, return the lib2to3 Node."""
685:    if src_txt[-1:] != "\n":
686:        src_txt += "\n"
687:    for grammar in GRAMMARS:
688:        drv = driver.Driver(grammar, pytree.convert)
689:        try:
690:            result = drv.parse_string(src_txt, True)
691:            break
692:
693:        except ParseError as pe:
694:            lineno, column = pe.context[1]
695:            lines = src_txt.splitlines()
696:            try:
697:                faulty_line = lines[lineno - 1]
698:            except IndexError:
699:                faulty_line = "<line number missing in source>"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)

Calling tool: grepTool
\bLeaf\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:34:    Abstract base class for Node and Leaf.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:128:        while not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:331:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:383:        return Leaf(self.type, self.value,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:412:    Convert raw node information to a Node or Leaf instance.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:426:        return Leaf(type, value, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:539:        if not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:45:from blib2to3.pytree import Node, Leaf, type_repr
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:69:LN = Union[Leaf, Node]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:704:    if isinstance(result, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:725:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:769:    def show(cls, code: Union[str, Leaf, Node]) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:898:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:900:    previous: Optional[Leaf] = None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:904:    def mark(self, leaf: Leaf) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:967:    def maybe_increment_for_loop_variable(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:980:    def maybe_decrement_after_for_loop_variable(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:994:    def maybe_increment_lambda_arguments(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1007:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1020:    def get_open_lsqb(self) -> Optional[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1030:    leaves: List[Leaf] = Factory(list)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1033:    comments: Dict[LeafID, List[Leaf]] = Factory(dict)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1038:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1066:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1111:            Leaf(token.DOT, ".") for _ in range(3)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1123:            second_leaf: Optional[Leaf] = self.leaves[1]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1174:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1228:    def append_comment(self, comment: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1253:    def comments_after(self, leaf: Leaf) -> List[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1271:    def is_complex_subscript(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1452:        if isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1565:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1569:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1611:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1841:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1846:            if isinstance(res, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1867:def container_of(leaf: Leaf) -> LN:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1892:def is_split_after_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> int:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1906:def is_split_before_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> int:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1954:            not isinstance(leaf.prev_sibling, Leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2006:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2015:    This is why this function generates simple parentless Leaf objects for
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2026:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2033:    It's not a :class:`blib2to3.pytree.Leaf` so that:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2035:    * it can be cached (`Leaf` objects should not be reused more than once as
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2184:    tail_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2185:    body_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2186:    head_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2224:    tail_leaves: List[Leaf] = []

Calling tool: grepTool
\bSTANDALONE_COMMENT\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:793:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1161:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1231:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1241:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2067:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2735:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2765:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `is_special_comment()` is defined at module scope (black.py:2476) and is only referenced inside `split_line()` (black.py:2121). `split_line()` is only called from within other functions (e.g., `format_str`), not at import time, so the definition order is safe.


Todo item 9 of 10 is correct
description: 'Review that `is_special_comment()` is declared at module scope before any potential use at import time (it is only called within `split_line()` during execution, so definition order is safe).'
Validating todo item 10 of 10
description: 'Inspect `tests` for `test_comments6` to ensure it exercises a multiline function with per-parameter `# type:` comments (and a trailing return type comment) and asserts formatting is not collapsed into a single line containing multiple `# type:` comments, matching the PR intent to preserve multiline in this case.'
Calling tool: grepTool
test_comments6\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py:366:    def test_comments6(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py
340:
341:    @patch("black.dump_to_file", dump_to_stderr)
342:    def test_comments3(self) -> None:
343:        source, expected = read_data("comments3")
344:        actual = fs(source)
345:        self.assertFormatEqual(expected, actual)
346:        black.assert_equivalent(source, actual)
347:        black.assert_stable(source, actual, line_length=ll)
348:
349:    @patch("black.dump_to_file", dump_to_stderr)
350:    def test_comments4(self) -> None:
351:        source, expected = read_data("comments4")
352:        actual = fs(source)
353:        self.assertFormatEqual(expected, actual)
354:        black.assert_equivalent(source, actual)
355:        black.assert_stable(source, actual, line_length=ll)
356:
357:    @patch("black.dump_to_file", dump_to_stderr)
358:    def test_comments5(self) -> None:
359:        source, expected = read_data("comments5")
360:        actual = fs(source)
361:        self.assertFormatEqual(expected, actual)
362:        black.assert_equivalent(source, actual)
363:        black.assert_stable(source, actual, line_length=ll)
364:
365:    @patch("black.dump_to_file", dump_to_stderr)
366:    def test_comments6(self) -> None:
367:        source, expected = read_data("comments6")
368:        actual = fs(source)
369:        self.assertFormatEqual(expected, actual)
370:        black.assert_equivalent(source, actual)
371:        black.assert_stable(source, actual, line_length=ll)
372:
373:    @patch("black.dump_to_file", dump_to_stderr)
374:    def test_cantfit(self) -> None:
375:        source, expected = read_data("cantfit")
376:        actual = fs(source)
377:        self.assertFormatEqual(expected, actual)
378:        black.assert_equivalent(source, actual)
379:        black.assert_stable(source, actual, line_length=ll)
380:
381:    @patch("black.dump_to_file", dump_to_stderr)
382:    def test_import_spacing(self) -> None:
383:        source, expected = read_data("import_spacing")
384:        actual = fs(source)
385:        self.assertFormatEqual(expected, actual)
386:        black.assert_equivalent(source, actual)
387:        black.assert_stable(source, actual, line_length=ll)
388:
389:    @patch("black.dump_to_file", dump_to_stderr)
390:    def test_composition(self) -> None:
391:        source, expected = read_data("composition")
392:        actual = fs(source)
393:        self.assertFormatEqual(expected, actual)
394:        black.assert_equivalent(source, actual)
395:        black.assert_stable(source, actual, line_length=ll)
396:
397:    @patch("black.dump_to_file", dump_to_stderr)
398:    def test_empty_lines(self) -> None:
399:        source, expected = read_data("empty_lines")
400:        actual = fs(source)
401:        self.assertFormatEqual(expected, actual)
402:        black.assert_equivalent(source, actual)
403:        black.assert_stable(source, actual, line_length=ll)
404:
405:    @patch("black.dump_to_file", dump_to_stderr)
406:    def test_string_prefixes(self) -> None:
407:        source, expected = read_data("string_prefixes")
408:        actual = fs(source)
409:        self.assertFormatEqual(expected, actual)
410:        black.assert_equivalent(source, actual)
411:        black.assert_stable(source, actual, line_length=ll)
412:
413:    @patch("black.dump_to_file", dump_to_stderr)
414:    def test_numeric_literals(self) -> None:
415:        source, expected = read_data("numeric_literals")
416:        actual = fs(source, mode=black.FileMode.PYTHON36)
417:        self.assertFormatEqual(expected, actual)
418:        black.assert_equivalent(source, actual)
419:        black.assert_stable(source, actual, line_length=ll)
420:
421:    @patch("black.dump_to_file", dump_to_stderr)
422:    def test_numeric_literals_ignoring_underscores(self) -> None:
423:        source, expected = read_data("numeric_literals_skip_underscores")
424:        mode = (
425:            black.FileMode.PYTHON36 | black.FileMode.NO_NUMERIC_UNDERSCORE_NORMALIZATION
426:        )
427:        actual = fs(source, mode=mode)
428:        self.assertFormatEqual(expected, actual)
429:        black.assert_equivalent(source, actual)
430:        black.assert_stable(source, actual, line_length=ll, mode=mode)
431:
432:    @patch("black.dump_to_file", dump_to_stderr)
433:    def test_numeric_literals_py2(self) -> None:
434:        source, expected = read_data("numeric_literals_py2")
435:        actual = fs(source)
436:        self.assertFormatEqual(expected, actual)
437:        black.assert_stable(source, actual, line_length=ll)
438:
439:    @patch("black.dump_to_file", dump_to_stderr)
440:    def test_python2(self) -> None:
441:        source, expected = read_data("python2")
442:        actual = fs(source)
443:        self.assertFormatEqual(expected, actual)
444:        # black.assert_equivalent(source, actual)
445:        black.assert_stable(source, actual, line_length=ll)
446:
447:    @patch("black.dump_to_file", dump_to_stderr)
448:    def test_python2_unicode_literals(self) -> None:
449:        source, expected = read_data("python2_unicode_literals")
450:        actual = fs(source)
451:        self.assertFormatEqual(expected, actual)
452:        black.assert_stable(source, actual, line_length=ll)
453:
454:    @patch("black.dump_to_file", dump_to_stderr)
455:    def test_stub(self) -> None:
456:        mode = black.FileMode.PYI
457:        source, expected = read_data("stub.pyi")
458:        actual = fs(source, mode=mode)
459:        self.assertFormatEqual(expected, actual)

Calling tool: globTool
**/tests/data/*comments6*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/data/comments6.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/data/comments6.py
1:from typing import Any, Tuple
2:
3:
4:def f(
5:    a,  # type: int
6:):
7:    pass
8:
9:
10:# test type comments
11:def f(a, b, c, d, e, f, g, h, i):
12:    # type: (int, int, int, int, int, int, int, int, int) -> None
13:    pass
14:
15:
16:def f(
17:    a,  # type: int
18:    b,  # type: int
19:    c,  # type: int
20:    d,  # type: int
21:    e,  # type: int
22:    f,  # type: int
23:    g,  # type: int
24:    h,  # type: int
25:    i,  # type: int
26:):
27:    # type: (...) -> None
28:    pass
29:
30:
31:def f(
32:    arg,  # type: int
33:    *args,  # type: *Any
34:    default=False,  # type: bool
35:    **kwargs,  # type: **Any
36:):
37:    # type: (...) -> None
38:    pass
39:
40:
41:def f(
42:    a,  # type: int
43:    b,  # type: int
44:    c,  # type: int
45:    d,  # type: int
46:):
47:    # type: (...) -> None
48:
49:    element = 0  # type: int
50:    another_element = 1  # type: float
51:    another_element_with_long_name = 2  # type: int
52:    another_really_really_long_element_with_a_unnecessarily_long_name_to_describe_what_it_does_enterprise_style = (
53:        3
54:    )  # type: int
55:
56:    tup = (
57:        another_element,  # type: int
58:        another_really_really_long_element_with_a_unnecessarily_long_name_to_describe_what_it_does_enterprise_style,  # type: int
59:    )  # type: Tuple[int, int]
60:
61:    a = (
62:        element
63:        + another_element
64:        + another_element_with_long_name
65:        + element
66:        + another_element
67:        + another_element_with_long_name
68:    )  # type: int

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py:54:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager, redirect_stderr
5:from functools import partial, wraps
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import (
13:    Any,
14:    BinaryIO,
15:    Callable,
16:    Coroutine,
17:    Generator,
18:    List,
19:    Tuple,
20:    Iterator,
21:    TypeVar,
22:)
23:import unittest
24:from unittest.mock import patch, MagicMock
25:
26:from click import unstyle
27:from click.testing import CliRunner
28:
29:import black
30:
31:try:
32:    import blackd
33:    from aiohttp.test_utils import TestClient, TestServer
34:except ImportError:
35:    has_blackd_deps = False
36:else:
37:    has_blackd_deps = True
38:
39:
40:ll = 88
41:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
42:fs = partial(black.format_str, line_length=ll)
43:THIS_FILE = Path(__file__)
44:THIS_DIR = THIS_FILE.parent
45:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
46:T = TypeVar("T")
47:R = TypeVar("R")
48:
49:
50:def dump_to_stderr(*output: str) -> str:
51:    return "\n" + "\n".join(output) + "\n"
52:
53:
54:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
55:    """read_data('test_name') -> 'input', 'output'"""
56:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
57:        name += ".py"
58:    _input: List[str] = []
59:    _output: List[str] = []
60:    base_dir = THIS_DIR / "data" if data else THIS_DIR
61:    with open(base_dir / name, "r", encoding="utf8") as test:
62:        lines = test.readlines()
63:    result = _input
64:    for line in lines:
65:        line = line.replace(EMPTY_LINE, "")
66:        if line.rstrip() == "# output":
67:            result = _output
68:            continue
69:
70:        result.append(line)
71:    if _input and not _output:
72:        # If there's no output marker, treat the entire file as already pre-formatted.
73:        _output = _input[:]
74:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
75:
76:
77:@contextmanager
78:def cache_dir(exists: bool = True) -> Iterator[Path]:
79:    with TemporaryDirectory() as workspace:
80:        cache_dir = Path(workspace)
81:        if not exists:
82:            cache_dir = cache_dir / "new"
83:        with patch("black.CACHE_DIR", cache_dir):
84:            yield cache_dir
85:
86:
87:@contextmanager
88:def event_loop(close: bool) -> Iterator[None]:
89:    policy = asyncio.get_event_loop_policy()
90:    old_loop = policy.get_event_loop()
91:    loop = policy.new_event_loop()
92:    asyncio.set_event_loop(loop)
93:    try:
94:        yield
95:
96:    finally:
97:        policy.set_event_loop(old_loop)
98:        if close:
99:            loop.close()
100:
101:
102:def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:
103:    @event_loop(close=True)
104:    @wraps(f)
105:    def wrapper(*args: Any, **kwargs: Any) -> None:
106:        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))
107:
108:    return wrapper
109:
110:
111:class BlackRunner(CliRunner):
112:    """Modify CliRunner so that stderr is not merged with stdout.
113:
114:    This is a hack that can be removed once we depend on Click 7.x"""
115:
116:    def __init__(self) -> None:
117:        self.stderrbuf = BytesIO()
118:        self.stdoutbuf = BytesIO()
119:        self.stdout_bytes = b""
120:        self.stderr_bytes = b""

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: tests/test_black.py:test_comments6 reads tests/data/comments6.py as both input and expected (no # output marker), so it asserts formatting is unchanged. comments6.py includes a multiline def with per-parameter “# type:” comments and a trailing return type comment (lines 16–28), ensuring Black does not collapse it into a single line with multiple type comments.


Todo item 10 of 10 is correct
description: 'Inspect `tests` for `test_comments6` to ensure it exercises a multiline function with per-parameter `# type:` comments (and a trailing return type comment) and asserts formatting is not collapsed into a single line containing multiple `# type:` comments, matching the PR intent to preserve multiline in this case.'
Validating todo item 1 of 10
description: 'In `split_line()`, verify the new early-return condition includes `not has_special_comment` along with `not line.should_explode` and `is_line_short_enough(...)`, ensuring lines with special comments are not returned unmodified.'

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)
2208:    for result in (head, body, tail):
2209:        if result:
2210:            yield result
2211:
2212:
2213:def right_hand_split(
2214:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2215:) -> Iterator[Line]:
2216:    """Split line into many lines, starting with the last matching bracket pair.

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s split_line(), lines 2124–2129 show the early-return condition now includes `not has_special_comment` alongside `not line.should_explode` and `is_line_short_enough(...)`. The detection of special comments is implemented above, ensuring such lines aren’t returned unmodified.

Todo item 1 of 10 is correct
description: 'In `split_line()`, verify the new early-return condition includes `not has_special_comment` along with `not line.should_explode` and `is_line_short_enough(...)`, ensuring lines with special comments are not returned unmodified.'

Validating todo item 2 of 10
description: 'Confirm the scanning logic for `has_special_comment` iterates all `line.leaves` and, for each, all `line.comments_after(leaf)`, and sets `has_special_comment = True` only when `leaf.type == token.COMMA` and `is_special_comment(comment)` is True.'

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py

Calling tool: grepTool
def split_line\(
Matched content:
2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)
2208:    for result in (head, body, tail):
2209:        if result:
2210:            yield result
2211:
2212:
2213:def right_hand_split(
2214:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2215:) -> Iterator[Line]:
2216:    """Split line into many lines, starting with the last matching bracket pair.

Calling tool: grepTool
def is_special_comment\(
Matched content:
2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: grepTool
has_special_comment
Matched content:
2118:    has_special_comment = False
2122:                has_special_comment = True
2125:        not has_special_comment

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2118-2126, the code iterates over all line.leaves and for each leaf over line.comments_after(leaf), setting has_special_comment = True only when leaf.type == token.COMMA and is_special_comment(comment) returns True.

Todo item 2 of 10 is correct
description: 'Confirm the scanning logic for `has_special_comment` iterates all `line.leaves` and, for each, all `line.comments_after(leaf)`, and sets `has_special_comment = True` only when `leaf.type == token.COMMA` and `is_special_comment(comment)` is True.'

Validating todo item 3 of 10
description: 'Check that `is_special_comment()` is defined and returns True only for leaves where `(leaf.type == token.COMMENT or leaf.type == STANDALONE_COMMENT)` and `leaf.value.startswith('# type:')`.'

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.
2510:    """
2511:    match = re.match(r"^([furbFURB]*)(.*)$", leaf.value, re.DOTALL)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Found is_special_comment in black.py at lines 2476-2483. It returns bool((t == token.COMMENT or t == STANDALONE_COMMENT) and v.startswith("# type:")), matching the requirement exactly.

Todo item 3 of 10 is correct
description: 'Check that `is_special_comment()` is defined and returns True only for leaves where `(leaf.type == token.COMMENT or leaf.type == STANDALONE_COMMENT)` and `leaf.value.startswith('# type:')`.'

Validating todo item 4 of 10
description: 'Verify that `STANDALONE_COMMENT` is defined in the module and corresponds to the token type used elsewhere for standalone comments to avoid a NameError at runtime.'

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:793:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1161:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1231:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1241:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2067:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2735:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2765:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
780:KEYWORDS = set(keyword.kwlist)
781:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
782:FLOW_CONTROL = {"return", "raise", "break", "continue"}
783:STATEMENT = {
784:    syms.if_stmt,
785:    syms.while_stmt,
786:    syms.for_stmt,
787:    syms.try_stmt,
788:    syms.except_clause,
789:    syms.with_stmt,
790:    syms.funcdef,
791:    syms.classdef,
792:}
793:STANDALONE_COMMENT = 153
794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
795:LOGIC_OPERATORS = {"and", "or"}
796:COMPARATORS = {
797:    token.LESS,
798:    token.GREATER,
799:    token.EQEQUAL,
800:    token.NOTEQUAL,
801:    token.LESSEQUAL,
802:    token.GREATEREQUAL,
803:}
804:MATH_OPERATORS = {
805:    token.VBAR,
806:    token.CIRCUMFLEX,
807:    token.AMPER,
808:    token.LEFTSHIFT,
809:    token.RIGHTSHIFT,
810:    token.PLUS,
811:    token.MINUS,
812:    token.STAR,
813:    token.SLASH,
814:    token.DOUBLESLASH,
815:    token.PERCENT,
816:    token.AT,
817:    token.TILDE,
818:    token.DOUBLESTAR,
819:}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2000:
2001:
2002:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
2003:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
2004:
2005:
2006:def generate_comments(leaf: LN) -> Iterator[Leaf]:
2007:    """Clean the prefix of the `leaf` and generate comments from it, if any.
2008:
2009:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
2010:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
2011:    move because it does away with modifying the grammar to include all the
2012:    possible places in which comments can be placed.
2013:
2014:    The sad consequence for us though is that comments don't "belong" anywhere.
2015:    This is why this function generates simple parentless Leaf objects for
2016:    comments.  We simply don't know what the correct parent should be.
2017:
2018:    No matter though, we can live without this.  We really only need to
2019:    differentiate between inline and standalone comments.  The latter don't
2020:    share the line with any code.
2021:
2022:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
2024:    """
2025:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
2026:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
2027:
2028:
2029:@dataclass
2030:class ProtoComment:
2031:    """Describes a piece of syntax that is a comment.
2032:
2033:    It's not a :class:`blib2to3.pytree.Leaf` so that:
2034:
2035:    * it can be cached (`Leaf` objects should not be reused more than once as
2036:      they store their lineno, column, prefix, and parent information);
2037:    * `newlines` and `consumed` fields are kept separate from the `value`. This
2038:      simplifies handling of special marker comments like ``# fmt: off/on``.
2039:    """
2040:
2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
2042:    value: str  # content of the comment
2043:    newlines: int  # how many newlines before the comment
2044:    consumed: int  # how many characters of the original leaf's prefix did we consume
2045:
2046:
2047:@lru_cache(maxsize=4096)
2048:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2049:    """Return a list of :class:`ProtoComment` objects parsed from the given `prefix`."""
2050:    result: List[ProtoComment] = []
2051:    if not prefix or "#" not in prefix:
2052:        return result
2053:
2054:    consumed = 0
2055:    nlines = 0
2056:    for index, line in enumerate(prefix.split("\n")):
2057:        consumed += len(line) + 1  # adding the length of the split '\n'
2058:        line = line.lstrip()
2059:        if not line:
2060:            nlines += 1
2061:        if not line.startswith("#"):
2062:            continue
2063:
2064:        if index == 0 and not is_endmarker:
2065:            comment_type = token.COMMENT  # simple trailing comment
2066:        else:
2067:            comment_type = STANDALONE_COMMENT
2068:        comment = make_comment(line)
2069:        result.append(
2070:            ProtoComment(
2071:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2072:            )
2073:        )
2074:        nlines = 0
2075:    return result
2076:
2077:
2078:def make_comment(content: str) -> str:
2079:    """Return a consistently formatted comment from the given `content` string.
2080:
2081:    All comments (except for "##", "#!", "#:", '#'", "#%%") should have a single
2082:    space between the hash sign and the content.
2083:
2084:    If `content` didn't start with a hash sign, one is provided.
2085:    """
2086:    content = content.rstrip()
2087:    if not content:
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2450:            current_line.append(leaf)
2451:
2452:    for leaf in line.leaves:
2453:        yield from append_to_line(leaf)
2454:
2455:        for comment_after in line.comments_after(leaf):
2456:            yield from append_to_line(comment_after)
2457:
2458:    if current_line:
2459:        yield current_line
2460:
2461:
2462:def is_import(leaf: Leaf) -> bool:
2463:    """Return True if the given leaf starts an import statement."""
2464:    p = leaf.parent
2465:    t = leaf.type
2466:    v = leaf.value
2467:    return bool(
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1558:
1559:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1560:        """Visit decorators."""
1561:        for child in node.children:
1562:            yield from self.line()
1563:            yield from self.visit(child)
1564:
1565:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1566:        """Remove a semicolon and put the other statement on a separate line."""
1567:        yield from self.line()
1568:
1569:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1570:        """End of file. Process outstanding comments and end with a newline."""
1571:        yield from self.visit_default(leaf)
1572:        yield from self.line()
1573:
1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1575:        if not self.current_line.bracket_tracker.any_open_brackets():
1576:            yield from self.line()
1577:        yield from self.visit_default(leaf)
1578:
1579:    def __attrs_post_init__(self) -> None:
1580:        """You are in a twisty little maze of passages."""
1581:        v = self.visit_stmt
1582:        Ø: Set[str] = set()
1583:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1584:        self.visit_if_stmt = partial(
1585:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1586:        )
1587:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1588:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1589:        self.visit_try_stmt = partial(
1590:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1591:        )
1592:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1593:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1594:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1595:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1596:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1597:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: STANDALONE_COMMENT is defined at module level (black.py:793) and registered in token.tok_name. It is used elsewhere as the token type for standalone comments (e.g., in list_comments setting comment_type=STANDALONE_COMMENT and visit_STANDALONE_COMMENT). The new is_special_comment correctly references it, so no NameError will occur.

Todo item 4 of 10 is correct
description: 'Verify that `STANDALONE_COMMENT` is defined in the module and corresponds to the token type used elsewhere for standalone comments to avoid a NameError at runtime.'

Validating todo item 5 of 10
description: 'Verify `token` is imported in the module and that `token.COMMENT` is a valid token type used elsewhere in the file (consistency check).'

Calling tool: grepTool
(?i)^import token|from .* import token|pgen2\.token|blib2to3.*token
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:18:import tokenize
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:47:from blib2to3.pgen2 import driver, token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:26:        # from .pgen2 import token // token.__dict__.items():
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:361:        from .pgen2.token import tok_name
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.py:34:from blib2to3.pgen2.token import *
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.py:36:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/pgen.pyi:7:from blib2to3.pgen2.tokenize import _TokenInfo
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/grammar.py:19:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/parse.py:14:from . import token
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.py:4:#   originally monkeypatched in by pgen2.tokenize
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.pyi:1:# Stubs for lib2to3.pgen2.tokenize (Python 3.6)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/tokenize.pyi:5:from blib2to3.pgen2.token import *  # noqa
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.pyi:1:# Stubs for lib2to3.pgen2.token (Python 3.6)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pygram.py:10:from .pgen2 import token

Calling tool: grepTool
token\.COMMENT|token\.COMMA|STANDALONE_COMMENT
Matched content:
793:STANDALONE_COMMENT = 153
794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
919:        if leaf.type == token.COMMENT:
1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1161:            if leaf.type == STANDALONE_COMMENT:
1178:            and self.leaves[-1].type == token.COMMA
1216:            if bracket_depth == depth and leaf.type == token.COMMA:
1231:            comment.type == STANDALONE_COMMENT
1237:        if comment.type != token.COMMENT:
1241:            comment.type = STANDALONE_COMMENT
1458:                elif comment.type == token.COMMENT:
1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1626:    if t == token.COMMENT:
1647:            elif prevp.type != token.COMMA and not complex_subscript:
1699:        if not prev or prev.type != token.COMMA:
1704:        if prev and prev.type != token.COMMA:
1721:        elif prev.type != token.COMMA:
1728:            if not prevp or prevp.type != token.COMMA:
1745:        elif prev.type != token.COMMA:
1900:    if leaf.type == token.COMMA:
2022:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
2065:            comment_type = token.COMMENT  # simple trailing comment
2067:            comment_type = STANDALONE_COMMENT
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2342:                if leaves[-1].type != token.COMMA:
2343:                    leaves.append(Leaf(token.COMMA, ","))
2426:            and current_line.leaves[-1].type != token.COMMA
2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2429:            current_line.append(Leaf(token.COMMA, ","))
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2735:                if comment.type != STANDALONE_COMMENT:
2765:                        STANDALONE_COMMENT,
2845:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2850:        and node.children[1].type == token.COMMA
2985:        exclude = {id(last_leaf)} if last_leaf.type == token.COMMA else set()
3014:            and n.children[-1].type == token.COMMA
3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1:import asyncio
2:from asyncio.base_events import BaseEventLoop
3:from concurrent.futures import Executor, ProcessPoolExecutor
4:from datetime import datetime
5:from enum import Enum, Flag
6:from functools import lru_cache, partial, wraps
7:import io
8:import itertools
9:import keyword
10:import logging
11:from multiprocessing import Manager, freeze_support
12:import os
13:from pathlib import Path
14:import pickle
15:import re
16:import signal
17:import sys
18:import tokenize
19:from typing import (
20:    Any,
21:    Callable,
22:    Collection,
23:    Dict,
24:    Generator,
25:    Generic,
26:    Iterable,
27:    Iterator,
28:    List,
29:    Optional,
30:    Pattern,
31:    Sequence,
32:    Set,
33:    Tuple,
34:    TypeVar,
35:    Union,
36:    cast,
37:)
38:
39:from appdirs import user_cache_dir
40:from attr import dataclass, Factory
41:import click
42:import toml
43:
44:# lib2to3 fork
45:from blib2to3.pytree import Node, Leaf, type_repr
46:from blib2to3 import pygram, pytree
47:from blib2to3.pgen2 import driver, token
48:from blib2to3.pgen2.parse import ParseError
49:
50:
51:__version__ = "18.9b0"
52:DEFAULT_LINE_LENGTH = 88
53:DEFAULT_EXCLUDES = (
54:    r"/(\.eggs|\.git|\.hg|\.mypy_cache|\.nox|\.tox|\.venv|_build|buck-out|build|dist)/"
55:)
56:DEFAULT_INCLUDES = r"\.pyi?$"
57:CACHE_DIR = Path(user_cache_dir("black", version=__version__))
58:
59:
60:# types
61:FileContent = str
62:Encoding = str
63:NewLine = str
64:Depth = int
65:NodeType = int
66:LeafID = int
67:Priority = int
68:Index = int
69:LN = Union[Leaf, Node]
70:SplitFunc = Callable[["Line", bool], Iterator["Line"]]

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pgen2/token.py
1:"""Token constants (from "token.h")."""
2:
3:#  Taken from Python (r53757) and modified to include some tokens
4:#   originally monkeypatched in by pgen2.tokenize
5:
6:#--start constants--
7:ENDMARKER = 0
8:NAME = 1
9:NUMBER = 2
10:STRING = 3
11:NEWLINE = 4
12:INDENT = 5
13:DEDENT = 6
14:LPAR = 7
15:RPAR = 8
16:LSQB = 9
17:RSQB = 10
18:COLON = 11
19:COMMA = 12
20:SEMI = 13
21:PLUS = 14
22:MINUS = 15
23:STAR = 16
24:SLASH = 17
25:VBAR = 18
26:AMPER = 19
27:LESS = 20
28:GREATER = 21
29:EQUAL = 22
30:DOT = 23
31:PERCENT = 24
32:BACKQUOTE = 25
33:LBRACE = 26
34:RBRACE = 27
35:EQEQUAL = 28
36:NOTEQUAL = 29
37:LESSEQUAL = 30
38:GREATEREQUAL = 31
39:TILDE = 32
40:CIRCUMFLEX = 33
41:LEFTSHIFT = 34
42:RIGHTSHIFT = 35
43:DOUBLESTAR = 36
44:PLUSEQUAL = 37
45:MINEQUAL = 38
46:STAREQUAL = 39
47:SLASHEQUAL = 40
48:PERCENTEQUAL = 41
49:AMPEREQUAL = 42
50:VBAREQUAL = 43
51:CIRCUMFLEXEQUAL = 44
52:LEFTSHIFTEQUAL = 45
53:RIGHTSHIFTEQUAL = 46
54:DOUBLESTAREQUAL = 47
55:DOUBLESLASH = 48
56:DOUBLESLASHEQUAL = 49
57:AT = 50
58:ATEQUAL = 51
59:OP = 52
60:COMMENT = 53
61:NL = 54
62:RARROW = 55
63:AWAIT = 56
64:ASYNC = 57
65:ERRORTOKEN = 58
66:N_TOKENS = 59
67:NT_OFFSET = 256
68:#--end constants--
69:
70:tok_name = {}
71:for _name, _value in list(globals().items()):
72:    if type(_value) is type(0):
73:        tok_name[_value] = _name
74:
75:
76:def ISTERMINAL(x):
77:    return x < NT_OFFSET
78:
79:def ISNONTERMINAL(x):
80:    return x >= NT_OFFSET
81:
82:def ISEOF(x):
83:    return x == ENDMARKER

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `black.py` imports `token` from blib2to3.pgen2 (line 47) and `token.COMMENT` is a defined token (blib2to3/pgen2/token.py line 60) and already used multiple times within `black.py` (e.g., lines 919, 1237, 1458, 1626), confirming consistency.

Todo item 5 of 10 is correct
description: 'Verify `token` is imported in the module and that `token.COMMENT` is a valid token type used elsewhere in the file (consistency check).'

Validating todo item 6 of 10
description: 'Ensure that objects yielded by `line.comments_after(leaf)` are `Leaf` instances (or have `.type` and `.value` attributes), so they are compatible with `is_special_comment()` usage.'

Calling tool: grepTool
class Line\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1026:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1000:        if leaf.type == token.NAME and leaf.value == "lambda":
1001:            self.depth += 1
1002:            self._lambda_argument_depths.append(self.depth)
1003:            return True
1004:
1005:        return False
1006:
1007:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
1008:        """See `maybe_increment_lambda_arguments` above for explanation."""
1009:        if (
1010:            self._lambda_argument_depths
1011:            and self._lambda_argument_depths[-1] == self.depth
1012:            and leaf.type == token.COLON
1013:        ):
1014:            self.depth -= 1
1015:            self._lambda_argument_depths.pop()
1016:            return True
1017:
1018:        return False
1019:
1020:    def get_open_lsqb(self) -> Optional[Leaf]:
1021:        """Return the most recent opening square bracket (if any)."""
1022:        return self.bracket_match.get((self.depth - 1, token.RSQB))
1023:
1024:
1025:@dataclass
1026:class Line:
1027:    """Holds leaves and comments. Can be printed with `str(line)`."""
1028:
1029:    depth: int = 0
1030:    leaves: List[Leaf] = Factory(list)
1031:    # The LeafID keys of comments must remain ordered by the corresponding leaf's index
1032:    # in leaves
1033:    comments: Dict[LeafID, List[Leaf]] = Factory(dict)
1034:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1035:    inside_brackets: bool = False
1036:    should_explode: bool = False
1037:
1038:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1039:        """Add a new `leaf` to the end of the line.
1040:
1041:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1042:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1043:        Trailing commas are maybe removed, unpacked for loop variables are
1044:        demoted from being delimiters.
1045:
1046:        Inline comments are put aside.
1047:        """
1048:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1049:        if not has_value:
1050:            return
1051:
1052:        if token.COLON == leaf.type and self.is_class_paren_empty:
1053:            del self.leaves[-2:]
1054:        if self.leaves and not preformatted:
1055:            # Note: at this point leaf.prefix should be empty except for
1056:            # imports, for which we only preserve newlines.
1057:            leaf.prefix += whitespace(
1058:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1059:            )
1060:        if self.inside_brackets or not preformatted:
1061:            self.bracket_tracker.mark(leaf)
1062:            self.maybe_remove_trailing_comma(leaf)
1063:        if not self.append_comment(leaf):
1064:            self.leaves.append(leaf)
1065:
1066:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1067:        """Like :func:`append()` but disallow invalid standalone comment structure.
1068:
1069:        Raises ValueError when any `leaf` is appended after a standalone comment
1070:        or when a standalone comment is not the first leaf on the line.
1071:        """
1072:        if self.bracket_tracker.depth == 0:
1073:            if self.is_comment:
1074:                raise ValueError("cannot append to standalone comments")
1075:
1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1077:                raise ValueError(
1078:                    "cannot append standalone comments to a populated line"
1079:                )
1080:
1081:        self.append(leaf, preformatted=preformatted)
1082:
1083:    @property
1084:    def is_comment(self) -> bool:
1085:        """Is this line a standalone comment?"""
1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1087:
1088:    @property
1089:    def is_decorator(self) -> bool:
1090:        """Is this line a decorator?"""
1091:        return bool(self) and self.leaves[0].type == token.AT
1092:
1093:    @property
1094:    def is_import(self) -> bool:
1095:        """Is this an import line?"""
1096:        return bool(self) and is_import(self.leaves[0])
1097:
1098:    @property
1099:    def is_class(self) -> bool:
1100:        """Is this line a class definition?"""
1101:        return (
1102:            bool(self)
1103:            and self.leaves[0].type == token.NAME
1104:            and self.leaves[0].value == "class"
1105:        )
1106:
1107:    @property
1108:    def is_stub_class(self) -> bool:
1109:        """Is this line a class definition with a body consisting only of "..."?"""
1110:        return self.is_class and self.leaves[-3:] == [
1111:            Leaf(token.DOT, ".") for _ in range(3)
1112:        ]
1113:
1114:    @property
1115:    def is_def(self) -> bool:
1116:        """Is this a function definition? (Also returns True for async defs.)"""
1117:        try:
1118:            first_leaf = self.leaves[0]
1119:        except IndexError:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1120:            return False
1121:
1122:        try:
1123:            second_leaf: Optional[Leaf] = self.leaves[1]
1124:        except IndexError:
1125:            second_leaf = None
1126:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1127:            first_leaf.type == token.ASYNC
1128:            and second_leaf is not None
1129:            and second_leaf.type == token.NAME
1130:            and second_leaf.value == "def"
1131:        )
1132:
1133:    @property
1134:    def is_class_paren_empty(self) -> bool:
1135:        """Is this a class with no base classes but using parentheses?
1136:
1137:        Those are unnecessary and should be removed.
1138:        """
1139:        return (
1140:            bool(self)
1141:            and len(self.leaves) == 4
1142:            and self.is_class
1143:            and self.leaves[2].type == token.LPAR
1144:            and self.leaves[2].value == "("
1145:            and self.leaves[3].type == token.RPAR
1146:            and self.leaves[3].value == ")"
1147:        )
1148:
1149:    @property
1150:    def is_triple_quoted_string(self) -> bool:
1151:        """Is the line a triple quoted string?"""
1152:        return (
1153:            bool(self)
1154:            and self.leaves[0].type == token.STRING
1155:            and self.leaves[0].value.startswith(('"""', "'''"))
1156:        )
1157:
1158:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1159:        """If so, needs to be split before emitting."""
1160:        for leaf in self.leaves:
1161:            if leaf.type == STANDALONE_COMMENT:
1162:                if leaf.bracket_depth <= depth_limit:
1163:                    return True
1164:
1165:        return False
1166:
1167:    def contains_multiline_strings(self) -> bool:
1168:        for leaf in self.leaves:
1169:            if is_multiline_string(leaf):
1170:                return True
1171:
1172:        return False
1173:
1174:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1175:        """Remove trailing comma if there is one and it's safe."""
1176:        if not (
1177:            self.leaves
1178:            and self.leaves[-1].type == token.COMMA
1179:            and closing.type in CLOSING_BRACKETS
1180:        ):
1181:            return False
1182:
1183:        if closing.type == token.RBRACE:
1184:            self.remove_trailing_comma()
1185:            return True
1186:
1187:        if closing.type == token.RSQB:
1188:            comma = self.leaves[-1]
1189:            if comma.parent and comma.parent.type == syms.listmaker:
1190:                self.remove_trailing_comma()
1191:                return True
1192:
1193:        # For parens let's check if it's safe to remove the comma.
1194:        # Imports are always safe.
1195:        if self.is_import:
1196:            self.remove_trailing_comma()
1197:            return True
1198:
1199:        # Otherwise, if the trailing one is the only one, we might mistakenly
1200:        # change a tuple into a different type by removing the comma.
1201:        depth = closing.bracket_depth + 1
1202:        commas = 0
1203:        opening = closing.opening_bracket
1204:        for _opening_index, leaf in enumerate(self.leaves):
1205:            if leaf is opening:
1206:                break
1207:
1208:        else:
1209:            return False
1210:
1211:        for leaf in self.leaves[_opening_index + 1 :]:
1212:            if leaf is closing:
1213:                break
1214:
1215:            bracket_depth = leaf.bracket_depth
1216:            if bracket_depth == depth and leaf.type == token.COMMA:
1217:                commas += 1
1218:                if leaf.parent and leaf.parent.type == syms.arglist:
1219:                    commas += 1
1220:                    break
1221:
1222:        if commas > 1:
1223:            self.remove_trailing_comma()
1224:            return True
1225:
1226:        return False
1227:
1228:    def append_comment(self, comment: Leaf) -> bool:
1229:        """Add an inline or standalone comment to the line."""
1230:        if (
1231:            comment.type == STANDALONE_COMMENT
1232:            and self.bracket_tracker.any_open_brackets()
1233:        ):
1234:            comment.prefix = ""
1235:            return False
1236:
1237:        if comment.type != token.COMMENT:
1238:            return False
1239:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
1240:        if not self.leaves:
1241:            comment.type = STANDALONE_COMMENT
1242:            comment.prefix = ""
1243:            return False
1244:
1245:        else:
1246:            leaf_id = id(self.leaves[-1])
1247:            if leaf_id not in self.comments:
1248:                self.comments[leaf_id] = [comment]
1249:            else:
1250:                self.comments[leaf_id].append(comment)
1251:            return True
1252:
1253:    def comments_after(self, leaf: Leaf) -> List[Leaf]:
1254:        """Generate comments that should appear directly after `leaf`."""
1255:        return self.comments.get(id(leaf), [])
1256:
1257:    def remove_trailing_comma(self) -> None:
1258:        """Remove the trailing comma and moves the comments attached to it."""
1259:        # Remember, the LeafID keys of self.comments are ordered by the
1260:        # corresponding leaf's index in self.leaves
1261:        # If id(self.leaves[-2]) is in self.comments, the order doesn't change.
1262:        # Otherwise, we insert it into self.comments, and it becomes the last entry.
1263:        # However, since we delete id(self.leaves[-1]) from self.comments, the invariant
1264:        # is maintained
1265:        self.comments.setdefault(id(self.leaves[-2]), []).extend(
1266:            self.comments.get(id(self.leaves[-1]), [])
1267:        )
1268:        self.comments.pop(id(self.leaves[-1]), None)
1269:        self.leaves.pop()
1270:
1271:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1272:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1273:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1274:        if open_lsqb is None:
1275:            return False
1276:
1277:        subscript_start = open_lsqb.next_sibling
1278:
1279:        if isinstance(subscript_start, Node):
1280:            if subscript_start.type == syms.listmaker:
1281:                return False
1282:
1283:            if subscript_start.type == syms.subscriptlist:
1284:                subscript_start = child_towards(subscript_start, leaf)
1285:        return subscript_start is not None and any(
1286:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1287:        )
1288:
1289:    def __str__(self) -> str:
1290:        """Render the line."""
1291:        if not self:
1292:            return "\n"
1293:
1294:        indent = "    " * self.depth
1295:        leaves = iter(self.leaves)
1296:        first = next(leaves)
1297:        res = f"{first.prefix}{indent}{first.value}"
1298:        for leaf in leaves:
1299:            res += str(leaf)
1300:        for comment in itertools.chain.from_iterable(self.comments.values()):
1301:            res += str(comment)
1302:        return res + "\n"
1303:
1304:    def __bool__(self) -> bool:
1305:        """Return True if the line has leaves or comments."""
1306:        return bool(self.leaves or self.comments)
1307:
1308:
1309:@dataclass
1310:class EmptyLineTracker:
1311:    """Provides a stateful method that returns the number of potential extra
1312:    empty lines needed before and after the currently processed line.
1313:
1314:    Note: this tracker works on lines that haven't been split yet.  It assumes
1315:    the prefix of the first leaf consists of optional newlines.  Those newlines
1316:    are consumed by `maybe_empty_lines()` and included in the computation.
1317:    """
1318:
1319:    is_pyi: bool = False
1320:    previous_line: Optional[Line] = None
1321:    previous_after: int = 0
1322:    previous_defs: List[int] = Factory(list)
1323:
1324:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1325:        """Return the number of extra empty lines before and after the `current_line`.
1326:
1327:        This is for separating `def`, `async def` and `class` with extra empty
1328:        lines (two on module-level).
1329:        """
1330:        before, after = self._maybe_empty_lines(current_line)
1331:        before -= self.previous_after
1332:        self.previous_after = after
1333:        self.previous_line = current_line
1334:        return before, after
1335:
1336:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1337:        max_allowed = 1
1338:        if current_line.depth == 0:
1339:            max_allowed = 1 if self.is_pyi else 2
1340:        if current_line.leaves:
1341:            # Consume the first leaf's extra newlines.
1342:            first_leaf = current_line.leaves[0]
1343:            before = first_leaf.prefix.count("\n")
1344:            before = min(before, max_allowed)
1345:            first_leaf.prefix = ""
1346:        else:
1347:            before = 0
1348:        depth = current_line.depth
1349:        while self.previous_defs and self.previous_defs[-1] >= depth:
1350:            self.previous_defs.pop()
1351:            if self.is_pyi:
1352:                before = 0 if depth else 1
1353:            else:
1354:                before = 1 if depth else 2
1355:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1356:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1357:
1358:        if (
1359:            self.previous_line

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2450:            current_line.append(leaf)
2451:
2452:    for leaf in line.leaves:
2453:        yield from append_to_line(leaf)
2454:
2455:        for comment_after in line.comments_after(leaf):
2456:            yield from append_to_line(comment_after)
2457:
2458:    if current_line:
2459:        yield current_line
2460:
2461:
2462:def is_import(leaf: Leaf) -> bool:
2463:    """Return True if the given leaf starts an import statement."""
2464:    p = leaf.parent
2465:    t = leaf.type
2466:    v = leaf.value
2467:    return bool(
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.
2508:
2509:    Note: Mutates its argument.

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2085:    """
2086:    content = content.rstrip()
2087:    if not content:
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `Line.comments_after()` returns values from `self.comments`, which is a Dict[LeafID, List[Leaf>] populated by `append_comment()` with `Leaf` instances. Thus, items yielded are `Leaf`s with `.type` and `.value`, compatible with `is_special_comment()`.

Todo item 6 of 10 is correct
description: 'Ensure that objects yielded by `line.comments_after(leaf)` are `Leaf` instances (or have `.type` and `.value` attributes), so they are compatible with `is_special_comment()` usage.'

Validating todo item 7 of 10
description: 'Confirm that the new logic only treats comments beginning exactly with `'# type:'` as special; comments with other prefixes (e.g., `# foo`) do not set `has_special_comment` to True.'

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:

Calling tool: grepTool
is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2121:            if leaf.type == token.COMMA and is_special_comment(comment):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: The implementation uses is_special_comment() which returns True only if the comment leaf’s value starts with the exact prefix "# type:". In split_line(), has_special_comment is set only when such a comment appears after a comma. Comments like "# foo" don’t match startswith("# type:") and therefore won’t set has_special_comment to True.

Todo item 7 of 10 is correct
description: 'Confirm that the new logic only treats comments beginning exactly with `'# type:'` as special; comments with other prefixes (e.g., `# foo`) do not set `has_special_comment` to True.'

Validating todo item 8 of 10
description: 'Validate that the added logic does not change behavior for lines without special comments: when `has_special_comment` remains False, the original short-line early return still triggers unchanged.'

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """
2492:    if not inside_brackets:
2493:        spl = leaf.prefix.split("#")
2494:        if "\\" not in spl[0]:
2495:            nl_count = spl[-1].count("\n")
2496:            if len(spl) > 1:
2497:                nl_count -= 1
2498:            leaf.prefix = "\n" * nl_count
2499:            return
2500:
2501:    leaf.prefix = ""
2502:
2503:
2504:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2505:    """Make all string prefixes lowercase.
2506:
2507:    If remove_u_prefix is given, also removes any u prefix from the string.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In split_line(), the early return condition was extended to include “not has_special_comment”. For lines without special comments, has_special_comment remains False, so the condition reduces to the original (not line.should_explode and is_line_short_enough(...)). The added scanning loop is read-only and doesn’t alter line state, preserving behavior.

Todo item 8 of 10 is correct
description: 'Validate that the added logic does not change behavior for lines without special comments: when `has_special_comment` remains False, the original short-line early return still triggers unchanged.'

Validating todo item 9 of 10
description: 'Review that `is_special_comment()` is declared at module scope before any potential use at import time (it is only called within `split_line()` during execution, so definition order is safe).'

Calling tool: grepTool
def is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: grepTool
is_special_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2121:            if leaf.type == token.COMMA and is_special_comment(comment):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2476:def is_special_comment(leaf: Leaf) -> bool:

Calling tool: grepTool
def split_line\(|split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:654:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2097:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
620:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
621:    return dst_contents
622:
623:
624:def format_str(
625:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
626:) -> FileContent:
627:    """Reformat a string and return new contents.
628:
629:    `line_length` determines how many characters per line are allowed.
630:    """
631:    src_node = lib2to3_parse(src_contents.lstrip())
632:    dst_contents = ""
633:    future_imports = get_future_imports(src_node)
634:    is_pyi = bool(mode & FileMode.PYI)
635:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
636:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
637:    normalize_fmt_off(src_node)
638:    lines = LineGenerator(
639:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
640:        is_pyi=is_pyi,
641:        normalize_strings=normalize_strings,
642:        allow_underscores=py36
643:        and not bool(mode & FileMode.NO_NUMERIC_UNDERSCORE_NORMALIZATION),
644:    )
645:    elt = EmptyLineTracker(is_pyi=is_pyi)
646:    empty_line = Line()
647:    after = 0
648:    for current_line in lines.visit(src_node):
649:        for _ in range(after):
650:            dst_contents += str(empty_line)
651:        before, after = elt.maybe_empty_lines(current_line)
652:        for _ in range(before):
653:            dst_contents += str(empty_line)
654:        for line in split_line(current_line, line_length=line_length, py36=py36):
655:            dst_contents += str(line)
656:    return dst_contents
657:
658:
659:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
660:    """Return a tuple of (decoded_contents, encoding, newline).
661:
662:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
663:    universal newlines (i.e. only contains LF).
664:    """
665:    srcbuf = io.BytesIO(src)
666:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
667:    if not lines:
668:        return "", encoding, "\n"
669:
670:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
671:    srcbuf.seek(0)
672:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
673:        return tiow.read(), encoding, newline
674:
675:
676:GRAMMARS = [
677:    pygram.python_grammar_no_print_statement_no_exec_statement,
678:    pygram.python_grammar_no_print_statement,
679:    pygram.python_grammar,
680:]
681:
682:
683:def lib2to3_parse(src_txt: str) -> Node:
684:    """Given a string with source, return the lib2to3 Node."""
685:    if src_txt[-1:] != "\n":
686:        src_txt += "\n"
687:    for grammar in GRAMMARS:
688:        drv = driver.Driver(grammar, pytree.convert)
689:        try:
690:            result = drv.parse_string(src_txt, True)
691:            break
692:
693:        except ParseError as pe:
694:            lineno, column = pe.context[1]
695:            lines = src_txt.splitlines()
696:            try:
697:                faulty_line = lines[lineno - 1]
698:            except IndexError:
699:                faulty_line = "<line number missing in source>"

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2088:        return "#"
2089:
2090:    if content[0] == "#":
2091:        content = content[1:]
2092:    if content and content[0] not in " !:#'%":
2093:        content = " " + content
2094:    return "#" + content
2095:
2096:
2097:def split_line(
2098:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2099:) -> Iterator[Line]:
2100:    """Split a `line` into potentially many lines.
2101:
2102:    They should fit in the allotted `line_length` but might not be able to.
2103:    `inner` signifies that there were a pair of brackets somewhere around the
2104:    current `line`, possibly transitively. This means we can fallback to splitting
2105:    by delimiters if the LHS/RHS don't yield any results.
2106:
2107:    If `py36` is True, splitting may generate syntax that is only compatible
2108:    with Python 3.6 and later.
2109:    """
2110:    if line.is_comment:
2111:        yield line
2112:        return
2113:
2114:    line_str = str(line).strip("\n")
2115:
2116:    # we don't want to split special comments like type annotations
2117:    # https://github.com/python/typing/issues/186
2118:    has_special_comment = False
2119:    for leaf in line.leaves:
2120:        for comment in line.comments_after(leaf):
2121:            if leaf.type == token.COMMA and is_special_comment(comment):
2122:                has_special_comment = True
2123:
2124:    if (
2125:        not has_special_comment
2126:        and not line.should_explode
2127:        and is_line_short_enough(line, line_length=line_length, line_str=line_str)
2128:    ):
2129:        yield line
2130:        return
2131:
2132:    split_funcs: List[SplitFunc]
2133:    if line.is_def:
2134:        split_funcs = [left_hand_split]
2135:    else:
2136:
2137:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2138:            for omit in generate_trailers_to_omit(line, line_length):
2139:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2140:                if is_line_short_enough(lines[0], line_length=line_length):
2141:                    yield from lines
2142:                    return
2143:
2144:            # All splits failed, best effort split with no omits.
2145:            # This mostly happens to multiline strings that are by definition
2146:            # reported as not fitting a single line.
2147:            yield from right_hand_split(line, py36)
2148:
2149:        if line.inside_brackets:
2150:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2151:        else:
2152:            split_funcs = [rhs]
2153:    for split_func in split_funcs:
2154:        # We are accumulating lines in `result` because we might want to abort
2155:        # mission and return the original line in the end, or attempt a different
2156:        # split altogether.
2157:        result: List[Line] = []
2158:        try:
2159:            for l in split_func(line, py36):
2160:                if str(l).strip("\n") == line_str:
2161:                    raise CannotSplit("Split function returned an unchanged result")
2162:
2163:                result.extend(
2164:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2165:                )
2166:        except CannotSplit:
2167:            continue
2168:
2169:        else:
2170:            yield from result
2171:            break
2172:
2173:    else:
2174:        yield line
2175:
2176:
2177:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2178:    """Split line into many lines, starting with the first matching bracket pair.
2179:
2180:    Note: this usually looks weird, only use this for function definitions.
2181:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2182:    :func:`right_hand_split` which also handles optional parentheses.
2183:    """
2184:    tail_leaves: List[Leaf] = []
2185:    body_leaves: List[Leaf] = []
2186:    head_leaves: List[Leaf] = []
2187:    current_leaves = head_leaves
2188:    matching_bracket = None
2189:    for leaf in line.leaves:
2190:        if (
2191:            current_leaves is body_leaves
2192:            and leaf.type in CLOSING_BRACKETS
2193:            and leaf.opening_bracket is matching_bracket
2194:        ):
2195:            current_leaves = tail_leaves if body_leaves else head_leaves
2196:        current_leaves.append(leaf)
2197:        if current_leaves is head_leaves:
2198:            if leaf.type in OPENING_BRACKETS:
2199:                matching_bracket = leaf
2200:                current_leaves = body_leaves
2201:    if not matching_bracket:
2202:        raise CannotSplit("No brackets found")
2203:
2204:    head = bracket_split_build_line(head_leaves, line, matching_bracket)
2205:    body = bracket_split_build_line(body_leaves, line, matching_bracket, is_body=True)
2206:    tail = bracket_split_build_line(tail_leaves, line, matching_bracket)
2207:    bracket_split_succeeded_or_raise(head, body, tail)

Calling tool: grepTool
\bLeaf\b
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:34:    Abstract base class for Node and Leaf.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:128:        while not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:331:class Leaf(Base):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:383:        return Leaf(self.type, self.value,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:412:    Convert raw node information to a Node or Leaf instance.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:426:        return Leaf(type, value, context=context)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/blib2to3/pytree.py:539:        if not isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:45:from blib2to3.pytree import Node, Leaf, type_repr
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:69:LN = Union[Leaf, Node]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:704:    if isinstance(result, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:725:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:769:    def show(cls, code: Union[str, Leaf, Node]) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:898:    bracket_match: Dict[Tuple[Depth, NodeType], Leaf] = Factory(dict)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:900:    previous: Optional[Leaf] = None
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:904:    def mark(self, leaf: Leaf) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:967:    def maybe_increment_for_loop_variable(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:980:    def maybe_decrement_after_for_loop_variable(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:994:    def maybe_increment_lambda_arguments(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1007:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1020:    def get_open_lsqb(self) -> Optional[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1030:    leaves: List[Leaf] = Factory(list)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1033:    comments: Dict[LeafID, List[Leaf]] = Factory(dict)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1038:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1066:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1111:            Leaf(token.DOT, ".") for _ in range(3)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1123:            second_leaf: Optional[Leaf] = self.leaves[1]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1174:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1228:    def append_comment(self, comment: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1253:    def comments_after(self, leaf: Leaf) -> List[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1271:    def is_complex_subscript(self, leaf: Leaf) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1452:        if isinstance(node, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1565:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1569:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1574:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1611:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1841:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1846:            if isinstance(res, Leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1867:def container_of(leaf: Leaf) -> LN:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1892:def is_split_after_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> int:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1906:def is_split_before_delimiter(leaf: Leaf, previous: Optional[Leaf] = None) -> int:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1954:            not isinstance(leaf.prev_sibling, Leaf)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2006:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2015:    This is why this function generates simple parentless Leaf objects for
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2026:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2033:    It's not a :class:`blib2to3.pytree.Leaf` so that:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2035:    * it can be cached (`Leaf` objects should not be reused more than once as
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2184:    tail_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2185:    body_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2186:    head_leaves: List[Leaf] = []
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2224:    tail_leaves: List[Leaf] = []

Calling tool: grepTool
\bSTANDALONE_COMMENT\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:793:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:794:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1076:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1086:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1161:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1231:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1241:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:1608:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2023:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2041:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2067:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2427:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2735:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:2765:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py:3051:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/black.py
2468:        t == token.NAME
2469:        and (
2470:            (v == "import" and p and p.type == syms.import_name)
2471:            or (v == "from" and p and p.type == syms.import_from)
2472:        )
2473:    )
2474:
2475:
2476:def is_special_comment(leaf: Leaf) -> bool:
2477:    """Return True if the given leaf is a special comment.
2478:    Only returns true for type comments for now."""
2479:    t = leaf.type
2480:    v = leaf.value
2481:    return bool(
2482:        (t == token.COMMENT or t == STANDALONE_COMMENT) and (v.startswith("# type:"))
2483:    )
2484:
2485:
2486:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2487:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2488:    else.
2489:
2490:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2491:    """

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `is_special_comment()` is defined at module scope (black.py:2476) and is only referenced inside `split_line()` (black.py:2121). `split_line()` is only called from within other functions (e.g., `format_str`), not at import time, so the definition order is safe.

Todo item 9 of 10 is correct
description: 'Review that `is_special_comment()` is declared at module scope before any potential use at import time (it is only called within `split_line()` during execution, so definition order is safe).'

Validating todo item 10 of 10
description: 'Inspect `tests` for `test_comments6` to ensure it exercises a multiline function with per-parameter `# type:` comments (and a trailing return type comment) and asserts formatting is not collapsed into a single line containing multiple `# type:` comments, matching the PR intent to preserve multiline in this case.'

Calling tool: grepTool
test_comments6\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py:366:    def test_comments6(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py
340:
341:    @patch("black.dump_to_file", dump_to_stderr)
342:    def test_comments3(self) -> None:
343:        source, expected = read_data("comments3")
344:        actual = fs(source)
345:        self.assertFormatEqual(expected, actual)
346:        black.assert_equivalent(source, actual)
347:        black.assert_stable(source, actual, line_length=ll)
348:
349:    @patch("black.dump_to_file", dump_to_stderr)
350:    def test_comments4(self) -> None:
351:        source, expected = read_data("comments4")
352:        actual = fs(source)
353:        self.assertFormatEqual(expected, actual)
354:        black.assert_equivalent(source, actual)
355:        black.assert_stable(source, actual, line_length=ll)
356:
357:    @patch("black.dump_to_file", dump_to_stderr)
358:    def test_comments5(self) -> None:
359:        source, expected = read_data("comments5")
360:        actual = fs(source)
361:        self.assertFormatEqual(expected, actual)
362:        black.assert_equivalent(source, actual)
363:        black.assert_stable(source, actual, line_length=ll)
364:
365:    @patch("black.dump_to_file", dump_to_stderr)
366:    def test_comments6(self) -> None:
367:        source, expected = read_data("comments6")
368:        actual = fs(source)
369:        self.assertFormatEqual(expected, actual)
370:        black.assert_equivalent(source, actual)
371:        black.assert_stable(source, actual, line_length=ll)
372:
373:    @patch("black.dump_to_file", dump_to_stderr)
374:    def test_cantfit(self) -> None:
375:        source, expected = read_data("cantfit")
376:        actual = fs(source)
377:        self.assertFormatEqual(expected, actual)
378:        black.assert_equivalent(source, actual)
379:        black.assert_stable(source, actual, line_length=ll)
380:
381:    @patch("black.dump_to_file", dump_to_stderr)
382:    def test_import_spacing(self) -> None:
383:        source, expected = read_data("import_spacing")
384:        actual = fs(source)
385:        self.assertFormatEqual(expected, actual)
386:        black.assert_equivalent(source, actual)
387:        black.assert_stable(source, actual, line_length=ll)
388:
389:    @patch("black.dump_to_file", dump_to_stderr)
390:    def test_composition(self) -> None:
391:        source, expected = read_data("composition")
392:        actual = fs(source)
393:        self.assertFormatEqual(expected, actual)
394:        black.assert_equivalent(source, actual)
395:        black.assert_stable(source, actual, line_length=ll)
396:
397:    @patch("black.dump_to_file", dump_to_stderr)
398:    def test_empty_lines(self) -> None:
399:        source, expected = read_data("empty_lines")
400:        actual = fs(source)
401:        self.assertFormatEqual(expected, actual)
402:        black.assert_equivalent(source, actual)
403:        black.assert_stable(source, actual, line_length=ll)
404:
405:    @patch("black.dump_to_file", dump_to_stderr)
406:    def test_string_prefixes(self) -> None:
407:        source, expected = read_data("string_prefixes")
408:        actual = fs(source)
409:        self.assertFormatEqual(expected, actual)
410:        black.assert_equivalent(source, actual)
411:        black.assert_stable(source, actual, line_length=ll)
412:
413:    @patch("black.dump_to_file", dump_to_stderr)
414:    def test_numeric_literals(self) -> None:
415:        source, expected = read_data("numeric_literals")
416:        actual = fs(source, mode=black.FileMode.PYTHON36)
417:        self.assertFormatEqual(expected, actual)
418:        black.assert_equivalent(source, actual)
419:        black.assert_stable(source, actual, line_length=ll)
420:
421:    @patch("black.dump_to_file", dump_to_stderr)
422:    def test_numeric_literals_ignoring_underscores(self) -> None:
423:        source, expected = read_data("numeric_literals_skip_underscores")
424:        mode = (
425:            black.FileMode.PYTHON36 | black.FileMode.NO_NUMERIC_UNDERSCORE_NORMALIZATION
426:        )
427:        actual = fs(source, mode=mode)
428:        self.assertFormatEqual(expected, actual)
429:        black.assert_equivalent(source, actual)
430:        black.assert_stable(source, actual, line_length=ll, mode=mode)
431:
432:    @patch("black.dump_to_file", dump_to_stderr)
433:    def test_numeric_literals_py2(self) -> None:
434:        source, expected = read_data("numeric_literals_py2")
435:        actual = fs(source)
436:        self.assertFormatEqual(expected, actual)
437:        black.assert_stable(source, actual, line_length=ll)
438:
439:    @patch("black.dump_to_file", dump_to_stderr)
440:    def test_python2(self) -> None:
441:        source, expected = read_data("python2")
442:        actual = fs(source)
443:        self.assertFormatEqual(expected, actual)
444:        # black.assert_equivalent(source, actual)
445:        black.assert_stable(source, actual, line_length=ll)
446:
447:    @patch("black.dump_to_file", dump_to_stderr)
448:    def test_python2_unicode_literals(self) -> None:
449:        source, expected = read_data("python2_unicode_literals")
450:        actual = fs(source)
451:        self.assertFormatEqual(expected, actual)
452:        black.assert_stable(source, actual, line_length=ll)
453:
454:    @patch("black.dump_to_file", dump_to_stderr)
455:    def test_stub(self) -> None:
456:        mode = black.FileMode.PYI
457:        source, expected = read_data("stub.pyi")
458:        actual = fs(source, mode=mode)
459:        self.assertFormatEqual(expected, actual)

Calling tool: globTool
**/tests/data/*comments6*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/data/comments6.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/data/comments6.py
1:from typing import Any, Tuple
2:
3:
4:def f(
5:    a,  # type: int
6:):
7:    pass
8:
9:
10:# test type comments
11:def f(a, b, c, d, e, f, g, h, i):
12:    # type: (int, int, int, int, int, int, int, int, int) -> None
13:    pass
14:
15:
16:def f(
17:    a,  # type: int
18:    b,  # type: int
19:    c,  # type: int
20:    d,  # type: int
21:    e,  # type: int
22:    f,  # type: int
23:    g,  # type: int
24:    h,  # type: int
25:    i,  # type: int
26:):
27:    # type: (...) -> None
28:    pass
29:
30:
31:def f(
32:    arg,  # type: int
33:    *args,  # type: *Any
34:    default=False,  # type: bool
35:    **kwargs,  # type: **Any
36:):
37:    # type: (...) -> None
38:    pass
39:
40:
41:def f(
42:    a,  # type: int
43:    b,  # type: int
44:    c,  # type: int
45:    d,  # type: int
46:):
47:    # type: (...) -> None
48:
49:    element = 0  # type: int
50:    another_element = 1  # type: float
51:    another_element_with_long_name = 2  # type: int
52:    another_really_really_long_element_with_a_unnecessarily_long_name_to_describe_what_it_does_enterprise_style = (
53:        3
54:    )  # type: int
55:
56:    tup = (
57:        another_element,  # type: int
58:        another_really_really_long_element_with_a_unnecessarily_long_name_to_describe_what_it_does_enterprise_style,  # type: int
59:    )  # type: Tuple[int, int]
60:
61:    a = (
62:        element
63:        + another_element
64:        + another_element_with_long_name
65:        + element
66:        + another_element
67:        + another_element_with_long_name
68:    )  # type: int

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py:54:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-11/good/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager, redirect_stderr
5:from functools import partial, wraps
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import (
13:    Any,
14:    BinaryIO,
15:    Callable,
16:    Coroutine,
17:    Generator,
18:    List,
19:    Tuple,
20:    Iterator,
21:    TypeVar,
22:)
23:import unittest
24:from unittest.mock import patch, MagicMock
25:
26:from click import unstyle
27:from click.testing import CliRunner
28:
29:import black
30:
31:try:
32:    import blackd
33:    from aiohttp.test_utils import TestClient, TestServer
34:except ImportError:
35:    has_blackd_deps = False
36:else:
37:    has_blackd_deps = True
38:
39:
40:ll = 88
41:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
42:fs = partial(black.format_str, line_length=ll)
43:THIS_FILE = Path(__file__)
44:THIS_DIR = THIS_FILE.parent
45:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
46:T = TypeVar("T")
47:R = TypeVar("R")
48:
49:
50:def dump_to_stderr(*output: str) -> str:
51:    return "\n" + "\n".join(output) + "\n"
52:
53:
54:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
55:    """read_data('test_name') -> 'input', 'output'"""
56:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
57:        name += ".py"
58:    _input: List[str] = []
59:    _output: List[str] = []
60:    base_dir = THIS_DIR / "data" if data else THIS_DIR
61:    with open(base_dir / name, "r", encoding="utf8") as test:
62:        lines = test.readlines()
63:    result = _input
64:    for line in lines:
65:        line = line.replace(EMPTY_LINE, "")
66:        if line.rstrip() == "# output":
67:            result = _output
68:            continue
69:
70:        result.append(line)
71:    if _input and not _output:
72:        # If there's no output marker, treat the entire file as already pre-formatted.
73:        _output = _input[:]
74:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
75:
76:
77:@contextmanager
78:def cache_dir(exists: bool = True) -> Iterator[Path]:
79:    with TemporaryDirectory() as workspace:
80:        cache_dir = Path(workspace)
81:        if not exists:
82:            cache_dir = cache_dir / "new"
83:        with patch("black.CACHE_DIR", cache_dir):
84:            yield cache_dir
85:
86:
87:@contextmanager
88:def event_loop(close: bool) -> Iterator[None]:
89:    policy = asyncio.get_event_loop_policy()
90:    old_loop = policy.get_event_loop()
91:    loop = policy.new_event_loop()
92:    asyncio.set_event_loop(loop)
93:    try:
94:        yield
95:
96:    finally:
97:        policy.set_event_loop(old_loop)
98:        if close:
99:            loop.close()
100:
101:
102:def async_test(f: Callable[..., Coroutine[Any, None, R]]) -> Callable[..., None]:
103:    @event_loop(close=True)
104:    @wraps(f)
105:    def wrapper(*args: Any, **kwargs: Any) -> None:
106:        asyncio.get_event_loop().run_until_complete(f(*args, **kwargs))
107:
108:    return wrapper
109:
110:
111:class BlackRunner(CliRunner):
112:    """Modify CliRunner so that stderr is not merged with stdout.
113:
114:    This is a hack that can be removed once we depend on Click 7.x"""
115:
116:    def __init__(self) -> None:
117:        self.stderrbuf = BytesIO()
118:        self.stdoutbuf = BytesIO()
119:        self.stdout_bytes = b""
120:        self.stderr_bytes = b""

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: tests/test_black.py:test_comments6 reads tests/data/comments6.py as both input and expected (no # output marker), so it asserts formatting is unchanged. comments6.py includes a multiline def with per-parameter “# type:” comments and a trailing return type comment (lines 16–28), ensuring Black does not collapse it into a single line with multiple type comments.

Todo item 10 of 10 is correct
description: 'Inspect `tests` for `test_comments6` to ensure it exercises a multiline function with per-parameter `# type:` comments (and a trailing return type comment) and asserts formatting is not collapsed into a single line containing multiple `# type:` comments, matching the PR intent to preserve multiline in this case.'


=== PHASE 2 COMPLETE ===

