=== PHASE 1: ANALYSIS ===

[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "class Feature\\(|VERSION_TO_FEATURES|get_parser_configs|lib2to3_parse\\(|TokenizerConfig|generate_tokens\\(|async_is_reserved_keyword|parse_string\\(",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "test_async_as_identifier",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "elif initial\\.isidentifier\\(\\).*async|await",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "def lib2to3_parse\\(",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "from attr import dataclass|@dataclass",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "Driver\\(", "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black" ]
Calling tool: grepTool
class Feature\(|VERSION_TO_FEATURES|get_parser_configs|lib2to3_parse\(|TokenizerConfig|generate_tokens\(|async_is_reserved_keyword|parse_string\(
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/coverage_bugsinpy.txt:42:    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:699:    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:767:def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:775:            result = drv.parse_string(src_txt, True)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:861:            code = lib2to3_parse(code)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:3129:        version for version in TargetVersion if features <= VERSION_TO_FEATURES[version]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:699:    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:767:def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:775:            result = drv.parse_string(src_txt, True)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:861:            code = lib2to3_parse(code)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:3129:        version for version in TargetVersion if features <= VERSION_TO_FEATURES[version]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/data/debug_visitor.py:32:        list(v.visit(lib2to3_parse(code)))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:6:generate_tokens(readline) is a generator that breaks a stream of
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:161:    tuples generated by generate_tokens().
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:170:    for token_info in generate_tokens(readline):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:328:        t1 = [tok[:2] for tok in generate_tokens(f.readline)]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:331:        t2 = [tok[:2] for tokin generate_tokens(readline)]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:337:def generate_tokens(readline):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py:339:    The generate_tokens() generator requires one argument, readline, which
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.pyi:28:def generate_tokens(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py.original:100:        tokens = tokenize.generate_tokens(stream.readline)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py.original:112:    def parse_string(self, text, debug=False):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py.original:114:        tokens = tokenize.generate_tokens(io.StringIO(text).readline)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:6:generate_tokens(readline) is a generator that breaks a stream of
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:161:    tuples generated by generate_tokens().
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:170:    for token_info in generate_tokens(readline):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:328:        t1 = [tok[:2] for tok in generate_tokens(f.readline)]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:331:        t2 = [tok[:2] for tokin generate_tokens(readline)]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:337:def generate_tokens(readline):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py.original:339:    The generate_tokens() generator requires one argument, readline, which
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/pgen.py:19:        self.generator = tokenize.generate_tokens(stream.readline)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py:100:        tokens = tokenize.generate_tokens(stream.readline)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py:112:    def parse_string(self, text, debug=False):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py:114:        tokens = tokenize.generate_tokens(io.StringIO(text).readline)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.pyi:22:    def parse_string(self, text: Text, debug: bool = ...) -> _NL: ...
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:147:                exp_node = black.lib2to3_parse(expected)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:154:                exp_node = black.lib2to3_parse(actual)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:877:    def test_lib2to3_parse(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:879:            black.lib2to3_parse("invalid syntax")
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:882:        black.lib2to3_parse(straddling)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:883:        black.lib2to3_parse(straddling, {TargetVersion.PY27})
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:884:        black.lib2to3_parse(straddling, {TargetVersion.PY36})
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:885:        black.lib2to3_parse(straddling, {TargetVersion.PY27, TargetVersion.PY36})
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:888:        black.lib2to3_parse(py2_only)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(
220:            filename=value, hint=f"Error reading configuration file: {e}"
221:        )
222:
223:    if not config:
224:        return None
225:
226:    if ctx.default_map is None:
227:        ctx.default_map = {}
228:    ctx.default_map.update(  # type: ignore  # bad types in .pyi
229:        {k.replace("--", "").replace("-", "_"): v for k, v in config.items()}
230:    )
231:    return value
232:
233:
234:@click.command(context_settings=dict(help_option_names=["-h", "--help"]))
235:@click.option("-c", "--code", type=str, help="Format the code passed in as a string.")
236:@click.option(
237:    "-l",
238:    "--line-length",
239:    type=int,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(
220:            filename=value, hint=f"Error reading configuration file: {e}"
221:        )
222:
223:    if not config:
224:        return None
225:
226:    if ctx.default_map is None:
227:        ctx.default_map = {}
228:    ctx.default_map.update(  # type: ignore  # bad types in .pyi
229:        {k.replace("--", "").replace("-", "_"): v for k, v in config.items()}
230:    )
231:    return value
232:
233:
234:@click.command(context_settings=dict(help_option_names=["-h", "--help"]))
235:@click.option("-c", "--code", type=str, help="Format the code passed in as a string.")
236:@click.option(
237:    "-l",
238:    "--line-length",
239:    type=int,
240:    default=DEFAULT_LINE_LENGTH,
241:    help="How many characters per line to allow.",
242:    show_default=True,
243:)
244:@click.option(
245:    "-t",
246:    "--target-version",
247:    type=click.Choice([v.name.lower() for v in TargetVersion]),
248:    callback=lambda c, p, v: [TargetVersion[val.upper()] for val in v],
249:    multiple=True,
250:    help=(
251:        "Python versions that should be supported by Black's output. [default: "
252:        "per-file auto-detection]"
253:    ),
254:)
255:@click.option(
256:    "--py36",
257:    is_flag=True,
258:    help=(
259:        "Allow using Python 3.6-only syntax on all input files.  This will put "
260:        "trailing commas in function signatures and calls also after *args and "
261:        "**kwargs. Deprecated; use --target-version instead. "
262:        "[default: per-file auto-detection]"
263:    ),
264:)
265:@click.option(
266:    "--pyi",
267:    is_flag=True,
268:    help=(
269:        "Format all input files like typing stubs regardless of file extension "
270:        "(useful when piping source on standard input)."
271:    ),
272:)
273:@click.option(
274:    "-S",
275:    "--skip-string-normalization",
276:    is_flag=True,
277:    help="Don't normalize string quotes or prefixes.",
278:)
279:@click.option(
280:    "--check",
281:    is_flag=True,
282:    help=(
283:        "Don't write the files back, just return the status.  Return code 0 "
284:        "means nothing would change.  Return code 1 means some files would be "
285:        "reformatted.  Return code 123 means there was an internal error."
286:    ),
287:)
288:@click.option(
289:    "--diff",
290:    is_flag=True,
291:    help="Don't write the files back, just output a diff for each file on stdout.",
292:)
293:@click.option(
294:    "--fast/--safe",
295:    is_flag=True,
296:    help="If --fast given, skip temporary sanity checks. [default: --safe]",
297:)
298:@click.option(
299:    "--include",
300:    type=str,
301:    default=DEFAULT_INCLUDES,
302:    help=(
303:        "A regular expression that matches files and directories that should be "
304:        "included on recursive searches.  An empty value means all files are "
305:        "included regardless of the name.  Use forward slashes for directories on "
306:        "all platforms (Windows, too).  Exclusions are calculated first, inclusions "
307:        "later."
308:    ),
309:    show_default=True,
310:)
311:@click.option(
312:    "--exclude",
313:    type=str,
314:    default=DEFAULT_EXCLUDES,
315:    help=(
316:        "A regular expression that matches files and directories that should be "
317:        "excluded on recursive searches.  An empty value means no paths are excluded. "
318:        "Use forward slashes for directories on all platforms (Windows, too).  "
319:        "Exclusions are calculated first, inclusions later."

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py
1:# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
2:# Licensed to PSF under a Contributor Agreement.
3:
4:# Modifications:
5:# Copyright 2006 Google, Inc. All Rights Reserved.
6:# Licensed to PSF under a Contributor Agreement.
7:
8:"""Parser driver.
9:
10:This provides a high-level interface to parse a file into a syntax tree.
11:
12:"""
13:
14:__author__ = "Guido van Rossum <guido@python.org>"
15:
16:__all__ = ["Driver", "load_grammar"]
17:
18:# Python imports
19:import codecs
20:import io
21:import os
22:import logging
23:import pkgutil
24:import sys
25:
26:# Pgen imports
27:from . import grammar, parse, token, tokenize, pgen
28:
29:
30:class Driver(object):
31:
32:    def __init__(self, grammar, convert=None, logger=None):
33:        self.grammar = grammar
34:        if logger is None:
35:            logger = logging.getLogger(__name__)
36:        self.logger = logger
37:        self.convert = convert
38:
39:    def parse_tokens(self, tokens, debug=False):
40:        """Parse a series of tokens and return the syntax tree."""
41:        # XXX Move the prefix computation into a wrapper around tokenize.
42:        p = parse.Parser(self.grammar, self.convert)
43:        p.setup()
44:        lineno = 1
45:        column = 0
46:        indent_columns = []
47:        type = value = start = end = line_text = None
48:        prefix = ""
49:        for quintuple in tokens:
50:            type, value, start, end, line_text = quintuple
51:            if start != (lineno, column):
52:                assert (lineno, column) <= start, ((lineno, column), start)
53:                s_lineno, s_column = start
54:                if lineno < s_lineno:
55:                    prefix += "\n" * (s_lineno - lineno)
56:                    lineno = s_lineno
57:                    column = 0
58:                if column < s_column:
59:                    prefix += line_text[column:s_column]
60:                    column = s_column
61:            if type in (tokenize.COMMENT, tokenize.NL):
62:                prefix += value
63:                lineno, column = end
64:                if value.endswith("\n"):
65:                    lineno += 1
66:                    column = 0
67:                continue
68:            if type == token.OP:
69:                type = grammar.opmap[value]
70:            if debug:
71:                self.logger.debug("%s %r (prefix=%r)",
72:                                  token.tok_name[type], value, prefix)
73:            if type == token.INDENT:
74:                indent_columns.append(len(value))
75:                _prefix = prefix + value
76:                prefix = ""
77:                value = ""
78:            elif type == token.DEDENT:
79:                _indent_col = indent_columns.pop()
80:                prefix, _prefix = self._partially_consume_prefix(prefix, _indent_col)
81:            if p.addtoken(type, value, (prefix, start)):
82:                if debug:
83:                    self.logger.debug("Stop.")
84:                break
85:            prefix = ""
86:            if type in {token.INDENT, token.DEDENT}:
87:                prefix = _prefix
88:            lineno, column = end
89:            if value.endswith("\n"):
90:                lineno += 1
91:                column = 0
92:        else:
93:            # We never broke out -- EOF is too soon (how can this happen???)
94:            raise parse.ParseError("incomplete input",
95:                                   type, value, (prefix, start))
96:        return p.rootnode
97:
98:    def parse_stream_raw(self, stream, debug=False):
99:        """Parse a stream and return the syntax tree."""
100:        tokens = tokenize.generate_tokens(stream.readline)
101:        return self.parse_tokens(tokens, debug)
102:
103:    def parse_stream(self, stream, debug=False):
104:        """Parse a stream and return the syntax tree."""
105:        return self.parse_stream_raw(stream, debug)
106:
107:    def parse_file(self, filename, encoding=None, debug=False):
108:        """Parse a file and return the syntax tree."""
109:        with io.open(filename, "r", encoding=encoding) as stream:
110:            return self.parse_stream(stream, debug)
111:
112:    def parse_string(self, text, debug=False):
113:        """Parse a string and return the syntax tree."""
114:        tokens = tokenize.generate_tokens(io.StringIO(text).readline)
115:        return self.parse_tokens(tokens, debug)
116:
117:    def _partially_consume_prefix(self, prefix, column):
118:        lines = []
119:        current_line = ""
120:        current_column = 0
121:        wait_for_nl = False
122:        for char in prefix:
123:            current_line += char
124:            if wait_for_nl:
125:                if char == '\n':
126:                    if current_line.strip() and current_column < column:
127:                        res = ''.join(lines)
128:                        return res, prefix[len(res):]
129:
130:                    lines.append(current_line)
131:                    current_line = ""
132:                    current_column = 0
133:                    wait_for_nl = False
134:            elif char in ' \t':
135:                current_column += 1
136:            elif char == '\n':
137:                # unexpected empty line
138:                current_column = 0
139:            else:
140:                # indent is finished
141:                wait_for_nl = True
142:        return ''.join(lines), current_line
143:
144:
145:def _generate_pickle_name(gt, cache_dir=None):
146:    head, tail = os.path.splitext(gt)
147:    if tail == ".txt":
148:        tail = ""
149:    name = head + tail + ".".join(map(str, sys.version_info)) + ".pickle"
150:    if cache_dir:
151:        return os.path.join(cache_dir, os.path.basename(name))
152:    else:
153:        return name
154:
155:
156:def load_grammar(gt="Grammar.txt", gp=None,
157:                 save=True, force=False, logger=None):
158:    """Load the grammar (maybe from a pickle)."""
159:    if logger is None:
160:        logger = logging.getLogger(__name__)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py.original
1:# Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
2:# Licensed to PSF under a Contributor Agreement.
3:
4:# Modifications:
5:# Copyright 2006 Google, Inc. All Rights Reserved.
6:# Licensed to PSF under a Contributor Agreement.
7:
8:"""Parser driver.
9:
10:This provides a high-level interface to parse a file into a syntax tree.
11:
12:"""
13:
14:__author__ = "Guido van Rossum <guido@python.org>"
15:
16:__all__ = ["Driver", "load_grammar"]
17:
18:# Python imports
19:import codecs
20:import io
21:import os
22:import logging
23:import pkgutil
24:import sys
25:
26:# Pgen imports
27:from . import grammar, parse, token, tokenize, pgen
28:
29:
30:class Driver(object):
31:
32:    def __init__(self, grammar, convert=None, logger=None):
33:        self.grammar = grammar
34:        if logger is None:
35:            logger = logging.getLogger(__name__)
36:        self.logger = logger
37:        self.convert = convert
38:
39:    def parse_tokens(self, tokens, debug=False):
40:        """Parse a series of tokens and return the syntax tree."""
41:        # XXX Move the prefix computation into a wrapper around tokenize.
42:        p = parse.Parser(self.grammar, self.convert)
43:        p.setup()
44:        lineno = 1
45:        column = 0
46:        indent_columns = []
47:        type = value = start = end = line_text = None
48:        prefix = ""
49:        for quintuple in tokens:
50:            type, value, start, end, line_text = quintuple
51:            if start != (lineno, column):
52:                assert (lineno, column) <= start, ((lineno, column), start)
53:                s_lineno, s_column = start
54:                if lineno < s_lineno:
55:                    prefix += "\n" * (s_lineno - lineno)
56:                    lineno = s_lineno
57:                    column = 0
58:                if column < s_column:
59:                    prefix += line_text[column:s_column]
60:                    column = s_column
61:            if type in (tokenize.COMMENT, tokenize.NL):
62:                prefix += value
63:                lineno, column = end
64:                if value.endswith("\n"):
65:                    lineno += 1
66:                    column = 0
67:                continue
68:            if type == token.OP:
69:                type = grammar.opmap[value]
70:            if debug:
71:                self.logger.debug("%s %r (prefix=%r)",
72:                                  token.tok_name[type], value, prefix)
73:            if type == token.INDENT:
74:                indent_columns.append(len(value))
75:                _prefix = prefix + value
76:                prefix = ""
77:                value = ""
78:            elif type == token.DEDENT:
79:                _indent_col = indent_columns.pop()
80:                prefix, _prefix = self._partially_consume_prefix(prefix, _indent_col)
81:            if p.addtoken(type, value, (prefix, start)):
82:                if debug:
83:                    self.logger.debug("Stop.")
84:                break
85:            prefix = ""
86:            if type in {token.INDENT, token.DEDENT}:
87:                prefix = _prefix
88:            lineno, column = end
89:            if value.endswith("\n"):
90:                lineno += 1
91:                column = 0
92:        else:
93:            # We never broke out -- EOF is too soon (how can this happen???)
94:            raise parse.ParseError("incomplete input",
95:                                   type, value, (prefix, start))
96:        return p.rootnode
97:
98:    def parse_stream_raw(self, stream, debug=False):
99:        """Parse a stream and return the syntax tree."""
100:        tokens = tokenize.generate_tokens(stream.readline)
101:        return self.parse_tokens(tokens, debug)
102:
103:    def parse_stream(self, stream, debug=False):
104:        """Parse a stream and return the syntax tree."""
105:        return self.parse_stream_raw(stream, debug)
106:
107:    def parse_file(self, filename, encoding=None, debug=False):
108:        """Parse a file and return the syntax tree."""
109:        with io.open(filename, "r", encoding=encoding) as stream:
110:            return self.parse_stream(stream, debug)
111:
112:    def parse_string(self, text, debug=False):
113:        """Parse a string and return the syntax tree."""
114:        tokens = tokenize.generate_tokens(io.StringIO(text).readline)
115:        return self.parse_tokens(tokens, debug)
116:
117:    def _partially_consume_prefix(self, prefix, column):
118:        lines = []
119:        current_line = ""
120:        current_column = 0
121:        wait_for_nl = False
122:        for char in prefix:
123:            current_line += char
124:            if wait_for_nl:
125:                if char == '\n':
126:                    if current_line.strip() and current_column < column:
127:                        res = ''.join(lines)
128:                        return res, prefix[len(res):]
129:
130:                    lines.append(current_line)
131:                    current_line = ""
132:                    current_column = 0
133:                    wait_for_nl = False
134:            elif char in ' \t':
135:                current_column += 1
136:            elif char == '\n':
137:                # unexpected empty line
138:                current_column = 0
139:            else:
140:                # indent is finished

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py
1:# Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.
2:# All rights reserved.
3:
4:"""Tokenization help for Python programs.
5:
6:generate_tokens(readline) is a generator that breaks a stream of
7:text into Python tokens.  It accepts a readline-like method which is called
8:repeatedly to get the next line of input (or "" for EOF).  It generates
9:5-tuples with these members:
10:
11:    the token type (see token.py)
12:    the token (a string)
13:    the starting (row, column) indices of the token (a 2-tuple of ints)
14:    the ending (row, column) indices of the token (a 2-tuple of ints)
15:    the original line (string)
16:
17:It is designed to match the working of the Python tokenizer exactly, except
18:that it produces COMMENT tokens for comments and gives type OP for all
19:operators
20:
21:Older entry points
22:    tokenize_loop(readline, tokeneater)
23:    tokenize(readline, tokeneater=printtoken)
24:are the same, except instead of generating tokens, tokeneater is a callback
25:function to which the 5 fields described above are passed as 5 arguments,
26:each time a new token is found."""
27:
28:__author__ = 'Ka-Ping Yee <ping@lfw.org>'
29:__credits__ = \
30:    'GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro'
31:
32:import re
33:from codecs import BOM_UTF8, lookup
34:from blib2to3.pgen2.token import *
35:
36:from . import token
37:__all__ = [x for x in dir(token) if x[0] != '_'] + ["tokenize",
38:           "generate_tokens", "untokenize"]
39:del token
40:
41:try:
42:    bytes
43:except NameError:
44:    # Support bytes type in Python <= 2.5, so 2to3 turns itself into
45:    # valid Python 3 code.
46:    bytes = str
47:
48:def group(*choices): return '(' + '|'.join(choices) + ')'
49:def any(*choices): return group(*choices) + '*'
50:def maybe(*choices): return group(*choices) + '?'
51:def _combinations(*l):
52:    return set(
53:        x + y for x in l for y in l + ("",) if x.casefold() != y.casefold()
54:    )
55:
56:Whitespace = r'[ \f\t]*'
57:Comment = r'#[^\r\n]*'
58:Ignore = Whitespace + any(r'\\\r?\n' + Whitespace) + maybe(Comment)
59:Name = r'\w+'  # this is invalid but it's fine because Name comes after Number in all groups
60:
61:Binnumber = r'0[bB]_?[01]+(?:_[01]+)*'
62:Hexnumber = r'0[xX]_?[\da-fA-F]+(?:_[\da-fA-F]+)*[lL]?'
63:Octnumber = r'0[oO]?_?[0-7]+(?:_[0-7]+)*[lL]?'
64:Decnumber = group(r'[1-9]\d*(?:_\d+)*[lL]?', '0[lL]?')
65:Intnumber = group(Binnumber, Hexnumber, Octnumber, Decnumber)
66:Exponent = r'[eE][-+]?\d+(?:_\d+)*'
67:Pointfloat = group(r'\d+(?:_\d+)*\.(?:\d+(?:_\d+)*)?', r'\.\d+(?:_\d+)*') + maybe(Exponent)
68:Expfloat = r'\d+(?:_\d+)*' + Exponent
69:Floatnumber = group(Pointfloat, Expfloat)
70:Imagnumber = group(r'\d+(?:_\d+)*[jJ]', Floatnumber + r'[jJ]')
71:Number = group(Imagnumber, Floatnumber, Intnumber)
72:
73:# Tail end of ' string.
74:Single = r"[^'\\]*(?:\\.[^'\\]*)*'"
75:# Tail end of " string.
76:Double = r'[^"\\]*(?:\\.[^"\\]*)*"'
77:# Tail end of ''' string.
78:Single3 = r"[^'\\]*(?:(?:\\.|'(?!''))[^'\\]*)*'''"
79:# Tail end of """ string.
80:Double3 = r'[^"\\]*(?:(?:\\.|"(?!""))[^"\\]*)*"""'
81:_litprefix = r"(?:[uUrRbBfF]|[rR][fFbB]|[fFbBuU][rR])?"
82:Triple = group(_litprefix + "'''", _litprefix + '"""')
83:# Single-line ' or " string.
84:String = group(_litprefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*'",
85:               _litprefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*"')
86:
87:# Because of leftmost-then-longest match semantics, be sure to put the
88:# longest operators first (e.g., if = came before ==, == would get
89:# recognized as two instances of =).
90:Operator = group(r"\*\*=?", r">>=?", r"<<=?", r"<>", r"!=",
91:                 r"//=?", r"->",
92:                 r"[+\-*/%&@|^=<>]=?",
93:                 r"~")
94:
95:Bracket = '[][(){}]'
96:Special = group(r'\r?\n', r'[:;.,`@]')
97:Funny = group(Operator, Bracket, Special)
98:
99:PlainToken = group(Number, Funny, String, Name)
100:Token = Ignore + PlainToken
101:
102:# First (or only) line of ' or " string.
103:ContStr = group(_litprefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*" +
104:                group("'", r'\\\r?\n'),
105:                _litprefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*' +
106:                group('"', r'\\\r?\n'))
107:PseudoExtras = group(r'\\\r?\n', Comment, Triple)
108:PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)
109:
110:tokenprog = re.compile(Token, re.UNICODE)
111:pseudoprog = re.compile(PseudoToken, re.UNICODE)
112:single3prog = re.compile(Single3)
113:double3prog = re.compile(Double3)
114:
115:_strprefixes = (
116:    _combinations('r', 'R', 'f', 'F') |
117:    _combinations('r', 'R', 'b', 'B') |
118:    {'u', 'U', 'ur', 'uR', 'Ur', 'UR'}
119:)
120:
121:endprogs = {"'": re.compile(Single), '"': re.compile(Double),
122:            "'''": single3prog, '"""': double3prog,
123:            **{f"{prefix}'''": single3prog for prefix in _strprefixes},
124:            **{f'{prefix}"""': double3prog for prefix in _strprefixes},
125:            **{prefix: None for prefix in _strprefixes}}
126:
127:triple_quoted = (
128:    {"'''", '"""'} |
129:    {f"{prefix}'''" for prefix in _strprefixes} |
130:    {f'{prefix}"""' for prefix in _strprefixes}
131:)
132:single_quoted = (
133:    {"'", '"'} |
134:    {f"{prefix}'" for prefix in _strprefixes} |
135:    {f'{prefix}"' for prefix in _strprefixes}
136:)
137:
138:tabsize = 8
139:
140:class TokenError(Exception): pass
141:
142:class StopTokenizing(Exception): pass
143:
144:def printtoken(type, token, xxx_todo_changeme, xxx_todo_changeme1, line): # for testing
145:    (srow, scol) = xxx_todo_changeme
146:    (erow, ecol) = xxx_todo_changeme1
147:    print("%d,%d-%d,%d:\t%s\t%s" % \
148:        (srow, scol, erow, ecol, tok_name[type], repr(token)))
149:
150:def tokenize(readline, tokeneater=printtoken):
151:    """
152:    The tokenize() function accepts two parameters: one representing the
153:    input stream, and one providing an output mechanism for tokenize().
154:
155:    The first parameter, readline, must be a callable object which provides
156:    the same interface as the readline() method of built-in file objects.
157:    Each call to the function should return one line of input as a string.
158:
159:    The second parameter, tokeneater, must also be a callable object. It is
160:    called once for each token, with five arguments, corresponding to the
161:    tuples generated by generate_tokens().
162:    """
163:    try:
164:        tokenize_loop(readline, tokeneater)
165:    except StopTokenizing:
166:        pass
167:
168:# backwards compatible interface
169:def tokenize_loop(readline, tokeneater):
170:    for token_info in generate_tokens(readline):
171:        tokeneater(*token_info)
172:
173:class Untokenizer:
174:
175:    def __init__(self):
176:        self.tokens = []
177:        self.prev_row = 1
178:        self.prev_col = 0
179:
180:    def add_whitespace(self, start):
181:        row, col = start
182:        assert row <= self.prev_row
183:        col_offset = col - self.prev_col
184:        if col_offset:
185:            self.tokens.append(" " * col_offset)
186:
187:    def untokenize(self, iterable):
188:        for t in iterable:
189:            if len(t) == 2:
190:                self.compat(t, iterable)
191:                break
192:            tok_type, token, start, end, line = t
193:            self.add_whitespace(start)
194:            self.tokens.append(token)
195:            self.prev_row, self.prev_col = end
196:            if tok_type in (NEWLINE, NL):
197:                self.prev_row += 1
198:                self.prev_col = 0
199:        return "".join(self.tokens)
200:
201:    def compat(self, token, iterable):
202:        startline = False
203:        indents = []
204:        toks_append = self.tokens.append
205:        toknum, tokval = token
206:        if toknum in (NAME, NUMBER):
207:            tokval += ' '
208:        if toknum in (NEWLINE, NL):
209:            startline = True
210:        for tok in iterable:
211:            toknum, tokval = tok[:2]
212:
213:            if toknum in (NAME, NUMBER, ASYNC, AWAIT):
214:                tokval += ' '
215:
216:            if toknum == INDENT:
217:                indents.append(tokval)
218:                continue
219:            elif toknum == DEDENT:
220:                indents.pop()

Calling tool: grepTool
test_async_as_identifier
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/coverage_bugsinpy.txt:1:coverage run -m unittest -q tests.test_black.BlackTestCase.test_async_as_identifier
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/coverage_bugsinpy.txt:3:FAIL: test_async_as_identifier (tests.test_black.BlackTestCase)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/coverage_bugsinpy.txt:8:  File "/workspace/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py", line 518, in test_async_as_identifier
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py:506:    def test_async_as_identifier(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_async_as_identifier

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py
480:    @patch("black.dump_to_file", dump_to_stderr)
481:    def test_python2_print_function(self) -> None:
482:        source, expected = read_data("python2_print_function")
483:        mode = black.FileMode(target_versions={TargetVersion.PY27})
484:        actual = fs(source, mode=mode)
485:        self.assertFormatEqual(expected, actual)
486:        black.assert_equivalent(source, actual)
487:        black.assert_stable(source, actual, mode)
488:
489:    @patch("black.dump_to_file", dump_to_stderr)
490:    def test_python2_unicode_literals(self) -> None:
491:        source, expected = read_data("python2_unicode_literals")
492:        actual = fs(source)
493:        self.assertFormatEqual(expected, actual)
494:        black.assert_equivalent(source, actual)
495:        black.assert_stable(source, actual, black.FileMode())
496:
497:    @patch("black.dump_to_file", dump_to_stderr)
498:    def test_stub(self) -> None:
499:        mode = black.FileMode(is_pyi=True)
500:        source, expected = read_data("stub.pyi")
501:        actual = fs(source, mode=mode)
502:        self.assertFormatEqual(expected, actual)
503:        black.assert_stable(source, actual, mode)
504:
505:    @patch("black.dump_to_file", dump_to_stderr)
506:    def test_async_as_identifier(self) -> None:
507:        source_path = (THIS_DIR / "data" / "async_as_identifier.py").resolve()
508:        source, expected = read_data("async_as_identifier")
509:        actual = fs(source)
510:        self.assertFormatEqual(expected, actual)
511:        major, minor = sys.version_info[:2]
512:        if major < 3 or (major <= 3 and minor < 7):
513:            black.assert_equivalent(source, actual)
514:        black.assert_stable(source, actual, black.FileMode())
515:        # ensure black can parse this when the target is 3.6
516:        self.invokeBlack([str(source_path), "--target-version", "py36"])
517:        # but not on 3.7, because async/await is no longer an identifier
518:        self.invokeBlack([str(source_path), "--target-version", "py37"], exit_code=123)
519:
520:    @patch("black.dump_to_file", dump_to_stderr)
521:    def test_python37(self) -> None:
522:        source_path = (THIS_DIR / "data" / "python37.py").resolve()
523:        source, expected = read_data("python37")
524:        actual = fs(source)
525:        self.assertFormatEqual(expected, actual)
526:        major, minor = sys.version_info[:2]
527:        if major > 3 or (major == 3 and minor >= 7):
528:            black.assert_equivalent(source, actual)
529:        black.assert_stable(source, actual, black.FileMode())
530:        # ensure black can parse this when the target is 3.7
531:        self.invokeBlack([str(source_path), "--target-version", "py37"])
532:        # but not on 3.6, because we use async as a reserved keyword
533:        self.invokeBlack([str(source_path), "--target-version", "py36"], exit_code=123)
534:
535:    @patch("black.dump_to_file", dump_to_stderr)
536:    def test_fmtonoff(self) -> None:
537:        source, expected = read_data("fmtonoff")
538:        actual = fs(source)
539:        self.assertFormatEqual(expected, actual)
540:        black.assert_equivalent(source, actual)
541:        black.assert_stable(source, actual, black.FileMode())
542:
543:    @patch("black.dump_to_file", dump_to_stderr)
544:    def test_fmtonoff2(self) -> None:
545:        source, expected = read_data("fmtonoff2")
546:        actual = fs(source)
547:        self.assertFormatEqual(expected, actual)
548:        black.assert_equivalent(source, actual)
549:        black.assert_stable(source, actual, black.FileMode())
550:
551:    @patch("black.dump_to_file", dump_to_stderr)
552:    def test_remove_empty_parentheses_after_class(self) -> None:
553:        source, expected = read_data("class_blank_parentheses")
554:        actual = fs(source)
555:        self.assertFormatEqual(expected, actual)
556:        black.assert_equivalent(source, actual)
557:        black.assert_stable(source, actual, black.FileMode())
558:
559:    @patch("black.dump_to_file", dump_to_stderr)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/data/async_as_identifier.py
1:def async():
2:    pass
3:
4:
5:def await():
6:    pass
7:
8:
9:await = lambda: None
10:async = lambda: None
11:async()
12:await()
13:
14:
15:def sync_fn():
16:    await = lambda: None
17:    async = lambda: None
18:    async()
19:    await()
20:
21:
22:async def async_fn():
23:    await async_fn()
24:
25:
26:# output
27:def async():
28:    pass
29:
30:
31:def await():
32:    pass
33:
34:
35:await = lambda: None
36:async = lambda: None
37:async()
38:await()
39:
40:
41:def sync_fn():
42:    await = lambda: None
43:    async = lambda: None
44:    async()
45:    await()
46:
47:
48:async def async_fn():
49:    await async_fn()

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/data/python37.py
1:#!/usr/bin/env python3.7
2:
3:def f():
4:    return (i*2 async for i in arange(42))
5:
6:def g():
7:    return (something_long * something_long async for something_long in async_generator(with_an_argument))
8:
9:async def func():
10:    if test:
11:        out_batched = [
12:            i
13:            async for i in aitertools._async_map(
14:                self.async_inc, arange(8), batch_size=3
15:            )
16:        ]
17:
18:def awaited_generator_value(n):
19:    return (await awaitable for awaitable in awaitable_list)
20:
21:def make_arange(n):
22:    return (i * 2 for i in range(n) if await wrap(i))
23:
24:
25:# output
26:
27:
28:#!/usr/bin/env python3.7
29:
30:
31:def f():
32:    return (i * 2 async for i in arange(42))
33:
34:
35:def g():
36:    return (
37:        something_long * something_long
38:        async for something_long in async_generator(with_an_argument)
39:    )
40:
41:
42:async def func():
43:    if test:
44:        out_batched = [
45:            i
46:            async for i in aitertools._async_map(
47:                self.async_inc, arange(8), batch_size=3
48:            )
49:        ]

Calling tool: grepTool
elif initial\.isidentifier\(\).*async|await
Matched content:
359:    # 'stashed' and 'async_*' are used for async/await parsing
508:                    if token in ('async', 'await'):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.py
470:
471:                elif initial == '#':
472:                    assert not token.endswith("\n")
473:                    if stashed:
474:                        yield stashed
475:                        stashed = None
476:                    yield (COMMENT, token, spos, epos, line)
477:                elif token in triple_quoted:
478:                    endprog = endprogs[token]
479:                    endmatch = endprog.match(line, pos)
480:                    if endmatch:                           # all on one line
481:                        pos = endmatch.end(0)
482:                        token = line[start:pos]
483:                        if stashed:
484:                            yield stashed
485:                            stashed = None
486:                        yield (STRING, token, spos, (lnum, pos), line)
487:                    else:
488:                        strstart = (lnum, start)           # multiple lines
489:                        contstr = line[start:]
490:                        contline = line
491:                        break
492:                elif initial in single_quoted or \
493:                    token[:2] in single_quoted or \
494:                    token[:3] in single_quoted:
495:                    if token[-1] == '\n':                  # continued string
496:                        strstart = (lnum, start)
497:                        endprog = (endprogs[initial] or endprogs[token[1]] or
498:                                   endprogs[token[2]])
499:                        contstr, needcont = line[start:], 1
500:                        contline = line
501:                        break
502:                    else:                                  # ordinary string
503:                        if stashed:
504:                            yield stashed
505:                            stashed = None
506:                        yield (STRING, token, spos, epos, line)
507:                elif initial.isidentifier():               # ordinary name
508:                    if token in ('async', 'await'):
509:                        if async_def:
510:                            yield (ASYNC if token == 'async' else AWAIT,
511:                                   token, spos, epos, line)
512:                            continue
513:
514:                    tok = (NAME, token, spos, epos, line)
515:                    if token == 'async' and not stashed:
516:                        stashed = tok
517:                        continue
518:
519:                    if token in ('def', 'for'):
520:                        if (stashed
521:                                and stashed[0] == NAME
522:                                and stashed[1] == 'async'):
523:
524:                            if token == 'def':
525:                                async_def = True
526:                                async_def_indent = indents[-1]
527:
528:                            yield (ASYNC, stashed[1],
529:                                   stashed[2], stashed[3],
530:                                   stashed[4])
531:                            stashed = None
532:
533:                    if stashed:
534:                        yield stashed
535:                        stashed = None
536:
537:                    yield tok
538:                elif initial == '\\':                      # continued stmt
539:                    # This yield is new; needed for better idempotency:
540:                    if stashed:
541:                        yield stashed
542:                        stashed = None
543:                    yield (NL, token, spos, (lnum, pos), line)
544:                    continued = 1
545:                else:
546:                    if initial in '([{': parenlev = parenlev + 1
547:                    elif initial in ')]}': parenlev = parenlev - 1
548:                    if stashed:
549:                        yield stashed
550:                        stashed = None
551:                    yield (OP, token, spos, epos, line)
552:            else:
553:                yield (ERRORTOKEN, line[pos],
554:                           (lnum, pos), (lnum, pos+1), line)
555:                pos = pos + 1
556:
557:    if stashed:
558:        yield stashed
559:        stashed = None

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/tokenize.pyi
1:# Stubs for lib2to3.pgen2.tokenize (Python 3.6)
2:# NOTE: Only elements from __all__ are present.
3:
4:from typing import Callable, Iterable, Iterator, List, Text, Tuple
5:from blib2to3.pgen2.token import *  # noqa
6:
7:
8:_Coord = Tuple[int, int]
9:_TokenEater = Callable[[int, Text, _Coord, _Coord, Text], None]
10:_TokenInfo = Tuple[int, Text, _Coord, _Coord, Text]
11:
12:
13:class TokenError(Exception): ...
14:class StopTokenizing(Exception): ...
15:
16:def tokenize(readline: Callable[[], Text], tokeneater: _TokenEater = ...) -> None: ...
17:
18:class Untokenizer:
19:    tokens: List[Text]
20:    prev_row: int
21:    prev_col: int
22:    def __init__(self) -> None: ...
23:    def add_whitespace(self, start: _Coord) -> None: ...
24:    def untokenize(self, iterable: Iterable[_TokenInfo]) -> Text: ...
25:    def compat(self, token: Tuple[int, Text], iterable: Iterable[_TokenInfo]) -> None: ...
26:
27:def untokenize(iterable: Iterable[_TokenInfo]) -> Text: ...
28:def generate_tokens(
29:    readline: Callable[[], Text]
30:) -> Iterator[_TokenInfo]: ...

Calling tool: grepTool
def lib2to3_parse\(
Matched content:
767:def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py
740:    srcbuf = io.BytesIO(src)
741:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
742:    if not lines:
743:        return "", encoding, "\n"
744:
745:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
746:    srcbuf.seek(0)
747:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
748:        return tiow.read(), encoding, newline
749:
750:
751:def get_grammars(target_versions: Set[TargetVersion]) -> List[Grammar]:
752:    if not target_versions:
753:        # No target_version specified, so try all grammars.
754:        return [
755:            pygram.python_grammar_no_print_statement_no_exec_statement,
756:            pygram.python_grammar_no_print_statement,
757:            pygram.python_grammar,
758:        ]
759:    elif all(version.is_python2() for version in target_versions):
760:        # Python 2-only code, so try Python 2 grammars.
761:        return [pygram.python_grammar_no_print_statement, pygram.python_grammar]
762:    else:
763:        # Python 3-compatible code, so only try Python 3 grammar.
764:        return [pygram.python_grammar_no_print_statement_no_exec_statement]
765:
766:
767:def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node:
768:    """Given a string with source, return the lib2to3 Node."""
769:    if src_txt[-1:] != "\n":
770:        src_txt += "\n"
771:
772:    for grammar in get_grammars(set(target_versions)):
773:        drv = driver.Driver(grammar, pytree.convert)
774:        try:
775:            result = drv.parse_string(src_txt, True)
776:            break
777:
778:        except ParseError as pe:
779:            lineno, column = pe.context[1]
780:            lines = src_txt.splitlines()
781:            try:
782:                faulty_line = lines[lineno - 1]
783:            except IndexError:
784:                faulty_line = "<line number missing in source>"
785:            exc = InvalidInput(f"Cannot parse: {lineno}:{column}: {faulty_line}")
786:    else:
787:        raise exc from None
788:
789:    if isinstance(result, Leaf):
790:        result = Node(syms.file_input, [result])
791:    return result
792:
793:
794:def lib2to3_unparse(node: Node) -> str:
795:    """Given a lib2to3 node, return its string representation."""
796:    code = str(node)
797:    return code
798:
799:
800:T = TypeVar("T")
801:
802:
803:class Visitor(Generic[T]):
804:    """Basic lib2to3 visitor that yields things of type `T` on `visit()`."""
805:
806:    def visit(self, node: LN) -> Iterator[T]:
807:        """Main method to visit `node` and its children.
808:
809:        It tries to find a `visit_*()` method for the given `node.type`, like
810:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
811:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
812:        instead.
813:
814:        Then yields objects of type `T` from the selected visitor.
815:        """
816:        if node.type < 256:
817:            name = token.tok_name[node.type]
818:        else:
819:            name = type_repr(node.type)
820:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
821:
822:    def visit_default(self, node: LN) -> Iterator[T]:
823:        """Default `visit_*()` implementation. Recurses to children of `node`."""
824:        if isinstance(node, Node):
825:            for child in node.children:
826:                yield from self.visit(child)
827:
828:
829:@dataclass
830:class DebugVisitor(Visitor[T]):
831:    tree_depth: int = 0
832:
833:    def visit_default(self, node: LN) -> Iterator[T]:
834:        indent = " " * (2 * self.tree_depth)
835:        if isinstance(node, Node):
836:            _type = type_repr(node.type)
837:            out(f"{indent}{_type}", fg="yellow")
838:            self.tree_depth += 1
839:            for child in node.children:
840:                yield from self.visit(child)
841:
842:            self.tree_depth -= 1
843:            out(f"{indent}/{_type}", fg="yellow", bold=False)
844:        else:
845:            _type = token.tok_name.get(node.type, str(node.type))
846:            out(f"{indent}{_type}", fg="blue", nl=False)
847:            if node.prefix:
848:                # We don't have to handle prefixes for `Node` objects since
849:                # that delegates to the first child anyway.
850:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
851:            out(f" {node.value!r}", fg="blue", bold=False)
852:
853:    @classmethod
854:    def show(cls, code: Union[str, Leaf, Node]) -> None:
855:        """Pretty-print the lib2to3 AST of a given string of `code`.
856:
857:        Convenience method for debugging.
858:        """
859:        v: DebugVisitor[None] = DebugVisitor()

Calling tool: grepTool
from attr import dataclass|@dataclass
Showing first 50 results from grep. Consider using a more specific pattern or path.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:40:from attr import dataclass, evolve, Factory
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:170:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:829:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:976:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:1108:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:1402:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:1513:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:2122:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:3299:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/data/debug_visitor.py:1:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:40:from attr import dataclass, evolve, Factory
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:170:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:829:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:976:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:1108:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:1402:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:1513:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:2122:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:3299:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:40:from attr import dataclass, evolve, Factory
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:170:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:829:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:976:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:1108:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:1402:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:1513:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:2122:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:3299:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/tests/data/debug_visitor.py:1:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/dataclasses-0.6.dist-info/METADATA:49:  @dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/mypyc/lib-rt/CPy.h:1464:    /* Run the @dataclass descriptor */
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/typing_extensions.py:2020:            @dataclass_transform()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/typing_extensions.py:2031:            @dataclass_transform()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/typing_extensions.py:2039:            @dataclass_transform()
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/typing_extensions.py:2049:        behave similarly to a dataclass created with the ``@dataclasses.dataclass``
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/_windows.py:5:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/console.py:125:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/console.py:547:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/progress.py:924:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/traceback.py:144:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/traceback.py:153:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/traceback.py:162:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/traceback.py:171:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/table.py:38:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/table.py:129:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/cryptography/hazmat/primitives/serialization/ssh.py:92:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/pretty.py:423:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/pretty.py:508:@dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_vendor/rich/_ratio.py:152:    @dataclass
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/lib/python3.8/site-packages/pip/_internal/self_outdated_check.py:121:@dataclass

Calling tool: grepTool
Driver\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:773:        drv = driver.Driver(grammar, pytree.convert)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py:30:class Driver(object):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/blib2to3/pgen2/driver.py.original:30:class Driver(object):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:773:        drv = driver.Driver(grammar, pytree.convert)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:773:        drv = driver.Driver(grammar, pytree.convert)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/blib2to3/pgen2/driver.py:30:class Driver(object):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py
860:            self.assertEqual(report.return_code, 123)
861:            report.done(Path("f4"), black.Changed.NO)
862:            self.assertEqual(len(out_lines), 2)
863:            self.assertEqual(len(err_lines), 2)
864:            self.assertEqual(
865:                unstyle(str(report)),
866:                "2 files reformatted, 3 files left unchanged, "
867:                "2 files failed to reformat.",
868:            )
869:            self.assertEqual(report.return_code, 123)
870:            report.check = True
871:            self.assertEqual(
872:                unstyle(str(report)),
873:                "2 files would be reformatted, 3 files would be left unchanged, "
874:                "2 files would fail to reformat.",
875:            )
876:
877:    def test_lib2to3_parse(self) -> None:
878:        with self.assertRaises(black.InvalidInput):
879:            black.lib2to3_parse("invalid syntax")
880:
881:        straddling = "x + y"
882:        black.lib2to3_parse(straddling)
883:        black.lib2to3_parse(straddling, {TargetVersion.PY27})
884:        black.lib2to3_parse(straddling, {TargetVersion.PY36})
885:        black.lib2to3_parse(straddling, {TargetVersion.PY27, TargetVersion.PY36})
886:
887:        py2_only = "print x"
888:        black.lib2to3_parse(py2_only)
889:        black.lib2to3_parse(py2_only, {TargetVersion.PY27})
890:        with self.assertRaises(black.InvalidInput):
891:            black.lib2to3_parse(py2_only, {TargetVersion.PY36})
892:        with self.assertRaises(black.InvalidInput):
893:            black.lib2to3_parse(py2_only, {TargetVersion.PY27, TargetVersion.PY36})
894:
895:        py3_only = "exec(x, end=y)"
896:        black.lib2to3_parse(py3_only)
897:        with self.assertRaises(black.InvalidInput):
898:            black.lib2to3_parse(py3_only, {TargetVersion.PY27})
899:        black.lib2to3_parse(py3_only, {TargetVersion.PY36})

Calling tool: createTodo
Todo List Created
Todo List (20 items):
- [ ] Verify Feature enum includes ASYNC_IS_VALID_IDENTIFIER and ASYNC_IS_RESERVED_KEYWORD with clear mutual-exclusivity intent (comment present) as per PR. (ID: todo-1)
- [ ] Verify VERSION_TO_FEATURES mapping assigns ASYNC_IS_VALID_IDENTIFIER to PY27PY36 and ASYNC_IS_RESERVED_KEYWORD to PY37+ (PY37, PY38), and that exactly one of the two flags is present for each TargetVersion. (ID: todo-2)
- [ ] Check that black.py imports TokenizerConfig from blib2to3.pgen2.tokenize and that it is used in parser configuration. (ID: todo-3)
- [ ] Confirm a new @dataclass(frozen=True) ParserConfig is defined with fields: grammar: Grammar and tokenizer_config: TokenizerConfig = TokenizerConfig(). (ID: todo-4)
- [ ] Validate get_parser_configs() replaces get_grammars() and returns the correct ordered list when target_versions is empty: (1) Python 3.7+ grammar with TokenizerConfig(async_is_reserved_keyword=True); (2) Python 3.03.6 grammar with TokenizerConfig(async_is_reserved_keyword=False); (3) Python 2.7 no_print grammar; (4) Python 2.7 grammar. (ID: todo-5)
- [ ] Validate get_parser_configs() returns only Python 2 grammars (no TokenizerConfig argument) when all target versions are Python 2. (ID: todo-6)
- [ ] Validate get_parser_configs() logic for Python 3 target_versions: it adds (in order) the 3.7+ reserved-keyword config if not supports_feature(ASYNC_IS_VALID_IDENTIFIER), and the 3.03.6 non-reserved config if not supports_feature(ASYNC_IS_RESERVED_KEYWORD). Ensure at least one branch is taken for any Python 3 target set. (ID: todo-7)
- [ ] Verify that lib2to3_parse() now iterates over get_parser_configs(), constructing driver.Driver with parser_config.grammar and tokenizer_config=parser_config.tokenizer_config, and attempts parse_string accordingly. (ID: todo-8)
- [ ] Verify that get_grammars() is no longer used anywhere; only get_parser_configs() is referenced, preventing stale behavior. (ID: todo-9)
- [ ] Confirm blib2to3/pgen2/driver.Driver.__init__ signature includes tokenizer_config=tokenize.TokenizerConfig(), stores it as self.tokenizer_config, and maintains backward compatibility for existing call sites. (ID: todo-10)
- [ ] Confirm driver.parse_stream_raw() and driver.parse_string() pass config=self.tokenizer_config to tokenize.generate_tokens(). (ID: todo-11)
- [ ] Verify blib2to3/pgen2/tokenize defines @dataclass(frozen=True) TokenizerConfig with field async_is_reserved_keyword: bool = False, and that generate_tokens(readline, config: TokenizerConfig = TokenizerConfig()) signature is updated accordingly. (ID: todo-12)
- [ ] In generate_tokens(), verify async_is_reserved_keyword = config.async_is_reserved_keyword is read and used to control tokenization of 'async'/'await'. (ID: todo-13)
- [ ] Critically check the async/await tokenization condition: in reserved-keyword mode (async_is_reserved_keyword=True), 'async' and 'await' must be tokenized as ASYNC/AWAIT regardless of async_def context. Flag if the implementation still requires async_def (e.g., condition 'if async_is_reserved_keyword and async_def'). (ID: todo-14)
- [ ] Ensure Untokenizer.compat() accounts for ASYNC and AWAIT tokens (already present) so expanded ASYNC/AWAIT usage formats with appropriate spacing. (ID: todo-15)
- [ ] Verify black.tests test_async_as_identifier uses data file async_as_identifier.py and asserts: formatting succeeds; black can parse with --target-version py36; black fails with --target-version py37. (ID: todo-16)
- [ ] Verify black.tests test_python37 uses data file python37.py and asserts: formatting succeeds; black can parse with --target-version py37; black fails with --target-version py36. (ID: todo-17)
- [ ] Check tests/data/python37.py includes added cases: awaited_generator_value with '(await awaitable for ...)' and make_arange with 'if await wrap(i)' inside a generator expression. (ID: todo-18)
- [ ] Validate black.tests test_lib2to3_parse expectations still align: when target_versions includes {PY27, PY36}, only Python 3 grammar is tried (so 'print x' fails), while straddling code parses across configurations. (ID: todo-19)
- [ ] Confirm type stubs reflect API changes: blib2to3/pgen2/tokenize.pyi generate_tokens signature updated to include 'config: TokenizerConfig = ...'; and, if driver.pyi exists, consider whether Driver.__init__ needs corresponding stub update (or document that runtime change is acceptable without stub change). (ID: todo-20)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 20
description: 'Verify Feature enum includes ASYNC_IS_VALID_IDENTIFIER and ASYNC_IS_RESERVED_KEYWORD with clear mutual-exclusivity intent (comment present) as per PR.'
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "class Feature\\(", "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/{{FOLDER_PATH}}" ]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "class Feature\\(", "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black" ]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "ASYNC_IS_VALID_IDENTIFIER|ASYNC_IS_RESERVED_KEYWORD",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black"
]
[ "rg", "--no-heading", "--line-number", "--ignore-file", ".rgignore", "ASYNC_IS_VALID_IDENTIFIER",
  "/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black"
]
Calling tool: grepTool
class Feature\(
Grep command failed with exit code 2: rg: .rgignore: No such file or directory (os error 2)
rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
class Feature\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:132:class Feature(Enum):

Calling tool: grepTool
ASYNC_IS_VALID_IDENTIFIER|ASYNC_IS_RESERVED_KEYWORD
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: grepTool
ASYNC_IS_VALID_IDENTIFIER
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: In black.py, the Feature enum lacks ASYNC_IS_VALID_IDENTIFIER and ASYNC_IS_RESERVED_KEYWORD and there is no mutual-exclusivity comment. Grep found no occurrences of these symbols anywhere, and reading the Feature enum section confirms only existing features (UNICODE_LITERALS, F_STRINGS, etc.) are present without the async-related entries.


Validating todo item 1 of 20
description: 'Verify Feature enum includes ASYNC_IS_VALID_IDENTIFIER and ASYNC_IS_RESERVED_KEYWORD with clear mutual-exclusivity intent (comment present) as per PR.'

Calling tool: grepTool
class Feature\(
Grep command failed with exit code 2: rg: .rgignore: No such file or directory (os error 2)
rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
class Feature\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py:132:class Feature(Enum):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py:132:class Feature(Enum):

Calling tool: grepTool
ASYNC_IS_VALID_IDENTIFIER|ASYNC_IS_RESERVED_KEYWORD
No files found. Call grepTool again with a more generic pattern.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/env/src/black/black.py
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-6/bad/black/black.py.original
120:    PY35 = 5
121:    PY36 = 6
122:    PY37 = 7
123:    PY38 = 8
124:
125:    def is_python2(self) -> bool:
126:        return self is TargetVersion.PY27
127:
128:
129:PY36_VERSIONS = {TargetVersion.PY36, TargetVersion.PY37, TargetVersion.PY38}
130:
131:
132:class Feature(Enum):
133:    # All string literals are unicode
134:    UNICODE_LITERALS = 1
135:    F_STRINGS = 2
136:    NUMERIC_UNDERSCORES = 3
137:    TRAILING_COMMA_IN_CALL = 4
138:    TRAILING_COMMA_IN_DEF = 5
139:
140:
141:VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
142:    TargetVersion.PY27: set(),
143:    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
144:    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
145:    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
146:    TargetVersion.PY36: {
147:        Feature.UNICODE_LITERALS,
148:        Feature.F_STRINGS,
149:        Feature.NUMERIC_UNDERSCORES,
150:        Feature.TRAILING_COMMA_IN_CALL,
151:        Feature.TRAILING_COMMA_IN_DEF,
152:    },
153:    TargetVersion.PY37: {
154:        Feature.UNICODE_LITERALS,
155:        Feature.F_STRINGS,
156:        Feature.NUMERIC_UNDERSCORES,
157:        Feature.TRAILING_COMMA_IN_CALL,
158:        Feature.TRAILING_COMMA_IN_DEF,
159:    },
160:    TargetVersion.PY38: {
161:        Feature.UNICODE_LITERALS,
162:        Feature.F_STRINGS,
163:        Feature.NUMERIC_UNDERSCORES,
164:        Feature.TRAILING_COMMA_IN_CALL,
165:        Feature.TRAILING_COMMA_IN_DEF,
166:    },
167:}
168:
169:
170:@dataclass
171:class FileMode:
172:    target_versions: Set[TargetVersion] = Factory(set)
173:    line_length: int = DEFAULT_LINE_LENGTH
174:    string_normalization: bool = True
175:    is_pyi: bool = False
176:
177:    def get_cache_key(self) -> str:
178:        if self.target_versions:
179:            version_str = ",".join(
180:                str(version.value)
181:                for version in sorted(self.target_versions, key=lambda v: v.value)
182:            )
183:        else:
184:            version_str = "-"
185:        parts = [
186:            version_str,
187:            str(self.line_length),
188:            str(int(self.string_normalization)),
189:            str(int(self.is_pyi)),
190:        ]
191:        return ".".join(parts)
192:
193:
194:def supports_feature(target_versions: Set[TargetVersion], feature: Feature) -> bool:
195:    return all(feature in VERSION_TO_FEATURES[version] for version in target_versions)
196:
197:
198:def read_pyproject_toml(
199:    ctx: click.Context, param: click.Parameter, value: Union[str, int, bool, None]
200:) -> Optional[str]:
201:    """Inject Black configuration from "pyproject.toml" into defaults in `ctx`.
202:
203:    Returns the path to a successfully found and read configuration file, None
204:    otherwise.
205:    """
206:    assert not isinstance(value, (int, bool)), "Invalid parameter type passed"
207:    if not value:
208:        root = find_project_root(ctx.params.get("src", ()))
209:        path = root / "pyproject.toml"
210:        if path.is_file():
211:            value = str(path)
212:        else:
213:            return None
214:
215:    try:
216:        pyproject_toml = toml.load(value)
217:        config = pyproject_toml.get("tool", {}).get("black", {})
218:    except (toml.TomlDecodeError, OSError) as e:
219:        raise click.FileError(

Calling tool: grepTool
ASYNC_IS_VALID_IDENTIFIER
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: In black.py, the Feature enum lacks ASYNC_IS_VALID_IDENTIFIER and ASYNC_IS_RESERVED_KEYWORD and there is no mutual-exclusivity comment. Grep found no occurrences of these symbols anywhere, and reading the Feature enum section confirms only existing features (UNICODE_LITERALS, F_STRINGS, etc.) are present without the async-related entries.


=== PHASE 2 COMPLETE ===

