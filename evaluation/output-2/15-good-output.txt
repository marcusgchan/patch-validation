=== PHASE 1: ANALYSIS ===

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."

Calling tool: grepTool
fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:405:        source, expected = read_data("fmtonoff2")

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)

Calling tool: globTool
**/tests/data/fmtonoff2.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
FMT_ON|FMT_OFF
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2450:        return
2451:
2452:    elif value[:3] == "'''":
2453:        orig_quote = "'''"
2454:        new_quote = '"""'
2455:    elif value[0] == '"':
2456:        orig_quote = '"'
2457:        new_quote = "'"
2458:    else:
2459:        orig_quote = "'"
2460:        new_quote = '"'
2461:    first_quote_pos = leaf.value.find(orig_quote)
2462:    if first_quote_pos == -1:
2463:        return  # There's an internal error
2464:
2465:    prefix = leaf.value[:first_quote_pos]
2466:    unescaped_new_quote = re.compile(rf"(([^\\]|^)(\\\\)*){new_quote}")
2467:    escaped_new_quote = re.compile(rf"([^\\]|^)\\((?:\\\\)*){new_quote}")
2468:    escaped_orig_quote = re.compile(rf"([^\\]|^)\\((?:\\\\)*){orig_quote}")
2469:    body = leaf.value[first_quote_pos + len(orig_quote) : -len(orig_quote)]
2470:    if "r" in prefix.casefold():
2471:        if unescaped_new_quote.search(body):
2472:            # There's at least one unescaped new_quote in this raw string
2473:            # so converting is impossible
2474:            return
2475:
2476:        # Do not introduce or remove backslashes in raw strings
2477:        new_body = body
2478:    else:
2479:        # remove unnecessary escapes
2480:        new_body = sub_twice(escaped_new_quote, rf"\1\2{new_quote}", body)
2481:        if body != new_body:
2482:            # Consider the string without unnecessary escapes as the original
2483:            body = new_body
2484:            leaf.value = f"{prefix}{orig_quote}{body}{orig_quote}"
2485:        new_body = sub_twice(escaped_orig_quote, rf"\1\2{orig_quote}", new_body)
2486:        new_body = sub_twice(unescaped_new_quote, rf"\1\\{new_quote}", new_body)
2487:    if "f" in prefix.casefold():
2488:        matches = re.findall(r"[^{]\{(.*?)\}[^}]", new_body)
2489:        for m in matches:
2490:            if "\\" in str(m):
2491:                # Do not introduce backslashes in interpolated expressions
2492:                return
2493:    if new_quote == '"""' and new_body[-1:] == '"':
2494:        # edge case:
2495:        new_body = new_body[:-1] + '\\"'
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would

Calling tool: grepTool
class LineGenerator\(
Matched content:
1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
602:    normalize_fmt_off(src_node)
2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py
1:#!/usr/bin/env python3
2:import asyncio
3:import sys
4:
5:from third_party import X, Y, Z
6:
7:from library import some_connection, \
8:                    some_decorator
9:# fmt: off
10:from third_party import (X,
11:                         Y, Z)
12:# fmt: on
13:f'trigger 3.6 mode'
14:# fmt: off
15:def func_no_args():
16:  a; b; c
17:  if True: raise RuntimeError
18:  if False: ...
19:  for i in range(10):
20:    print(i)
21:    continue
22:  exec('new-style exec', {}, {})
23:  return None
24:async def coroutine(arg, exec=False):
25: 'Single-line docstring. Multiline is harder to reformat.'
26: async with some_connection() as conn:
27:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
28: await asyncio.sleep(1)
29:@asyncio.coroutine
30:@some_decorator(
31:with_args=True,
32:many_args=[1,2,3]
33:)
34:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
35: return text[number:-1]
36:# fmt: on
37:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r''):
38: offset = attr.ib(default=attr.Factory( lambda: _r.uniform(10000, 200000)))
39: assert task._cancel_stack[:len(old_stack)] == old_stack
40:def spaces_types(a: int = 1, b: tuple = (), c: list = [], d: dict = {}, e: bool = True, f: int = -1, g: int = 1 if False else 2, h: str = "", i: str = r''): ...
41:def spaces2(result= _core.Value(None)):
42: ...
43:something = {
44:    # fmt: off
45:    key: 'value',
46:}
47:def example(session):
48:    # fmt: off
49:    result = session\
50:        .query(models.Customer.id)\
51:        .filter(models.Customer.account_id == account_id,
52:                models.Customer.email == email_address)\
53:        .order_by(models.Customer.id.asc())\
54:        .all()
55:    # fmt: on
56:def long_lines():
57:    if True:
58:        typedargslist.extend(
59:            gen_annotated_params(ast_args.kwonlyargs, ast_args.kw_defaults, parameters, implicit_default=True)
60:        )
61:        # fmt: off
62:        a = (
63:            unnecessary_bracket()
64:        )
65:        # fmt: on
66:    _type_comment_re = re.compile(
67:        r"""
68:        ^
69:        [\t ]*
70:        \#[ ]type:[ ]*
71:        (?P<type>
72:            [^#\t\n]+?
73:        )
74:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
75:                        # a trailing space which is why we need the silliness below
76:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
77:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
78:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
79:        [\t ]*
80:        (?P<nl>
81:            (?:\#[^\n]*)?
82:            \n?
83:        )
84:        $
85:        """,
86:        # fmt: off
87:        re.MULTILINE|re.VERBOSE
88:        # fmt: on
89:    )
90:def single_literal_yapf_disable():
91:    """Black does not support this."""
92:    BAZ = {
93:        (1, 2, 3, 4),
94:        (5, 6, 7, 8),
95:        (9, 10, 11, 12),
96:    }  # yapf: disable
97:cfg.rule(
98:    "Default", "address",
99:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
100:    xxxxxx="xx_xxxxx", xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
101:    xxxxxxxxx_xxxx=True, xxxxxxxx_xxxxxxxxxx=False,
102:    xxxxxx_xxxxxx=2, xxxxxx_xxxxx_xxxxxxxx=70, xxxxxx_xxxxxx_xxxxx=True,
103:    # fmt: off
104:    xxxxxxx_xxxxxxxxxxxx={
105:        "xxxxxxxx": {
106:            "xxxxxx": False,
107:            "xxxxxxx": False,
108:            "xxxx_xxxxxx": "xxxxx",
109:        },
110:        "xxxxxxxx-xxxxx": {
111:            "xxxxxx": False,
112:            "xxxxxxx": True,
113:            "xxxx_xxxxxx": "xxxxxx",
114:        },
115:    },
116:    # fmt: on
117:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5
118:)
119:# fmt: off
120:# No formatting to the end of the file
121:l=[1,2,3]
122:d={'a':1,
123:   'b':2}
124:
125:# output
126:
127:
128:#!/usr/bin/env python3
129:import asyncio
130:import sys
131:
132:from third_party import X, Y, Z
133:
134:from library import some_connection, some_decorator
135:
136:# fmt: off
137:from third_party import (X,
138:                         Y, Z)
139:# fmt: on
140:f"trigger 3.6 mode"
141:# fmt: off
142:def func_no_args():
143:  a; b; c
144:  if True: raise RuntimeError
145:  if False: ...
146:  for i in range(10):
147:    print(i)
148:    continue
149:  exec('new-style exec', {}, {})
150:  return None
151:async def coroutine(arg, exec=False):
152: 'Single-line docstring. Multiline is harder to reformat.'
153: async with some_connection() as conn:
154:     await conn.do_what_i_mean('SELECT bobby, tables FROM xkcd', timeout=2)
155: await asyncio.sleep(1)
156:@asyncio.coroutine
157:@some_decorator(
158:with_args=True,
159:many_args=[1,2,3]
160:)
161:def function_signature_stress_test(number:int,no_annotation=None,text:str='default',* ,debug:bool=False,**kwargs) -> str:
162: return text[number:-1]
163:# fmt: on
164:def spaces(a=1, b=(), c=[], d={}, e=True, f=-1, g=1 if False else 2, h="", i=r""):
165:    offset = attr.ib(default=attr.Factory(lambda: _r.uniform(10000, 200000)))
166:    assert task._cancel_stack[: len(old_stack)] == old_stack
167:
168:
169:def spaces_types(
170:    a: int = 1,
171:    b: tuple = (),
172:    c: list = [],
173:    d: dict = {},
174:    e: bool = True,
175:    f: int = -1,
176:    g: int = 1 if False else 2,
177:    h: str = "",
178:    i: str = r"",
179:):
180:    ...
181:
182:
183:def spaces2(result=_core.Value(None)):
184:    ...
185:
186:
187:something = {
188:    # fmt: off
189:    key: 'value',
190:}
191:
192:
193:def example(session):
194:    # fmt: off
195:    result = session\
196:        .query(models.Customer.id)\
197:        .filter(models.Customer.account_id == account_id,
198:                models.Customer.email == email_address)\
199:        .order_by(models.Customer.id.asc())\
200:        .all()
201:    # fmt: on
202:
203:
204:def long_lines():
205:    if True:
206:        typedargslist.extend(
207:            gen_annotated_params(
208:                ast_args.kwonlyargs,
209:                ast_args.kw_defaults,
210:                parameters,
211:                implicit_default=True,
212:            )
213:        )
214:        # fmt: off
215:        a = (
216:            unnecessary_bracket()
217:        )
218:        # fmt: on
219:    _type_comment_re = re.compile(
220:        r"""
221:        ^
222:        [\t ]*
223:        \#[ ]type:[ ]*
224:        (?P<type>
225:            [^#\t\n]+?
226:        )
227:        (?<!ignore)     # note: this will force the non-greedy + in <type> to match
228:                        # a trailing space which is why we need the silliness below
229:        (?<!ignore[ ]{1})(?<!ignore[ ]{2})(?<!ignore[ ]{3})(?<!ignore[ ]{4})
230:        (?<!ignore[ ]{5})(?<!ignore[ ]{6})(?<!ignore[ ]{7})(?<!ignore[ ]{8})
231:        (?<!ignore[ ]{9})(?<!ignore[ ]{10})
232:        [\t ]*
233:        (?P<nl>
234:            (?:\#[^\n]*)?
235:            \n?
236:        )
237:        $
238:        """,
239:        # fmt: off
240:        re.MULTILINE|re.VERBOSE
241:        # fmt: on
242:    )
243:
244:
245:def single_literal_yapf_disable():
246:    """Black does not support this."""
247:    BAZ = {(1, 2, 3, 4), (5, 6, 7, 8), (9, 10, 11, 12)}  # yapf: disable
248:
249:
250:cfg.rule(
251:    "Default",
252:    "address",
253:    xxxx_xxxx=["xxx-xxxxxx-xxxxxxxxxx"],
254:    xxxxxx="xx_xxxxx",
255:    xxxxxxx="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
256:    xxxxxxxxx_xxxx=True,
257:    xxxxxxxx_xxxxxxxxxx=False,
258:    xxxxxx_xxxxxx=2,
259:    xxxxxx_xxxxx_xxxxxxxx=70,
260:    xxxxxx_xxxxxx_xxxxx=True,
261:    # fmt: off
262:    xxxxxxx_xxxxxxxxxxxx={
263:        "xxxxxxxx": {
264:            "xxxxxx": False,
265:            "xxxxxxx": False,
266:            "xxxx_xxxxxx": "xxxxx",
267:        },
268:        "xxxxxxxx-xxxxx": {
269:            "xxxxxx": False,
270:            "xxxxxxx": True,
271:            "xxxx_xxxxxx": "xxxxxx",
272:        },
273:    },
274:    # fmt: on
275:    xxxxxxxxxx_xxxxxxxxxxx_xxxxxxx_xxxxxxxxx=5,
276:)
277:# fmt: off
278:# No formatting to the end of the file
279:l=[1,2,3]
280:d={'a':1,
281:   'b':2}

Calling tool: grepTool
class EmptyLineTracker
Matched content:
1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
993:class Line:
1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1126:            if leaf.type == STANDALONE_COMMENT:
1196:            comment.type == STANDALONE_COMMENT
1207:            comment.type = STANDALONE_COMMENT
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
2021:            comment_type = STANDALONE_COMMENT
2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2574:                if comment.type != STANDALONE_COMMENT:
2601:                        STANDALONE_COMMENT,
2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
720:
721:            self.tree_depth -= 1
722:            out(f"{indent}/{_type}", fg="yellow", bold=False)
723:        else:
724:            _type = token.tok_name.get(node.type, str(node.type))
725:            out(f"{indent}{_type}", fg="blue", nl=False)
726:            if node.prefix:
727:                # We don't have to handle prefixes for `Node` objects since
728:                # that delegates to the first child anyway.
729:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:

Calling tool: grepTool
UnformattedLines|FormatOn|FormatOff|FormatError
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
\bType\[|\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: createTodo
Todo List Created
Todo List (19 items):
- [ ] Verify that format_str calls normalize_fmt_off(src_node) before any LineGenerator processing, ensuring fmt: off/on regions are converted in a separate preprocessing pass. (ID: todo-1)
- [ ] Confirm generate_comments no longer contains logic to raise or handle FormatOn/FormatOff exceptions and only yields Leaf objects for comments. (ID: todo-2)
- [ ] Ensure that the removed classes/exceptions (FormatError, FormatOn, FormatOff, UnformattedLines) have no remaining references anywhere in black.py (e.g., in LineGenerator or elsewhere). (ID: todo-3)
- [ ] Check that LineGenerator no longer supports UnformattedLines: method line(...) no longer takes a 'type' parameter and all call sites reflect this change (no 'type=UnformattedLines' usage). (ID: todo-4)
- [ ] Validate that LineGenerator.visit_STANDALONE_COMMENT yields a new line before emitting a standalone comment when not inside brackets, and then emits the comment, so standalone comments are truly on their own line. (ID: todo-5)
- [ ] Verify split_line returns the line unchanged when line.is_comment is True, preventing any splitting/rewrapping of fmt-off content now encapsulated as a standalone comment. (ID: todo-6)
- [ ] Confirm ALWAYS_NO_SPACE includes STANDALONE_COMMENT, ensuring no extra spaces are added before standalone comment leaves. (ID: todo-7)
- [ ] Validate normalize_invisible_parens(node) skips processing when the node prefix contains an FMT_OFF comment (checks for pc.value in FMT_OFF early), so parentheses aren't altered within fmt-off regions. (ID: todo-8)
- [ ] Confirm FMT_OFF and FMT_ON sets include the variants ('# fmt: off/on' and '# fmt:off/on' and '# yapf: disable/enable') as intended by the PR. (ID: todo-9)
- [ ] Verify normalize_fmt_off iterates until no more pairs are found (while try_again: convert_one_fmt_off_pair(...)), ensuring all fmt-off/on pairs in the file are processed. (ID: todo-10)
- [ ] Review convert_one_fmt_off_pair: it should only convert when the FMT_OFF comment is standalone or 'standalone in disguise' (previous leaf is None or WHITESPACE). If the comment is an inline trailing comment (e.g., '# yapf: disable' at end of a code line), it must be ignored (continue), matching test expectations. (ID: todo-11)
- [ ] Validate convert_one_fmt_off_pair constructs the STANDALONE_COMMENT leaf with value 'FMT_OFF + newline + ignored content until FMT_ON' and trims a trailing newline if present (hidden_value.endswith('\n')), preserving original content exactly. (ID: todo-12)
- [ ] Check prefix handling in convert_one_fmt_off_pair: first.prefix is trimmed with prefix[comment.consumed:], and the inserted STANDALONE_COMMENT leaf uses prefix[:previous_consumed] + '\n' * comment.newlines, ensuring surrounding newlines/indentation are preserved and no extra blank lines are introduced between functions (as per issue #335). (ID: todo-13)
- [ ] Verify generate_ignored_nodes starts from container_of(leaf) and yields consecutive siblings until it encounters FMT_ON in a container prefix or reaches the end of the current block; confirm the loop condition stops at token.ENDMARKER and does not cross statement boundaries improperly. (ID: todo-14)
- [ ] Check container_of(leaf) ascends to the topmost container with the same prefix but stops when encountering syms.file_input or nodes surrounded by brackets (SURROUNDED_BY_BRACKETS), so fmt-off conversion is limited to the correct block scope (including inside bracket pairs). (ID: todo-15)
- [ ] Ensure Line.append_comment converts a leading comment to STANDALONE_COMMENT and resets prefix appropriately, and for comments within open brackets it returns False so such comments are handled as normal leaves, consistent with the new STANDALONE_COMMENT handling. (ID: todo-16)
- [ ] Confirm EmptyLineTracker no longer special-cases UnformattedLines and that its logic uses current_line.is_comment to avoid injecting extra blank lines before defs/classes when the previous line is a standalone comment (fmt-off content). (ID: todo-17)
- [ ] Validate that tests/data/fmtonoff2.py has no '# output' section and therefore read_data returns the same content for source and expected, aligning with the intent that formatting should be a no-op for the fmt-off region. (ID: todo-18)
- [ ] Check that fmtonoff2 case (functions and list of tuples inside fmt-off block) will be preserved: after preprocessing, all that content is embedded in a single STANDALONE_COMMENT leaf so LineGenerator and split_line won't reformat or insert extra empty lines. (ID: todo-19)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 19
description: 'Verify that format_str calls normalize_fmt_off(src_node) before any LineGenerator processing, ensuring fmt: off/on regions are converted in a separate preprocessing pass.'
Calling tool: grepTool
def format_str\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:589:def format_str(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, format_str parses the source (line 596) and immediately calls normalize_fmt_off(src_node) (line 602) before constructing LineGenerator (line 603) and visiting lines (line 611). This ensures fmt: off/on regions are preprocessed prior to any LineGenerator processing.


Todo item 1 of 19 is correct
description: 'Verify that format_str calls normalize_fmt_off(src_node) before any LineGenerator processing, ensuring fmt: off/on regions are converted in a separate preprocessing pass.'
Validating todo item 2 of 19
description: 'Confirm generate_comments no longer contains logic to raise or handle FormatOn/FormatOff exceptions and only yields Leaf objects for comments.'
Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: grepTool
class Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FormatOn|FormatOff|FormatError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched and inspected generate_comments in black.py. It now simply iterates list_comments and yields Leaf objects, with no raising or handling of FormatOn/FormatOff. The exception classes are removed from code; only docs reference them. Thus the function meets the requirement.


Todo item 2 of 19 is correct
description: 'Confirm generate_comments no longer contains logic to raise or handle FormatOn/FormatOff exceptions and only yields Leaf objects for comments.'
Validating todo item 3 of 19
description: 'Ensure that the removed classes/exceptions (FormatError, FormatOn, FormatOff, UnformattedLines) have no remaining references anywhere in black.py (e.g., in LineGenerator or elsewhere).'
Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py

Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def generate_comments\(
Matched content:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: grepTool
class LineGenerator\(
Matched content:
1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:

Calling tool: grepTool
visit_unformatted\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched black.py for references to FormatError, FormatOn, FormatOff, and UnformattedLines and found none. Also inspected LineGenerator and generate_comments; prior try/except and UnformattedLines usage were removed per diff. Only remaining mentions are in docs, not in black.py.


Todo item 3 of 19 is correct
description: 'Ensure that the removed classes/exceptions (FormatError, FormatOn, FormatOff, UnformattedLines) have no remaining references anywhere in black.py (e.g., in LineGenerator or elsewhere).'
Validating todo item 4 of 19
description: 'Check that LineGenerator no longer supports UnformattedLines: method line(...) no longer takes a 'type' parameter and all call sites reflect this change (no 'type=UnformattedLines' usage).'
Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1406:    def line(self, indent: int = 0) -> Iterator[Line]:

Calling tool: grepTool
line\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_unformatted\(|FormatOff|FormatOn|fmt: off|FMT_OFF|FMT_ON
Matched content:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2570:            if comment.value in FMT_OFF:
2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription

Calling tool: grepTool
self\.line\(
Matched content:
1433:                    yield from self.line()
1437:                    yield from self.line()
1440:                    yield from self.line()
1453:        yield from self.line(+1)
1461:        yield from self.line()
1468:        yield from self.line(-1)
1487:                yield from self.line()
1505:                yield from self.line(+1)
1507:                yield from self.line(-1)
1511:                yield from self.line()
1516:        yield from self.line()
1532:            yield from self.line()
1537:        yield from self.line()
1542:        yield from self.line()
1546:            yield from self.line()

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)

Calling tool: grepTool
\bline\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class LineGenerator\([\s\S]*?\n\s*def visit\(
Grep command failed with exit code 2: rg: the literal "\n" is not allowed in a regex

Consider enabling multiline mode with the --multiline flag (or -U for short).
When multiline mode is enabled, new line characters can be matched.


Calling tool: grepTool
def visit\(
Matched content:
685:    def visit(self, node: LN) -> Iterator[T]:

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py that LineGenerator.line signature is now def line(self, indent: int = 0) with no type parameter, UnformattedLines class is removed, and there are no call sites passing type=UnformattedLines (or any type=) to self.line(). Grep confirms no remaining UnformattedLines references in code and all self.line(...) calls only pass indent.


Todo item 4 of 19 is correct
description: 'Check that LineGenerator no longer supports UnformattedLines: method line(...) no longer takes a 'type' parameter and all call sites reflect this change (no 'type=UnformattedLines' usage).'
Validating todo item 5 of 19
description: 'Validate that LineGenerator.visit_STANDALONE_COMMENT yields a new line before emitting a standalone comment when not inside brackets, and then emits the comment, so standalone comments are truly on their own line.'
Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]

Calling tool: grepTool
is_comment
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2064:    if line.is_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body

Calling tool: grepTool
split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):
2158:        if result:
2159:            yield result
2160:
2161:
2162:def right_hand_split(
2163:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2164:) -> Iterator[Line]:
2165:    """Split line into many lines, starting with the last matching bracket pair.
2166:
2167:    If the split was by optional parentheses, attempt splitting without them, too.
2168:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2169:    this split.

Calling tool: grepTool
class Line\:
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")

Calling tool: grepTool
def __str__\(self\).*Line
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def __str__\(self\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pytree.py:201:        def __str__(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1262:    def __str__(self) -> str:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3072:    def __str__(self) -> str:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:

Calling tool: grepTool
def visit_.*\(self, leaf: Leaf\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Confirmed in black.py that LineGenerator.visit_STANDALONE_COMMENT checks for no open brackets via bracket_tracker.any_open_brackets(), yields a new line with self.line(), then processes the comment via visit_default(leaf). This ensures standalone comments start on a fresh line when not inside brackets.


Todo item 5 of 19 is correct
description: 'Validate that LineGenerator.visit_STANDALONE_COMMENT yields a new line before emitting a standalone comment when not inside brackets, and then emits the comment, so standalone comments are truly on their own line.'
Validating todo item 6 of 19
description: 'Verify split_line returns the line unchanged when line.is_comment is True, preventing any splitting/rewrapping of fmt-off content now encapsulated as a standalone comment.'
Calling tool: grepTool
def split_line\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
940:        priority = priority or self.max_delimiter_priority()
941:        return sum(1 for p in self.delimiters.values() if p == priority)
942:
943:    def maybe_increment_for_loop_variable(self, leaf: Leaf) -> bool:
944:        """In a for loop, or comprehension, the variables are often unpacks.
945:
946:        To avoid splitting on the comma in this situation, increase the depth of
947:        tokens between `for` and `in`.
948:        """
949:        if leaf.type == token.NAME and leaf.value == "for":
950:            self.depth += 1
951:            self._for_loop_variable += 1
952:            return True
953:
954:        return False
955:
956:    def maybe_decrement_after_for_loop_variable(self, leaf: Leaf) -> bool:
957:        """See `maybe_increment_for_loop_variable` above for explanation."""
958:        if self._for_loop_variable and leaf.type == token.NAME and leaf.value == "in":
959:            self.depth -= 1
960:            self._for_loop_variable -= 1
961:            return True
962:
963:        return False
964:
965:    def maybe_increment_lambda_arguments(self, leaf: Leaf) -> bool:
966:        """In a lambda expression, there might be more than one argument.
967:
968:        To avoid splitting on the comma in this situation, increase the depth of
969:        tokens between `lambda` and `:`.
970:        """
971:        if leaf.type == token.NAME and leaf.value == "lambda":
972:            self.depth += 1
973:            self._lambda_arguments += 1
974:            return True
975:
976:        return False
977:
978:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
979:        """See `maybe_increment_lambda_arguments` above for explanation."""
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s split_line (around line 2051), the first check is `if line.is_comment: yield line; return`, which ensures comment-only lines are returned unchanged. The `Line.is_comment` property (line ~1049) correctly identifies standalone comment lines, matching the new fmt-off encapsulation behavior.


Todo item 6 of 19 is correct
description: 'Verify split_line returns the line unchanged when line.is_comment is True, preventing any splitting/rewrapping of fmt-off content now encapsulated as a standalone comment.'
Validating todo item 7 of 19
description: 'Confirm ALWAYS_NO_SPACE includes STANDALONE_COMMENT, ensuring no extra spaces are added before standalone comment leaves.'
Calling tool: grepTool
ALWAYS_NO_SPACE
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1593:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:14:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:67:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:111:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:162:    if t in ALWAYS_NO_SPACE:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:

Calling tool: grepTool
def whitespace\(|whitespace\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1022:            leaf.prefix += whitespace(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.py:180:    def add_whitespace(self, start):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.py:193:            self.add_whitespace(start)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.pyi:23:    def add_whitespace(self, start: _Coord) -> None: ...

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, ALWAYS_NO_SPACE is defined as CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} (line ~1578). The whitespace() function checks `if t in ALWAYS_NO_SPACE: return ""` (line ~1593), ensuring no extra spaces are added before STANDALONE_COMMENT leaves.


Todo item 7 of 19 is correct
description: 'Confirm ALWAYS_NO_SPACE includes STANDALONE_COMMENT, ensuring no extra spaces are added before standalone comment leaves.'
Validating todo item 8 of 19
description: 'Validate normalize_invisible_parens(node) skips processing when the node prefix contains an FMT_OFF comment (checks for pc.value in FMT_OFF early), so parentheses aren't altered within fmt-off regions.'
Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2470:    if "r" in prefix.casefold():
2471:        if unescaped_new_quote.search(body):
2472:            # There's at least one unescaped new_quote in this raw string
2473:            # so converting is impossible
2474:            return
2475:
2476:        # Do not introduce or remove backslashes in raw strings
2477:        new_body = body
2478:    else:
2479:        # remove unnecessary escapes
2480:        new_body = sub_twice(escaped_new_quote, rf"\1\2{new_quote}", body)
2481:        if body != new_body:
2482:            # Consider the string without unnecessary escapes as the original
2483:            body = new_body
2484:            leaf.value = f"{prefix}{orig_quote}{body}{orig_quote}"
2485:        new_body = sub_twice(escaped_orig_quote, rf"\1\2{orig_quote}", new_body)
2486:        new_body = sub_twice(unescaped_new_quote, rf"\1\\{new_quote}", new_body)
2487:    if "f" in prefix.casefold():
2488:        matches = re.findall(r"[^{]\{(.*?)\}[^}]", new_body)
2489:        for m in matches:
2490:            if "\\" in str(m):
2491:                # Do not introduce backslashes in interpolated expressions
2492:                return
2493:    if new_quote == '"""' and new_body[-1:] == '"':
2494:        # edge case:
2495:        new_body = new_body[:-1] + '\\"'
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).

Calling tool: grepTool
FMT_OFF
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2570:            if comment.value in FMT_OFF:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_invisible_parens() checks list_comments(node.prefix) and returns early if any pc.value is in FMT_OFF (lines ~2516-2519). This ensures no parentheses changes occur within fmt-off regions.


Todo item 8 of 19 is correct
description: 'Validate normalize_invisible_parens(node) skips processing when the node prefix contains an FMT_OFF comment (checks for pc.value in FMT_OFF early), so parentheses aren't altered within fmt-off regions.'
Validating todo item 9 of 19
description: 'Confirm FMT_OFF and FMT_ON sets include the variants ('# fmt: off/on' and '# fmt:off/on' and '# yapf: disable/enable') as intended by the PR.'
Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, FMT_OFF and FMT_ON are explicitly defined as {"# fmt: off", "# fmt:off", "# yapf: disable"} and {"# fmt: on", "# fmt:on", "# yapf: enable"} respectively (lines ~1967-1968). These match the intended variants and are used in the new logic paths.


Todo item 9 of 19 is correct
description: 'Confirm FMT_OFF and FMT_ON sets include the variants ('# fmt: off/on' and '# fmt:off/on' and '# yapf: disable/enable') as intended by the PR.'
Validating todo item 10 of 19
description: 'Verify normalize_fmt_off iterates until no more pairs are found (while try_again: convert_one_fmt_off_pair(...)), ensuring all fmt-off/on pairs in the file are processed.'
Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: normalize_fmt_off uses a while-loop that repeatedly calls convert_one_fmt_off_pair(node) until it returns False. convert_one_fmt_off_pair scans for a single fmt-off/on pair and returns True upon converting one, otherwise False. This ensures all pairs in the file are processed.


Todo item 10 of 19 is correct
description: 'Verify normalize_fmt_off iterates until no more pairs are found (while try_again: convert_one_fmt_off_pair(...)), ensuring all fmt-off/on pairs in the file are processed.'
Validating todo item 11 of 19
description: 'Review convert_one_fmt_off_pair: it should only convert when the FMT_OFF comment is standalone or 'standalone in disguise' (previous leaf is None or WHITESPACE). If the comment is an inline trailing comment (e.g., '# yapf: disable' at end of a code line), it must be ignored (continue), matching test expectations.'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1788:                return NO
1789:
1790:        elif t in {token.NAME, token.NUMBER, token.STRING}:
1791:            return NO
1792:
1793:    elif p.type == syms.import_from:
1794:        if t == token.DOT:
1795:            if prev and prev.type == token.DOT:
1796:                return NO
1797:
1798:        elif t == token.NAME:
1799:            if v == "import":
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:

Calling tool: grepTool
WHITESPACE\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
720:
721:            self.tree_depth -= 1
722:            out(f"{indent}/{_type}", fg="yellow", bold=False)
723:        else:
724:            _type = token.tok_name.get(node.type, str(node.type))
725:            out(f"{indent}{_type}", fg="blue", nl=False)
726:            if node.prefix:
727:                # We don't have to handle prefixes for `Node` objects since
728:                # that delegates to the first child anyway.
729:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py
360:        self.assertFormatEqual(expected, actual)
361:        black.assert_equivalent(source, actual)
362:        black.assert_stable(source, actual, line_length=ll)
363:
364:    @patch("black.dump_to_file", dump_to_stderr)
365:    def test_string_prefixes(self) -> None:
366:        source, expected = read_data("string_prefixes")
367:        actual = fs(source)
368:        self.assertFormatEqual(expected, actual)
369:        black.assert_equivalent(source, actual)
370:        black.assert_stable(source, actual, line_length=ll)
371:
372:    @patch("black.dump_to_file", dump_to_stderr)
373:    def test_python2(self) -> None:
374:        source, expected = read_data("python2")
375:        actual = fs(source)
376:        self.assertFormatEqual(expected, actual)
377:        # black.assert_equivalent(source, actual)
378:        black.assert_stable(source, actual, line_length=ll)
379:
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(

Calling tool: globTool
**/tests/data/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
fmt:\s*off
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:140:blocks that start with `# fmt: off` and end with `# fmt: on`.  It also
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:827:* `# fmt: off` and `# fmt: on` are now much more dependable:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:903:* fixed optional parentheses being removed within `# fmt: off` sections (#224)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:1066:* `# fmt: off` and `# fmt: on` are implemented (#5)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py:6:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:9:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:14:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:44:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:48:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:61:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:86:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:103:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:119:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:136:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:141:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:188:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:194:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:214:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:239:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:261:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:277:# fmt: off

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2476:        # Do not introduce or remove backslashes in raw strings
2477:        new_body = body
2478:    else:
2479:        # remove unnecessary escapes
2480:        new_body = sub_twice(escaped_new_quote, rf"\1\2{new_quote}", body)
2481:        if body != new_body:
2482:            # Consider the string without unnecessary escapes as the original
2483:            body = new_body
2484:            leaf.value = f"{prefix}{orig_quote}{body}{orig_quote}"
2485:        new_body = sub_twice(escaped_orig_quote, rf"\1\2{orig_quote}", new_body)
2486:        new_body = sub_twice(unescaped_new_quote, rf"\1\\{new_quote}", new_body)
2487:    if "f" in prefix.casefold():
2488:        matches = re.findall(r"[^{]\{(.*?)\}[^}]", new_body)
2489:        for m in matches:
2490:            if "\\" in str(m):
2491:                # Do not introduce backslashes in interpolated expressions
2492:                return
2493:    if new_quote == '"""' and new_body[-1:] == '"':
2494:        # edge case:
2495:        new_body = new_body[:-1] + '\\"'
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair (lines ~2562-2606) explicitly checks that a FMT_OFF comment is either a STANDALONE_COMMENT or ‘standalone in disguise’ by verifying the preceding leaf is None or WHITESPACE. If it’s an inline trailing comment (prev exists and is not WHITESPACE), it continues (ignores), matching test expectations (e.g., '# yapf: disable'). normalize_fmt_off invokes this function, ensuring the behavior is applied.


Todo item 11 of 19 is correct
description: 'Review convert_one_fmt_off_pair: it should only convert when the FMT_OFF comment is standalone or 'standalone in disguise' (previous leaf is None or WHITESPACE). If the comment is an inline trailing comment (e.g., '# yapf: disable' at end of a code line), it must be ignored (continue), matching test expectations.'
Validating todo item 12 of 19
description: 'Validate convert_one_fmt_off_pair constructs the STANDALONE_COMMENT leaf with value 'FMT_OFF + newline + ignored content until FMT_ON' and trims a trailing newline if present (hidden_value.endswith('\n')), preserving original content exactly.'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: convert_one_fmt_off_pair builds a STANDALONE_COMMENT leaf whose value is comment.value + "\n" + the concatenated string of ignored nodes, and trims a trailing newline if present. The code also adjusts prefixes to preserve original content, matching the requirement.


Todo item 12 of 19 is correct
description: 'Validate convert_one_fmt_off_pair constructs the STANDALONE_COMMENT leaf with value 'FMT_OFF + newline + ignored content until FMT_ON' and trims a trailing newline if present (hidden_value.endswith('\n')), preserving original content exactly.'
Validating todo item 13 of 19
description: 'Check prefix handling in convert_one_fmt_off_pair: first.prefix is trimmed with prefix[comment.consumed:], and the inserted STANDALONE_COMMENT leaf uses prefix[:previous_consumed] + '\n' * comment.newlines, ensuring surrounding newlines/indentation are preserved and no extra blank lines are introduced between functions (as per issue #335).'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s convert_one_fmt_off_pair, first.prefix is set to prefix[comment.consumed:] and the inserted STANDALONE_COMMENT uses prefix[:previous_consumed] + "\n" * comment.newlines (lines ~2582–2604). This preserves surrounding newlines/indentation, preventing extra blank lines between functions as required by issue #335.


Todo item 13 of 19 is correct
description: 'Check prefix handling in convert_one_fmt_off_pair: first.prefix is trimmed with prefix[comment.consumed:], and the inserted STANDALONE_COMMENT leaf uses prefix[:previous_consumed] + '\n' * comment.newlines, ensuring surrounding newlines/indentation are preserved and no extra blank lines are introduced between functions (as per issue #335).'
Validating todo item 14 of 19
description: 'Verify generate_ignored_nodes starts from container_of(leaf) and yields consecutive siblings until it encounters FMT_ON in a container prefix or reaches the end of the current block; confirm the loop condition stops at token.ENDMARKER and does not cross statement boundaries improperly.'
Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: grepTool
FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: grepTool
SURROUNDED_BY_BRACKETS
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1855:        if parent.type in SURROUNDED_BY_BRACKETS:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `generate_ignored_nodes` starts from `container_of(leaf)` (black.py:2618) and iterates consecutive siblings via `container = container.next_sibling` (lines 2624-2626). It stops when encountering `FMT_ON` in the container’s prefix (lines 2620-2622) and the while-loop guards against crossing boundaries with `container is not None and container.type != token.ENDMARKER` (line 2619). Additionally, `container_of` is constrained to not cross statement boundaries (breaks on file_input and bracketed parents, lines 1852-1856).


Todo item 14 of 19 is correct
description: 'Verify generate_ignored_nodes starts from container_of(leaf) and yields consecutive siblings until it encounters FMT_ON in a container prefix or reaches the end of the current block; confirm the loop condition stops at token.ENDMARKER and does not cross statement boundaries improperly.'
Validating todo item 15 of 19
description: 'Check container_of(leaf) ascends to the topmost container with the same prefix but stops when encountering syms.file_input or nodes surrounded by brackets (SURROUNDED_BY_BRACKETS), so fmt-off conversion is limited to the correct block scope (including inside bracket pairs).'
Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent

Calling tool: grepTool
SURROUNDED_BY_BRACKETS
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1855:        if parent.type in SURROUNDED_BY_BRACKETS:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,
820:    syms.xor_expr,
821:    syms.and_expr,
822:    syms.shift_expr,
823:    syms.arith_expr,
824:    syms.trailer,
825:    syms.term,
826:    syms.power,
827:}
828:ASSIGNMENTS = {
829:    "=",
830:    "+=",
831:    "-=",
832:    "*=",
833:    "@=",
834:    "/=",
835:    "%=",
836:    "&=",
837:    "|=",
838:    "^=",
839:    "<<=",

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s container_of(), the loop ascends parents while the first child’s prefix matches the leaf’s prefix, but explicitly breaks when encountering syms.file_input or any parent in SURROUNDED_BY_BRACKETS (lines 1849–1856). This ensures fmt-off conversion (used by generate_ignored_nodes) is limited to the correct block scope, including inside bracket pairs.


Todo item 15 of 19 is correct
description: 'Check container_of(leaf) ascends to the topmost container with the same prefix but stops when encountering syms.file_input or nodes surrounded by brackets (SURROUNDED_BY_BRACKETS), so fmt-off conversion is limited to the correct block scope (including inside bracket pairs).'
Validating todo item 16 of 19
description: 'Ensure Line.append_comment converts a leading comment to STANDALONE_COMMENT and resets prefix appropriately, and for comments within open brackets it returns False so such comments are handled as normal leaves, consistent with the new STANDALONE_COMMENT handling.'
Calling tool: grepTool
class Line\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("

Calling tool: grepTool
def append_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1193:    def append_comment(self, comment: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: grepTool
def __str__\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pytree.py:201:        def __str__(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1262:    def __str__(self) -> str:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3072:    def __str__(self) -> str:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())

Calling tool: grepTool
\.comments\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1212:            self.comments.append((after, comment))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1220:        if not self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1231:        for index, comment_after in self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1238:        for i in range(len(self.comments)):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1239:            comment_index, comment = self.comments[i]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1241:                self.comments[i] = (comma_index - 1, comment)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1273:        for _, comment in self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1279:        return bool(self.leaves or self.comments)

Calling tool: grepTool
comments_after\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2154:            for comment_after in line.comments_after(leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2207:            for comment_after in line.comments_after(leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2339:        for comment_after in line.comments_after(leaf, index):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2385:        for comment_after in line.comments_after(leaf, index):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3281:        for comment in line.comments_after(leaf, index):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):
2158:        if result:
2159:            yield result
2160:
2161:
2162:def right_hand_split(
2163:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2164:) -> Iterator[Line]:
2165:    """Split line into many lines, starting with the last matching bracket pair.
2166:
2167:    If the split was by optional parentheses, attempt splitting without them, too.
2168:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2169:    this split.
2170:
2171:    Note: running this function modifies `bracket_depth` on the leaves of `line`.
2172:    """
2173:    head = Line(depth=line.depth)
2174:    body = Line(depth=line.depth + 1, inside_brackets=True)
2175:    tail = Line(depth=line.depth)
2176:    tail_leaves: List[Leaf] = []
2177:    body_leaves: List[Leaf] = []
2178:    head_leaves: List[Leaf] = []
2179:    current_leaves = tail_leaves
2180:    opening_bracket = None
2181:    closing_bracket = None
2182:    for leaf in reversed(line.leaves):
2183:        if current_leaves is body_leaves:
2184:            if leaf is opening_bracket:
2185:                current_leaves = head_leaves if body_leaves else tail_leaves
2186:        current_leaves.append(leaf)
2187:        if current_leaves is tail_leaves:
2188:            if leaf.type in CLOSING_BRACKETS and id(leaf) not in omit:
2189:                opening_bracket = leaf.opening_bracket
2190:                closing_bracket = leaf
2191:                current_leaves = body_leaves
2192:    tail_leaves.reverse()
2193:    body_leaves.reverse()
2194:    head_leaves.reverse()
2195:    # Since body is a new indent level, remove spurious leading whitespace.
2196:    if body_leaves:
2197:        normalize_prefix(body_leaves[0], inside_brackets=True)
2198:    if not head_leaves:
2199:        # No `head` means the split failed. Either `tail` has all content or
2200:        # the matching `opening_bracket` wasn't available on `line` anymore.
2201:        raise CannotSplit("No brackets found")
2202:
2203:    # Build the new lines.
2204:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2205:        for leaf in leaves:
2206:            result.append(leaf, preformatted=True)
2207:            for comment_after in line.comments_after(leaf):
2208:                result.append(comment_after, preformatted=True)
2209:    assert opening_bracket and closing_bracket
2210:    body.should_explode = should_explode(body, opening_bracket)
2211:    bracket_split_succeeded_or_raise(head, body, tail)
2212:    if (
2213:        # the body shouldn't be exploded
2214:        not body.should_explode
2215:        # the opening bracket is an optional paren
2216:        and opening_bracket.type == token.LPAR
2217:        and not opening_bracket.value
2218:        # the closing bracket is an optional paren
2219:        and closing_bracket.type == token.RPAR
2220:        and not closing_bracket.value
2221:        # it's not an import (optional parens are the only thing we can split on
2222:        # in this case; attempting a split without them is a waste of time)
2223:        and not line.is_import
2224:        # there are no standalone comments in the body
2225:        and not body.contains_standalone_comments(0)
2226:        # and we can actually remove the parens
2227:        and can_omit_invisible_parens(body, line_length)
2228:    ):
2229:        omit = {id(closing_bracket), *omit}
2230:        try:
2231:            yield from right_hand_split(line, line_length, py36=py36, omit=omit)
2232:            return
2233:
2234:        except CannotSplit:
2235:            if not (
2236:                can_be_split(body)
2237:                or is_line_short_enough(body, line_length=line_length)
2238:            ):
2239:                raise CannotSplit(
2240:                    "Splitting failed, body is still too long and can't be split."
2241:                )
2242:
2243:            elif head.contains_multiline_strings() or tail.contains_multiline_strings():
2244:                raise CannotSplit(
2245:                    "The current optional pair of parentheses is bound to fail to "
2246:                    "satisfy the splitting algorithm because the head or the tail "
2247:                    "contains multiline strings which by definition never fit one "
2248:                    "line."
2249:                )
2250:
2251:    ensure_visible(opening_bracket)
2252:    ensure_visible(closing_bracket)
2253:    for result in (head, body, tail):
2254:        if result:
2255:            yield result
2256:
2257:
2258:def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None:
2259:    """Raise :exc:`CannotSplit` if the last left- or right-hand split failed.
2260:
2261:    Do nothing otherwise.
2262:
2263:    A left- or right-hand split is based on a pair of brackets. Content before
2264:    (and including) the opening bracket is left on one line, content inside the
2265:    brackets is put on a separate line, and finally content starting with and
2266:    following the closing bracket is put on a separate line.
2267:
2268:    Those are called `head`, `body`, and `tail`, respectively. If the split
2269:    produced the same line (all content in `head`) or ended up with an empty `body`
2270:    and the `tail` is just the closing bracket, then it's considered failed.
2271:    """
2272:    tail_len = len(str(tail).strip())
2273:    if not body:
2274:        if tail_len == 0:
2275:            raise CannotSplit("Splitting brackets produced the same line")
2276:
2277:        elif tail_len < 3:
2278:            raise CannotSplit(
2279:                f"Splitting brackets on an empty body to save "
2280:                f"{tail_len} characters is not worth it"
2281:            )
2282:
2283:
2284:def dont_increase_indentation(split_func: SplitFunc) -> SplitFunc:
2285:    """Normalize prefix of the first leaf in every line returned by `split_func`.
2286:
2287:    This is a decorator over relevant split functions.
2288:    """
2289:
2290:    @wraps(split_func)
2291:    def split_wrapper(line: Line, py36: bool = False) -> Iterator[Line]:
2292:        for l in split_func(line, py36):
2293:            normalize_prefix(l.leaves[0], inside_brackets=True)
2294:            yield l
2295:
2296:    return split_wrapper
2297:
2298:
2299:@dont_increase_indentation
2300:def delimiter_split(line: Line, py36: bool = False) -> Iterator[Line]:
2301:    """Split according to delimiters of the highest priority.
2302:
2303:    If `py36` is True, the split will add trailing commas also in function
2304:    signatures that contain `*` and `**`.
2305:    """
2306:    try:
2307:        last_leaf = line.leaves[-1]
2308:    except IndexError:
2309:        raise CannotSplit("Line empty")
2310:
2311:    bt = line.bracket_tracker
2312:    try:
2313:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2314:    except ValueError:
2315:        raise CannotSplit("No delimiters found")
2316:
2317:    if delimiter_priority == DOT_PRIORITY:
2318:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2319:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2320:
2321:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2322:    lowest_depth = sys.maxsize
2323:    trailing_comma_safe = True
2324:
2325:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2326:        """Append `leaf` to current line or to new line if appending impossible."""
2327:        nonlocal current_line
2328:        try:
2329:            current_line.append_safe(leaf, preformatted=True)
2330:        except ValueError as ve:
2331:            yield current_line
2332:
2333:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2334:            current_line.append(leaf)
2335:
2336:    for index, leaf in enumerate(line.leaves):
2337:        yield from append_to_line(leaf)
2338:
2339:        for comment_after in line.comments_after(leaf, index):
2340:            yield from append_to_line(comment_after)
2341:
2342:        lowest_depth = min(lowest_depth, leaf.bracket_depth)
2343:        if leaf.bracket_depth == lowest_depth and is_vararg(
2344:            leaf, within=VARARGS_PARENTS
2345:        ):
2346:            trailing_comma_safe = trailing_comma_safe and py36
2347:        leaf_priority = bt.delimiters.get(id(leaf))
2348:        if leaf_priority == delimiter_priority:
2349:            yield current_line
2350:
2351:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2352:    if current_line:
2353:        if (
2354:            trailing_comma_safe
2355:            and delimiter_priority == COMMA_PRIORITY
2356:            and current_line.leaves[-1].type != token.COMMA
2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2358:        ):
2359:            current_line.append(Leaf(token.COMMA, ","))
2360:        yield current_line
2361:
2362:
2363:@dont_increase_indentation
2364:def standalone_comment_split(line: Line, py36: bool = False) -> Iterator[Line]:
2365:    """Split standalone comments from the rest of the line."""
2366:    if not line.contains_standalone_comments(0):
2367:        raise CannotSplit("Line does not have any standalone comments")
2368:
2369:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2370:
2371:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2372:        """Append `leaf` to current line or to new line if appending impossible."""
2373:        nonlocal current_line
2374:        try:
2375:            current_line.append_safe(leaf, preformatted=True)
2376:        except ValueError as ve:
2377:            yield current_line
2378:
2379:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2380:            current_line.append(leaf)
2381:
2382:    for index, leaf in enumerate(line.leaves):
2383:        yield from append_to_line(leaf)
2384:
2385:        for comment_after in line.comments_after(leaf, index):
2386:            yield from append_to_line(comment_after)
2387:
2388:    if current_line:
2389:        yield current_line
2390:
2391:
2392:def is_import(leaf: Leaf) -> bool:
2393:    """Return True if the given leaf starts an import statement."""
2394:    p = leaf.parent
2395:    t = leaf.type
2396:    v = leaf.value
2397:    return bool(
2398:        t == token.NAME
2399:        and (
2400:            (v == "import" and p and p.type == syms.import_name)
2401:            or (v == "from" and p and p.type == syms.import_from)
2402:        )
2403:    )
2404:
2405:
2406:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2407:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2408:    else.
2409:
2410:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2411:    """
2412:    if not inside_brackets:
2413:        spl = leaf.prefix.split("#")
2414:        if "\\" not in spl[0]:
2415:            nl_count = spl[-1].count("\n")
2416:            if len(spl) > 1:
2417:                nl_count -= 1
2418:            leaf.prefix = "\n" * nl_count
2419:            return
2420:
2421:    leaf.prefix = ""
2422:
2423:
2424:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2425:    """Make all string prefixes lowercase.
2426:
2427:    If remove_u_prefix is given, also removes any u prefix from the string.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: In black.py Line.append_comment (lines ~1193-1213) converts a leading comment to STANDALONE_COMMENT and clears its prefix, but it only returns False for STANDALONE_COMMENT when brackets are open. For token.COMMENT within open brackets it returns True and stores it in comments, not as a normal leaf, violating the requirement that comments within open brackets be handled as normal leaves.


Validating todo item 1 of 19
description: 'Verify that format_str calls normalize_fmt_off(src_node) before any LineGenerator processing, ensuring fmt: off/on regions are converted in a separate preprocessing pass.'

Calling tool: grepTool
def format_str\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:589:def format_str(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, format_str parses the source (line 596) and immediately calls normalize_fmt_off(src_node) (line 602) before constructing LineGenerator (line 603) and visiting lines (line 611). This ensures fmt: off/on regions are preprocessed prior to any LineGenerator processing.

Todo item 1 of 19 is correct
description: 'Verify that format_str calls normalize_fmt_off(src_node) before any LineGenerator processing, ensuring fmt: off/on regions are converted in a separate preprocessing pass.'

Validating todo item 2 of 19
description: 'Confirm generate_comments no longer contains logic to raise or handle FormatOn/FormatOff exceptions and only yields Leaf objects for comments.'

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: grepTool
class Format(On|Off|Error)
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
FormatOn|FormatOff|FormatError
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched and inspected generate_comments in black.py. It now simply iterates list_comments and yields Leaf objects, with no raising or handling of FormatOn/FormatOff. The exception classes are removed from code; only docs reference them. Thus the function meets the requirement.

Todo item 2 of 19 is correct
description: 'Confirm generate_comments no longer contains logic to raise or handle FormatOn/FormatOff exceptions and only yields Leaf objects for comments.'

Validating todo item 3 of 19
description: 'Ensure that the removed classes/exceptions (FormatError, FormatOn, FormatOff, UnformattedLines) have no remaining references anywhere in black.py (e.g., in LineGenerator or elsewhere).'

Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py

Calling tool: grepTool
\bFormatError\b|\bFormatOn\b|\bFormatOff\b|\bUnformattedLines\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def generate_comments\(
Matched content:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """

Calling tool: grepTool
class LineGenerator\(
Matched content:
1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:

Calling tool: grepTool
visit_unformatted\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched black.py for references to FormatError, FormatOn, FormatOff, and UnformattedLines and found none. Also inspected LineGenerator and generate_comments; prior try/except and UnformattedLines usage were removed per diff. Only remaining mentions are in docs, not in black.py.

Todo item 3 of 19 is correct
description: 'Ensure that the removed classes/exceptions (FormatError, FormatOn, FormatOff, UnformattedLines) have no remaining references anywhere in black.py (e.g., in LineGenerator or elsewhere).'

Validating todo item 4 of 19
description: 'Check that LineGenerator no longer supports UnformattedLines: method line(...) no longer takes a 'type' parameter and all call sites reflect this change (no 'type=UnformattedLines' usage).'

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
def line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1406:    def line(self, indent: int = 0) -> Iterator[Line]:

Calling tool: grepTool
line\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
visit_unformatted\(|FormatOff|FormatOn|fmt: off|FMT_OFF|FMT_ON
Matched content:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2570:            if comment.value in FMT_OFF:
2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription

Calling tool: grepTool
self\.line\(
Matched content:
1433:                    yield from self.line()
1437:                    yield from self.line()
1440:                    yield from self.line()
1453:        yield from self.line(+1)
1461:        yield from self.line()
1468:        yield from self.line(-1)
1487:                yield from self.line()
1505:                yield from self.line(+1)
1507:                yield from self.line(-1)
1511:                yield from self.line()
1516:        yield from self.line()
1532:            yield from self.line()
1537:        yield from self.line()
1542:        yield from self.line()
1546:            yield from self.line()

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)

Calling tool: grepTool
\bline\([^\)]*type\s*=
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class LineGenerator\([\s\S]*?\n\s*def visit\(
Grep command failed with exit code 2: rg: the literal "\n" is not allowed in a regex

Consider enabling multiline mode with the --multiline flag (or -U for short).
When multiline mode is enabled, new line characters can be matched.


Calling tool: grepTool
def visit\(
Matched content:
685:    def visit(self, node: LN) -> Iterator[T]:

Calling tool: grepTool
\bType\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py that LineGenerator.line signature is now def line(self, indent: int = 0) with no type parameter, UnformattedLines class is removed, and there are no call sites passing type=UnformattedLines (or any type=) to self.line(). Grep confirms no remaining UnformattedLines references in code and all self.line(...) calls only pass indent.

Todo item 4 of 19 is correct
description: 'Check that LineGenerator no longer supports UnformattedLines: method line(...) no longer takes a 'type' parameter and all call sites reflect this change (no 'type=UnformattedLines' usage).'

Validating todo item 5 of 19
description: 'Validate that LineGenerator.visit_STANDALONE_COMMENT yields a new line before emitting a standalone comment when not inside brackets, and then emits the comment, so standalone comments are truly on their own line.'

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]

Calling tool: grepTool
is_comment
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2064:    if line.is_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body

Calling tool: grepTool
split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:617:        for line in split_line(current_line, line_length=line_length, py36=py36):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2051:def split_line(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):
2158:        if result:
2159:            yield result
2160:
2161:
2162:def right_hand_split(
2163:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2164:) -> Iterator[Line]:
2165:    """Split line into many lines, starting with the last matching bracket pair.
2166:
2167:    If the split was by optional parentheses, attempt splitting without them, too.
2168:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2169:    this split.

Calling tool: grepTool
class Line\:
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")

Calling tool: grepTool
def __str__\(self\).*Line
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def __str__\(self\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pytree.py:201:        def __str__(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1262:    def __str__(self) -> str:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3072:    def __str__(self) -> str:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:

Calling tool: grepTool
def visit_.*\(self, leaf: Leaf\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Confirmed in black.py that LineGenerator.visit_STANDALONE_COMMENT checks for no open brackets via bracket_tracker.any_open_brackets(), yields a new line with self.line(), then processes the comment via visit_default(leaf). This ensures standalone comments start on a fresh line when not inside brackets.

Todo item 5 of 19 is correct
description: 'Validate that LineGenerator.visit_STANDALONE_COMMENT yields a new line before emitting a standalone comment when not inside brackets, and then emits the comment, so standalone comments are truly on their own line.'

Validating todo item 6 of 19
description: 'Verify split_line returns the line unchanged when line.is_comment is True, preventing any splitting/rewrapping of fmt-off content now encapsulated as a standalone comment.'

Calling tool: grepTool
def split_line\(
Grep command failed with exit code 2: rg: /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/{{FOLDER_PATH}}: IO error for operation on /Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/{{FOLDER_PATH}}: No such file or directory (os error 2)


Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:
2106:                result.extend(
2107:                    split_line(l, line_length=line_length, inner=True, py36=py36)
2108:                )
2109:        except CannotSplit as cs:
2110:            continue
2111:
2112:        else:
2113:            yield from result
2114:            break
2115:
2116:    else:
2117:        yield line
2118:
2119:
2120:def left_hand_split(line: Line, py36: bool = False) -> Iterator[Line]:
2121:    """Split line into many lines, starting with the first matching bracket pair.
2122:
2123:    Note: this usually looks weird, only use this for function definitions.
2124:    Prefer RHS otherwise.  This is why this function is not symmetrical with
2125:    :func:`right_hand_split` which also handles optional parentheses.
2126:    """
2127:    head = Line(depth=line.depth)
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
940:        priority = priority or self.max_delimiter_priority()
941:        return sum(1 for p in self.delimiters.values() if p == priority)
942:
943:    def maybe_increment_for_loop_variable(self, leaf: Leaf) -> bool:
944:        """In a for loop, or comprehension, the variables are often unpacks.
945:
946:        To avoid splitting on the comma in this situation, increase the depth of
947:        tokens between `for` and `in`.
948:        """
949:        if leaf.type == token.NAME and leaf.value == "for":
950:            self.depth += 1
951:            self._for_loop_variable += 1
952:            return True
953:
954:        return False
955:
956:    def maybe_decrement_after_for_loop_variable(self, leaf: Leaf) -> bool:
957:        """See `maybe_increment_for_loop_variable` above for explanation."""
958:        if self._for_loop_variable and leaf.type == token.NAME and leaf.value == "in":
959:            self.depth -= 1
960:            self._for_loop_variable -= 1
961:            return True
962:
963:        return False
964:
965:    def maybe_increment_lambda_arguments(self, leaf: Leaf) -> bool:
966:        """In a lambda expression, there might be more than one argument.
967:
968:        To avoid splitting on the comma in this situation, increase the depth of
969:        tokens between `lambda` and `:`.
970:        """
971:        if leaf.type == token.NAME and leaf.value == "lambda":
972:            self.depth += 1
973:            self._lambda_arguments += 1
974:            return True
975:
976:        return False
977:
978:    def maybe_decrement_after_lambda_arguments(self, leaf: Leaf) -> bool:
979:        """See `maybe_increment_lambda_arguments` above for explanation."""
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s split_line (around line 2051), the first check is `if line.is_comment: yield line; return`, which ensures comment-only lines are returned unchanged. The `Line.is_comment` property (line ~1049) correctly identifies standalone comment lines, matching the new fmt-off encapsulation behavior.

Todo item 6 of 19 is correct
description: 'Verify split_line returns the line unchanged when line.is_comment is True, preventing any splitting/rewrapping of fmt-off content now encapsulated as a standalone comment.'

Validating todo item 7 of 19
description: 'Confirm ALWAYS_NO_SPACE includes STANDALONE_COMMENT, ensuring no extra spaces are added before standalone comment leaves.'

Calling tool: grepTool
ALWAYS_NO_SPACE
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1593:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:14:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:67:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:111:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/empty_lines.py:162:    if t in ALWAYS_NO_SPACE:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:

Calling tool: grepTool
def whitespace\(|whitespace\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1022:            leaf.prefix += whitespace(
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.py:180:    def add_whitespace(self, start):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.py:193:            self.add_whitespace(start)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pgen2/tokenize.pyi:23:    def add_whitespace(self, start: _Coord) -> None: ...

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, ALWAYS_NO_SPACE is defined as CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT} (line ~1578). The whitespace() function checks `if t in ALWAYS_NO_SPACE: return ""` (line ~1593), ensuring no extra spaces are added before STANDALONE_COMMENT leaves.

Todo item 7 of 19 is correct
description: 'Confirm ALWAYS_NO_SPACE includes STANDALONE_COMMENT, ensuring no extra spaces are added before standalone comment leaves.'

Validating todo item 8 of 19
description: 'Validate normalize_invisible_parens(node) skips processing when the node prefix contains an FMT_OFF comment (checks for pc.value in FMT_OFF early), so parentheses aren't altered within fmt-off regions.'

Calling tool: grepTool
def normalize_invisible_parens\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2470:    if "r" in prefix.casefold():
2471:        if unescaped_new_quote.search(body):
2472:            # There's at least one unescaped new_quote in this raw string
2473:            # so converting is impossible
2474:            return
2475:
2476:        # Do not introduce or remove backslashes in raw strings
2477:        new_body = body
2478:    else:
2479:        # remove unnecessary escapes
2480:        new_body = sub_twice(escaped_new_quote, rf"\1\2{new_quote}", body)
2481:        if body != new_body:
2482:            # Consider the string without unnecessary escapes as the original
2483:            body = new_body
2484:            leaf.value = f"{prefix}{orig_quote}{body}{orig_quote}"
2485:        new_body = sub_twice(escaped_orig_quote, rf"\1\2{orig_quote}", new_body)
2486:        new_body = sub_twice(unescaped_new_quote, rf"\1\\{new_quote}", new_body)
2487:    if "f" in prefix.casefold():
2488:        matches = re.findall(r"[^{]\{(.*?)\}[^}]", new_body)
2489:        for m in matches:
2490:            if "\\" in str(m):
2491:                # Do not introduce backslashes in interpolated expressions
2492:                return
2493:    if new_quote == '"""' and new_body[-1:] == '"':
2494:        # edge case:
2495:        new_body = new_body[:-1] + '\\"'
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).

Calling tool: grepTool
FMT_OFF
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2570:            if comment.value in FMT_OFF:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_invisible_parens() checks list_comments(node.prefix) and returns early if any pc.value is in FMT_OFF (lines ~2516-2519). This ensures no parentheses changes occur within fmt-off regions.

Todo item 8 of 19 is correct
description: 'Validate normalize_invisible_parens(node) skips processing when the node prefix contains an FMT_OFF comment (checks for pc.value in FMT_OFF early), so parentheses aren't altered within fmt-off regions.'

Validating todo item 9 of 19
description: 'Confirm FMT_OFF and FMT_ON sets include the variants ('# fmt: off/on' and '# fmt:off/on' and '# yapf: disable/enable') as intended by the PR.'

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, FMT_OFF and FMT_ON are explicitly defined as {"# fmt: off", "# fmt:off", "# yapf: disable"} and {"# fmt: on", "# fmt:on", "# yapf: enable"} respectively (lines ~1967-1968). These match the intended variants and are used in the new logic paths.

Todo item 9 of 19 is correct
description: 'Confirm FMT_OFF and FMT_ON sets include the variants ('# fmt: off/on' and '# fmt:off/on' and '# yapf: disable/enable') as intended by the PR.'

Validating todo item 10 of 19
description: 'Verify normalize_fmt_off iterates until no more pairs are found (while try_again: convert_one_fmt_off_pair(...)), ensuring all fmt-off/on pairs in the file are processed.'

Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: normalize_fmt_off uses a while-loop that repeatedly calls convert_one_fmt_off_pair(node) until it returns False. convert_one_fmt_off_pair scans for a single fmt-off/on pair and returns True upon converting one, otherwise False. This ensures all pairs in the file are processed.

Todo item 10 of 19 is correct
description: 'Verify normalize_fmt_off iterates until no more pairs are found (while try_again: convert_one_fmt_off_pair(...)), ensuring all fmt-off/on pairs in the file are processed.'

Validating todo item 11 of 19
description: 'Review convert_one_fmt_off_pair: it should only convert when the FMT_OFF comment is standalone or 'standalone in disguise' (previous leaf is None or WHITESPACE). If the comment is an inline trailing comment (e.g., '# yapf: disable' at end of a code line), it must be ignored (continue), matching test expectations.'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1788:                return NO
1789:
1790:        elif t in {token.NAME, token.NUMBER, token.STRING}:
1791:            return NO
1792:
1793:    elif p.type == syms.import_from:
1794:        if t == token.DOT:
1795:            if prev and prev.type == token.DOT:
1796:                return NO
1797:
1798:        elif t == token.NAME:
1799:            if v == "import":
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:

Calling tool: grepTool
WHITESPACE\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
720:
721:            self.tree_depth -= 1
722:            out(f"{indent}/{_type}", fg="yellow", bold=False)
723:        else:
724:            _type = token.tok_name.get(node.type, str(node.type))
725:            out(f"{indent}{_type}", fg="blue", nl=False)
726:            if node.prefix:
727:                # We don't have to handle prefixes for `Node` objects since
728:                # that delegates to the first child anyway.
729:                out(f" {node.prefix!r}", fg="green", bold=False, nl=False)
730:            out(f" {node.value!r}", fg="blue", bold=False)
731:
732:    @classmethod
733:    def show(cls, code: Union[str, Leaf, Node]) -> None:
734:        """Pretty-print the lib2to3 AST of a given string of `code`.
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/test_black.py
360:        self.assertFormatEqual(expected, actual)
361:        black.assert_equivalent(source, actual)
362:        black.assert_stable(source, actual, line_length=ll)
363:
364:    @patch("black.dump_to_file", dump_to_stderr)
365:    def test_string_prefixes(self) -> None:
366:        source, expected = read_data("string_prefixes")
367:        actual = fs(source)
368:        self.assertFormatEqual(expected, actual)
369:        black.assert_equivalent(source, actual)
370:        black.assert_stable(source, actual, line_length=ll)
371:
372:    @patch("black.dump_to_file", dump_to_stderr)
373:    def test_python2(self) -> None:
374:        source, expected = read_data("python2")
375:        actual = fs(source)
376:        self.assertFormatEqual(expected, actual)
377:        # black.assert_equivalent(source, actual)
378:        black.assert_stable(source, actual, line_length=ll)
379:
380:    @patch("black.dump_to_file", dump_to_stderr)
381:    def test_python2_unicode_literals(self) -> None:
382:        source, expected = read_data("python2_unicode_literals")
383:        actual = fs(source)
384:        self.assertFormatEqual(expected, actual)
385:        black.assert_stable(source, actual, line_length=ll)
386:
387:    @patch("black.dump_to_file", dump_to_stderr)
388:    def test_stub(self) -> None:
389:        mode = black.FileMode.PYI
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(
470:                unstyle(str(report)),
471:                "1 file reformatted, 2 files left unchanged, "
472:                "1 file failed to reformat.",
473:            )
474:            self.assertEqual(report.return_code, 123)
475:            report.done(Path("f3"), black.Changed.YES)
476:            self.assertEqual(len(out_lines), 4)
477:            self.assertEqual(len(err_lines), 1)
478:            self.assertEqual(out_lines[-1], "reformatted f3")
479:            self.assertEqual(

Calling tool: globTool
**/tests/data/*fmtonoff2*
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
fmt:\s*off
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:140:blocks that start with `# fmt: off` and end with `# fmt: on`.  It also
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:827:* `# fmt: off` and `# fmt: on` are now much more dependable:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:903:* fixed optional parentheses being removed within `# fmt: off` sections (#224)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/README.md:1066:* `# fmt: off` and `# fmt: on` are implemented (#5)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff2.py:6:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:9:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:14:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:44:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:48:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:61:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:86:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:103:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:119:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:136:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:141:# fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:188:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:194:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:214:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:239:        # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:261:    # fmt: off
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/tests/data/fmtonoff.py:277:# fmt: off

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2476:        # Do not introduce or remove backslashes in raw strings
2477:        new_body = body
2478:    else:
2479:        # remove unnecessary escapes
2480:        new_body = sub_twice(escaped_new_quote, rf"\1\2{new_quote}", body)
2481:        if body != new_body:
2482:            # Consider the string without unnecessary escapes as the original
2483:            body = new_body
2484:            leaf.value = f"{prefix}{orig_quote}{body}{orig_quote}"
2485:        new_body = sub_twice(escaped_orig_quote, rf"\1\2{orig_quote}", new_body)
2486:        new_body = sub_twice(unescaped_new_quote, rf"\1\\{new_quote}", new_body)
2487:    if "f" in prefix.casefold():
2488:        matches = re.findall(r"[^{]\{(.*?)\}[^}]", new_body)
2489:        for m in matches:
2490:            if "\\" in str(m):
2491:                # Do not introduce backslashes in interpolated expressions
2492:                return
2493:    if new_quote == '"""' and new_body[-1:] == '"':
2494:        # edge case:
2495:        new_body = new_body[:-1] + '\\"'
2496:    orig_escape_count = body.count("\\")
2497:    new_escape_count = new_body.count("\\")
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair (lines ~2562-2606) explicitly checks that a FMT_OFF comment is either a STANDALONE_COMMENT or ‘standalone in disguise’ by verifying the preceding leaf is None or WHITESPACE. If it’s an inline trailing comment (prev exists and is not WHITESPACE), it continues (ignores), matching test expectations (e.g., '# yapf: disable'). normalize_fmt_off invokes this function, ensuring the behavior is applied.

Todo item 11 of 19 is correct
description: 'Review convert_one_fmt_off_pair: it should only convert when the FMT_OFF comment is standalone or 'standalone in disguise' (previous leaf is None or WHITESPACE). If the comment is an inline trailing comment (e.g., '# yapf: disable' at end of a code line), it must be ignored (continue), matching test expectations.'

Validating todo item 12 of 19
description: 'Validate convert_one_fmt_off_pair constructs the STANDALONE_COMMENT leaf with value 'FMT_OFF + newline + ignored content until FMT_ON' and trims a trailing newline if present (hidden_value.endswith('\n')), preserving original content exactly.'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: convert_one_fmt_off_pair builds a STANDALONE_COMMENT leaf whose value is comment.value + "\n" + the concatenated string of ignored nodes, and trims a trailing newline if present. The code also adjusts prefixes to preserve original content, matching the requirement.

Todo item 12 of 19 is correct
description: 'Validate convert_one_fmt_off_pair constructs the STANDALONE_COMMENT leaf with value 'FMT_OFF + newline + ignored content until FMT_ON' and trims a trailing newline if present (hidden_value.endswith('\n')), preserving original content exactly.'

Validating todo item 13 of 19
description: 'Check prefix handling in convert_one_fmt_off_pair: first.prefix is trimmed with prefix[comment.consumed:], and the inserted STANDALONE_COMMENT leaf uses prefix[:previous_consumed] + '\n' * comment.newlines, ensuring surrounding newlines/indentation are preserved and no extra blank lines are introduced between functions (as per issue #335).'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s convert_one_fmt_off_pair, first.prefix is set to prefix[comment.consumed:] and the inserted STANDALONE_COMMENT uses prefix[:previous_consumed] + "\n" * comment.newlines (lines ~2582–2604). This preserves surrounding newlines/indentation, preventing extra blank lines between functions as required by issue #335.

Todo item 13 of 19 is correct
description: 'Check prefix handling in convert_one_fmt_off_pair: first.prefix is trimmed with prefix[comment.consumed:], and the inserted STANDALONE_COMMENT leaf uses prefix[:previous_consumed] + '\n' * comment.newlines, ensuring surrounding newlines/indentation are preserved and no extra blank lines are introduced between functions (as per issue #335).'

Validating todo item 14 of 19
description: 'Verify generate_ignored_nodes starts from container_of(leaf) and yields consecutive siblings until it encounters FMT_ON in a container prefix or reaches the end of the current block; confirm the loop condition stops at token.ENDMARKER and does not cross statement boundaries improperly.'

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: grepTool
FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: grepTool
SURROUNDED_BY_BRACKETS
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1855:        if parent.type in SURROUNDED_BY_BRACKETS:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: `generate_ignored_nodes` starts from `container_of(leaf)` (black.py:2618) and iterates consecutive siblings via `container = container.next_sibling` (lines 2624-2626). It stops when encountering `FMT_ON` in the container’s prefix (lines 2620-2622) and the while-loop guards against crossing boundaries with `container is not None and container.type != token.ENDMARKER` (line 2619). Additionally, `container_of` is constrained to not cross statement boundaries (breaks on file_input and bracketed parents, lines 1852-1856).

Todo item 14 of 19 is correct
description: 'Verify generate_ignored_nodes starts from container_of(leaf) and yields consecutive siblings until it encounters FMT_ON in a container prefix or reaches the end of the current block; confirm the loop condition stops at token.ENDMARKER and does not cross statement boundaries improperly.'

Validating todo item 15 of 19
description: 'Check container_of(leaf) ascends to the topmost container with the same prefix but stops when encountering syms.file_input or nodes surrounded by brackets (SURROUNDED_BY_BRACKETS), so fmt-off conversion is limited to the correct block scope (including inside bracket pairs).'

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1800:                return SPACE
1801:
1802:            if prev and prev.type == token.DOT:
1803:                return NO
1804:
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent
1900:        and leaf.parent.type not in {syms.factor, syms.star_expr}
1901:    ):
1902:        return MATH_PRIORITIES[leaf.type]
1903:
1904:    if leaf.type in COMPARATORS:
1905:        return COMPARATOR_PRIORITY
1906:
1907:    if (
1908:        leaf.type == token.STRING
1909:        and previous is not None
1910:        and previous.type == token.STRING
1911:    ):
1912:        return STRING_PRIORITY
1913:
1914:    if leaf.type != token.NAME:
1915:        return 0
1916:
1917:    if (
1918:        leaf.value == "for"
1919:        and leaf.parent

Calling tool: grepTool
SURROUNDED_BY_BRACKETS
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:799:SURROUNDED_BY_BRACKETS = {
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1855:        if parent.type in SURROUNDED_BY_BRACKETS:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,
780:    token.AT,
781:    token.TILDE,
782:    token.DOUBLESTAR,
783:}
784:STARS = {token.STAR, token.DOUBLESTAR}
785:VARARGS_PARENTS = {
786:    syms.arglist,
787:    syms.argument,  # double star in arglist
788:    syms.trailer,  # single argument to call
789:    syms.typedargslist,
790:    syms.varargslist,  # lambdas
791:}
792:UNPACKING_PARENTS = {
793:    syms.atom,  # single element of a list or set literal
794:    syms.dictsetmaker,
795:    syms.listmaker,
796:    syms.testlist_gexp,
797:    syms.testlist_star_expr,
798:}
799:SURROUNDED_BY_BRACKETS = {
800:    syms.typedargslist,
801:    syms.arglist,
802:    syms.subscriptlist,
803:    syms.vfplist,
804:    syms.import_as_names,
805:    syms.yield_expr,
806:    syms.testlist_gexp,
807:    syms.testlist_star_expr,
808:    syms.listmaker,
809:    syms.dictsetmaker,
810:}
811:TEST_DESCENDANTS = {
812:    syms.test,
813:    syms.lambdef,
814:    syms.or_test,
815:    syms.and_test,
816:    syms.not_test,
817:    syms.comparison,
818:    syms.star_expr,
819:    syms.expr,
820:    syms.xor_expr,
821:    syms.and_expr,
822:    syms.shift_expr,
823:    syms.arith_expr,
824:    syms.trailer,
825:    syms.term,
826:    syms.power,
827:}
828:ASSIGNMENTS = {
829:    "=",
830:    "+=",
831:    "-=",
832:    "*=",
833:    "@=",
834:    "/=",
835:    "%=",
836:    "&=",
837:    "|=",
838:    "^=",
839:    "<<=",

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py’s container_of(), the loop ascends parents while the first child’s prefix matches the leaf’s prefix, but explicitly breaks when encountering syms.file_input or any parent in SURROUNDED_BY_BRACKETS (lines 1849–1856). This ensures fmt-off conversion (used by generate_ignored_nodes) is limited to the correct block scope, including inside bracket pairs.

Todo item 15 of 19 is correct
description: 'Check container_of(leaf) ascends to the topmost container with the same prefix but stops when encountering syms.file_input or nodes surrounded by brackets (SURROUNDED_BY_BRACKETS), so fmt-off conversion is limited to the correct block scope (including inside bracket pairs).'

Validating todo item 16 of 19
description: 'Ensure Line.append_comment converts a leading comment to STANDALONE_COMMENT and resets prefix appropriately, and for comments within open brackets it returns False so such comments are handled as normal leaves, consistent with the new STANDALONE_COMMENT handling.'

Calling tool: grepTool
class Line\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:993:class Line:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("

Calling tool: grepTool
def append_comment\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1193:    def append_comment(self, comment: Leaf) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,
770:    token.CIRCUMFLEX,
771:    token.AMPER,
772:    token.LEFTSHIFT,
773:    token.RIGHTSHIFT,
774:    token.PLUS,
775:    token.MINUS,
776:    token.STAR,
777:    token.SLASH,
778:    token.DOUBLESLASH,
779:    token.PERCENT,

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.

Calling tool: grepTool
def __str__\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/blib2to3/pytree.py:201:        def __str__(self):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1262:    def __str__(self) -> str:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3072:    def __str__(self) -> str:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        Ø: Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=Ø
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=Ø)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=Ø)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=Ø)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=Ø)
1566:        self.visit_expr_stmt = partial(v, keywords=Ø, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=Ø, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())

Calling tool: grepTool
\.comments\b
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1212:            self.comments.append((after, comment))
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1220:        if not self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1231:        for index, comment_after in self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1238:        for i in range(len(self.comments)):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1239:            comment_index, comment = self.comments[i]
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1241:                self.comments[i] = (comma_index - 1, comment)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1273:        for _, comment in self.comments:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1279:        return bool(self.leaves or self.comments)

Calling tool: grepTool
comments_after\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2154:            for comment_after in line.comments_after(leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2207:            for comment_after in line.comments_after(leaf):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2339:        for comment_after in line.comments_after(leaf, index):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:2385:        for comment_after in line.comments_after(leaf, index):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py:3281:        for comment in line.comments_after(leaf, index):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/good/black/black.py
2128:    body = Line(depth=line.depth + 1, inside_brackets=True)
2129:    tail = Line(depth=line.depth)
2130:    tail_leaves: List[Leaf] = []
2131:    body_leaves: List[Leaf] = []
2132:    head_leaves: List[Leaf] = []
2133:    current_leaves = head_leaves
2134:    matching_bracket = None
2135:    for leaf in line.leaves:
2136:        if (
2137:            current_leaves is body_leaves
2138:            and leaf.type in CLOSING_BRACKETS
2139:            and leaf.opening_bracket is matching_bracket
2140:        ):
2141:            current_leaves = tail_leaves if body_leaves else head_leaves
2142:        current_leaves.append(leaf)
2143:        if current_leaves is head_leaves:
2144:            if leaf.type in OPENING_BRACKETS:
2145:                matching_bracket = leaf
2146:                current_leaves = body_leaves
2147:    # Since body is a new indent level, remove spurious leading whitespace.
2148:    if body_leaves:
2149:        normalize_prefix(body_leaves[0], inside_brackets=True)
2150:    # Build the new lines.
2151:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2152:        for leaf in leaves:
2153:            result.append(leaf, preformatted=True)
2154:            for comment_after in line.comments_after(leaf):
2155:                result.append(comment_after, preformatted=True)
2156:    bracket_split_succeeded_or_raise(head, body, tail)
2157:    for result in (head, body, tail):
2158:        if result:
2159:            yield result
2160:
2161:
2162:def right_hand_split(
2163:    line: Line, line_length: int, py36: bool = False, omit: Collection[LeafID] = ()
2164:) -> Iterator[Line]:
2165:    """Split line into many lines, starting with the last matching bracket pair.
2166:
2167:    If the split was by optional parentheses, attempt splitting without them, too.
2168:    `omit` is a collection of closing bracket IDs that shouldn't be considered for
2169:    this split.
2170:
2171:    Note: running this function modifies `bracket_depth` on the leaves of `line`.
2172:    """
2173:    head = Line(depth=line.depth)
2174:    body = Line(depth=line.depth + 1, inside_brackets=True)
2175:    tail = Line(depth=line.depth)
2176:    tail_leaves: List[Leaf] = []
2177:    body_leaves: List[Leaf] = []
2178:    head_leaves: List[Leaf] = []
2179:    current_leaves = tail_leaves
2180:    opening_bracket = None
2181:    closing_bracket = None
2182:    for leaf in reversed(line.leaves):
2183:        if current_leaves is body_leaves:
2184:            if leaf is opening_bracket:
2185:                current_leaves = head_leaves if body_leaves else tail_leaves
2186:        current_leaves.append(leaf)
2187:        if current_leaves is tail_leaves:
2188:            if leaf.type in CLOSING_BRACKETS and id(leaf) not in omit:
2189:                opening_bracket = leaf.opening_bracket
2190:                closing_bracket = leaf
2191:                current_leaves = body_leaves
2192:    tail_leaves.reverse()
2193:    body_leaves.reverse()
2194:    head_leaves.reverse()
2195:    # Since body is a new indent level, remove spurious leading whitespace.
2196:    if body_leaves:
2197:        normalize_prefix(body_leaves[0], inside_brackets=True)
2198:    if not head_leaves:
2199:        # No `head` means the split failed. Either `tail` has all content or
2200:        # the matching `opening_bracket` wasn't available on `line` anymore.
2201:        raise CannotSplit("No brackets found")
2202:
2203:    # Build the new lines.
2204:    for result, leaves in (head, head_leaves), (body, body_leaves), (tail, tail_leaves):
2205:        for leaf in leaves:
2206:            result.append(leaf, preformatted=True)
2207:            for comment_after in line.comments_after(leaf):
2208:                result.append(comment_after, preformatted=True)
2209:    assert opening_bracket and closing_bracket
2210:    body.should_explode = should_explode(body, opening_bracket)
2211:    bracket_split_succeeded_or_raise(head, body, tail)
2212:    if (
2213:        # the body shouldn't be exploded
2214:        not body.should_explode
2215:        # the opening bracket is an optional paren
2216:        and opening_bracket.type == token.LPAR
2217:        and not opening_bracket.value
2218:        # the closing bracket is an optional paren
2219:        and closing_bracket.type == token.RPAR
2220:        and not closing_bracket.value
2221:        # it's not an import (optional parens are the only thing we can split on
2222:        # in this case; attempting a split without them is a waste of time)
2223:        and not line.is_import
2224:        # there are no standalone comments in the body
2225:        and not body.contains_standalone_comments(0)
2226:        # and we can actually remove the parens
2227:        and can_omit_invisible_parens(body, line_length)
2228:    ):
2229:        omit = {id(closing_bracket), *omit}
2230:        try:
2231:            yield from right_hand_split(line, line_length, py36=py36, omit=omit)
2232:            return
2233:
2234:        except CannotSplit:
2235:            if not (
2236:                can_be_split(body)
2237:                or is_line_short_enough(body, line_length=line_length)
2238:            ):
2239:                raise CannotSplit(
2240:                    "Splitting failed, body is still too long and can't be split."
2241:                )
2242:
2243:            elif head.contains_multiline_strings() or tail.contains_multiline_strings():
2244:                raise CannotSplit(
2245:                    "The current optional pair of parentheses is bound to fail to "
2246:                    "satisfy the splitting algorithm because the head or the tail "
2247:                    "contains multiline strings which by definition never fit one "
2248:                    "line."
2249:                )
2250:
2251:    ensure_visible(opening_bracket)
2252:    ensure_visible(closing_bracket)
2253:    for result in (head, body, tail):
2254:        if result:
2255:            yield result
2256:
2257:
2258:def bracket_split_succeeded_or_raise(head: Line, body: Line, tail: Line) -> None:
2259:    """Raise :exc:`CannotSplit` if the last left- or right-hand split failed.
2260:
2261:    Do nothing otherwise.
2262:
2263:    A left- or right-hand split is based on a pair of brackets. Content before
2264:    (and including) the opening bracket is left on one line, content inside the
2265:    brackets is put on a separate line, and finally content starting with and
2266:    following the closing bracket is put on a separate line.
2267:
2268:    Those are called `head`, `body`, and `tail`, respectively. If the split
2269:    produced the same line (all content in `head`) or ended up with an empty `body`
2270:    and the `tail` is just the closing bracket, then it's considered failed.
2271:    """
2272:    tail_len = len(str(tail).strip())
2273:    if not body:
2274:        if tail_len == 0:
2275:            raise CannotSplit("Splitting brackets produced the same line")
2276:
2277:        elif tail_len < 3:
2278:            raise CannotSplit(
2279:                f"Splitting brackets on an empty body to save "
2280:                f"{tail_len} characters is not worth it"
2281:            )
2282:
2283:
2284:def dont_increase_indentation(split_func: SplitFunc) -> SplitFunc:
2285:    """Normalize prefix of the first leaf in every line returned by `split_func`.
2286:
2287:    This is a decorator over relevant split functions.
2288:    """
2289:
2290:    @wraps(split_func)
2291:    def split_wrapper(line: Line, py36: bool = False) -> Iterator[Line]:
2292:        for l in split_func(line, py36):
2293:            normalize_prefix(l.leaves[0], inside_brackets=True)
2294:            yield l
2295:
2296:    return split_wrapper
2297:
2298:
2299:@dont_increase_indentation
2300:def delimiter_split(line: Line, py36: bool = False) -> Iterator[Line]:
2301:    """Split according to delimiters of the highest priority.
2302:
2303:    If `py36` is True, the split will add trailing commas also in function
2304:    signatures that contain `*` and `**`.
2305:    """
2306:    try:
2307:        last_leaf = line.leaves[-1]
2308:    except IndexError:
2309:        raise CannotSplit("Line empty")
2310:
2311:    bt = line.bracket_tracker
2312:    try:
2313:        delimiter_priority = bt.max_delimiter_priority(exclude={id(last_leaf)})
2314:    except ValueError:
2315:        raise CannotSplit("No delimiters found")
2316:
2317:    if delimiter_priority == DOT_PRIORITY:
2318:        if bt.delimiter_count_with_priority(delimiter_priority) == 1:
2319:            raise CannotSplit("Splitting a single attribute from its owner looks wrong")
2320:
2321:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2322:    lowest_depth = sys.maxsize
2323:    trailing_comma_safe = True
2324:
2325:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2326:        """Append `leaf` to current line or to new line if appending impossible."""
2327:        nonlocal current_line
2328:        try:
2329:            current_line.append_safe(leaf, preformatted=True)
2330:        except ValueError as ve:
2331:            yield current_line
2332:
2333:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2334:            current_line.append(leaf)
2335:
2336:    for index, leaf in enumerate(line.leaves):
2337:        yield from append_to_line(leaf)
2338:
2339:        for comment_after in line.comments_after(leaf, index):
2340:            yield from append_to_line(comment_after)
2341:
2342:        lowest_depth = min(lowest_depth, leaf.bracket_depth)
2343:        if leaf.bracket_depth == lowest_depth and is_vararg(
2344:            leaf, within=VARARGS_PARENTS
2345:        ):
2346:            trailing_comma_safe = trailing_comma_safe and py36
2347:        leaf_priority = bt.delimiters.get(id(leaf))
2348:        if leaf_priority == delimiter_priority:
2349:            yield current_line
2350:
2351:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2352:    if current_line:
2353:        if (
2354:            trailing_comma_safe
2355:            and delimiter_priority == COMMA_PRIORITY
2356:            and current_line.leaves[-1].type != token.COMMA
2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
2358:        ):
2359:            current_line.append(Leaf(token.COMMA, ","))
2360:        yield current_line
2361:
2362:
2363:@dont_increase_indentation
2364:def standalone_comment_split(line: Line, py36: bool = False) -> Iterator[Line]:
2365:    """Split standalone comments from the rest of the line."""
2366:    if not line.contains_standalone_comments(0):
2367:        raise CannotSplit("Line does not have any standalone comments")
2368:
2369:    current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2370:
2371:    def append_to_line(leaf: Leaf) -> Iterator[Line]:
2372:        """Append `leaf` to current line or to new line if appending impossible."""
2373:        nonlocal current_line
2374:        try:
2375:            current_line.append_safe(leaf, preformatted=True)
2376:        except ValueError as ve:
2377:            yield current_line
2378:
2379:            current_line = Line(depth=line.depth, inside_brackets=line.inside_brackets)
2380:            current_line.append(leaf)
2381:
2382:    for index, leaf in enumerate(line.leaves):
2383:        yield from append_to_line(leaf)
2384:
2385:        for comment_after in line.comments_after(leaf, index):
2386:            yield from append_to_line(comment_after)
2387:
2388:    if current_line:
2389:        yield current_line
2390:
2391:
2392:def is_import(leaf: Leaf) -> bool:
2393:    """Return True if the given leaf starts an import statement."""
2394:    p = leaf.parent
2395:    t = leaf.type
2396:    v = leaf.value
2397:    return bool(
2398:        t == token.NAME
2399:        and (
2400:            (v == "import" and p and p.type == syms.import_name)
2401:            or (v == "from" and p and p.type == syms.import_from)
2402:        )
2403:    )
2404:
2405:
2406:def normalize_prefix(leaf: Leaf, *, inside_brackets: bool) -> None:
2407:    """Leave existing extra newlines if not `inside_brackets`. Remove everything
2408:    else.
2409:
2410:    Note: don't use backslashes for formatting or you'll lose your voting rights.
2411:    """
2412:    if not inside_brackets:
2413:        spl = leaf.prefix.split("#")
2414:        if "\\" not in spl[0]:
2415:            nl_count = spl[-1].count("\n")
2416:            if len(spl) > 1:
2417:                nl_count -= 1
2418:            leaf.prefix = "\n" * nl_count
2419:            return
2420:
2421:    leaf.prefix = ""
2422:
2423:
2424:def normalize_string_prefix(leaf: Leaf, remove_u_prefix: bool = False) -> None:
2425:    """Make all string prefixes lowercase.
2426:
2427:    If remove_u_prefix is given, also removes any u prefix from the string.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: In black.py Line.append_comment (lines ~1193-1213) converts a leading comment to STANDALONE_COMMENT and clears its prefix, but it only returns False for STANDALONE_COMMENT when brackets are open. For token.COMMENT within open brackets it returns True and stores it in comments, not as a normal leaf, violating the requirement that comments within open brackets be handled as normal leaves.


=== PHASE 2 COMPLETE ===

