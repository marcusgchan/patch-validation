=== PHASE 1: ANALYSIS ===

Calling tool: globTool
**/*test_fmtonoff2*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: globTool
**/test*fmt*
No files found. Call Project Search tool again with a more generic glob.

Calling tool: grepTool
test_fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
390:        source, expected = read_data("stub.pyi")
391:        actual = fs(source, mode=mode)
392:        self.assertFormatEqual(expected, actual)
393:        black.assert_stable(source, actual, line_length=ll, mode=mode)
394:
395:    @patch("black.dump_to_file", dump_to_stderr)
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)
426:
427:    def test_report_verbose(self) -> None:
428:        report = black.Report(verbose=True)
429:        out_lines = []
430:        err_lines = []
431:
432:        def out(msg: str, **kwargs: Any) -> None:
433:            out_lines.append(msg)
434:
435:        def err(msg: str, **kwargs: Any) -> None:
436:            err_lines.append(msg)
437:
438:        with patch("black.out", out), patch("black.err", err):
439:            report.done(Path("f1"), black.Changed.NO)
440:            self.assertEqual(len(out_lines), 1)
441:            self.assertEqual(len(err_lines), 0)
442:            self.assertEqual(out_lines[-1], "f1 already well formatted, good job.")
443:            self.assertEqual(unstyle(str(report)), "1 file left unchanged.")
444:            self.assertEqual(report.return_code, 0)
445:            report.done(Path("f2"), black.Changed.YES)
446:            self.assertEqual(len(out_lines), 2)
447:            self.assertEqual(len(err_lines), 0)
448:            self.assertEqual(out_lines[-1], "reformatted f2")
449:            self.assertEqual(
450:                unstyle(str(report)), "1 file reformatted, 1 file left unchanged."
451:            )
452:            report.done(Path("f3"), black.Changed.CACHED)
453:            self.assertEqual(len(out_lines), 3)
454:            self.assertEqual(len(err_lines), 0)
455:            self.assertEqual(
456:                out_lines[-1], "f3 wasn't modified on disk since last run."
457:            )
458:            self.assertEqual(
459:                unstyle(str(report)), "1 file reformatted, 2 files left unchanged."
460:            )
461:            self.assertEqual(report.return_code, 0)
462:            report.check = True
463:            self.assertEqual(report.return_code, 1)
464:            report.check = False
465:            report.failed(Path("e1"), "boom")
466:            self.assertEqual(len(out_lines), 3)
467:            self.assertEqual(len(err_lines), 1)
468:            self.assertEqual(err_lines[-1], "error: cannot format e1: boom")
469:            self.assertEqual(

Calling tool: grepTool
fmtonoff2
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_bug.info:4:test_file="tests/data/fmtonoff2.py;tests/test_black.py"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/bugsinpy_run_test.sh:1:python -m unittest -q tests.test_black.BlackTestCase.test_fmtonoff2
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:405:        source, expected = read_data("fmtonoff2")

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.
2100:        result: List[Line] = []
2101:        try:
2102:            for l in split_func(line, py36):
2103:                if str(l).strip("\n") == line_str:
2104:                    raise CannotSplit("Split function returned an unchanged result")
2105:

Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [

Calling tool: grepTool
class Line\(
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class Line
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:993:class Line:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
980:        if self._lambda_arguments and leaf.type == token.COLON:
981:            self.depth -= 1
982:            self._lambda_arguments -= 1
983:            return True
984:
985:        return False
986:
987:    def get_open_lsqb(self) -> Optional[Leaf]:
988:        """Return the most recent opening square bracket (if any)."""
989:        return self.bracket_match.get((self.depth - 1, token.RSQB))
990:
991:
992:@dataclass
993:class Line:
994:    """Holds leaves and comments. Can be printed with `str(line)`."""
995:
996:    depth: int = 0
997:    leaves: List[Leaf] = Factory(list)
998:    comments: List[Tuple[Index, Leaf]] = Factory(list)
999:    bracket_tracker: BracketTracker = Factory(BracketTracker)
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1080:    def is_def(self) -> bool:
1081:        """Is this a function definition? (Also returns True for async defs.)"""
1082:        try:
1083:            first_leaf = self.leaves[0]
1084:        except IndexError:
1085:            return False
1086:
1087:        try:
1088:            second_leaf: Optional[Leaf] = self.leaves[1]
1089:        except IndexError:
1090:            second_leaf = None
1091:        return (first_leaf.type == token.NAME and first_leaf.value == "def") or (
1092:            first_leaf.type == token.ASYNC
1093:            and second_leaf is not None
1094:            and second_leaf.type == token.NAME
1095:            and second_leaf.value == "def"
1096:        )
1097:
1098:    @property
1099:    def is_class_paren_empty(self) -> bool:
1100:        """Is this a class with no base classes but using parentheses?
1101:
1102:        Those are unnecessary and should be removed.
1103:        """
1104:        return (
1105:            bool(self)
1106:            and len(self.leaves) == 4
1107:            and self.is_class
1108:            and self.leaves[2].type == token.LPAR
1109:            and self.leaves[2].value == "("
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """

Calling tool: grepTool
class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        : Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=)
1566:        self.visit_expr_stmt = partial(v, keywords=, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:
1630:                    return NO
1631:
1632:                elif prevp.parent.type == syms.typedargslist:
1633:                    # A bit hacky: if the equal sign has whitespace, it means we
1634:                    # previously found it's a typed argument.  So, we're using
1635:                    # that, too.
1636:                    return prevp.prefix
1637:
1638:        elif prevp.type in STARS:
1639:            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):

Calling tool: createTodo
Todo List Created
Todo List (17 items):
- [ ] Verify format_str() calls normalize_fmt_off(src_node) before constructing LineGenerator and emitting lines (in black.py around lines 596-609). (ID: todo-1)
- [ ] Confirm new preprocessing pass exists: functions normalize_fmt_off(), convert_one_fmt_off_pair(), and generate_ignored_nodes() are defined and used, with normalize_fmt_off() looping until convert_one_fmt_off_pair() returns False. (ID: todo-2)
- [ ] Check convert_one_fmt_off_pair() only triggers on standalone '# fmt: off' comments (or disguised standalone: previous leaf missing or whitespace) and skips inline trailing '# fmt: off' comments (black.py lines ~2567-2578). (ID: todo-3)
- [ ] Check convert_one_fmt_off_pair() builds hidden_value that concatenates the '# fmt: off' line plus the exact string of all ignored nodes up to '# fmt: on', and trims a trailing newline if present to avoid adding an extra blank line (black.py lines ~2584-2591). (ID: todo-4)
- [ ] Validate convert_one_fmt_off_pair() updates prefixes correctly: sets first.prefix = prefix[comment.consumed:] to drop the consumed part, and computes the new STANDALONE_COMMENT prefix as prefix[:previous_consumed] + '\n' * comment.newlines (black.py lines ~2582-2586 and ~2601-2605). (ID: todo-5)
- [ ] Verify convert_one_fmt_off_pair() removes all ignored nodes and inserts a single STANDALONE_COMMENT leaf at the correct index in the parent, and returns True to allow repeated conversion (black.py lines ~2591-2606). (ID: todo-6)
- [ ] Confirm generate_ignored_nodes() starts from container_of(leaf) and yields sequential sibling containers until an '# fmt: on' comment is encountered or until ENDMARKER, ensuring content can span multiple top-level statements and functions (black.py lines ~2613-2627). (ID: todo-7)
- [ ] Confirm container_of() stops ascending at syms.file_input and at SURROUNDED_BY_BRACKETS to prevent over-climbing past the module root or into bracket pairs (black.py lines ~1852-1856). (ID: todo-8)
- [ ] Ensure exception-based fmt on/off handling was removed: classes FormatError, FormatOn, and FormatOff no longer exist; generate_comments() no longer raises these exceptions; LineGenerator.visit/visit_default no longer has try/except for FormatOn/Off; UnformattedLines and visit_unformatted() are removed; split_line() no longer checks for UnformattedLines; EmptyLineTracker no longer special-cases UnformattedLines. (ID: todo-9)
- [ ] Verify generate_comments() now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and never raises on FMT_ON/FMT_OFF (black.py lines ~1971-1991). (ID: todo-10)
- [ ] Verify LineGenerator has visit_STANDALONE_COMMENT() that yields a line break if not inside brackets before visiting the comment leaf (black.py lines ~1544-1547). (ID: todo-11)
- [ ] Check Line and whitespace handling for STANDALONE_COMMENT: ALWAYS_NO_SPACE includes STANDALONE_COMMENT; Line.is_comment returns True for a line with a single STANDALONE_COMMENT leaf; split_line() short-circuits when line.is_comment is True (black.py lines ~1578-1597, 1049-1052, and 2064-2066). (ID: todo-12)
- [ ] Validate EmptyLineTracker._maybe_empty_lines_for_class_or_def() avoids inserting empty lines when the previous line is a standalone comment at the same depth (black.py lines ~1365-1370). (ID: todo-13)
- [ ] Ensure FMT_OFF and FMT_ON sets are defined and include '# fmt: off/on' and Yapf equivalents '# yapf: disable/enable' (black.py lines ~1967-1968). (ID: todo-14)
- [ ] Confirm that tests/data/fmtonoff2.py contains no '# output' marker so expected == input per read_data(); tests/test_black.py:test_fmtonoff2 reads 'fmtonoff2' and asserts formatted output equals expected (tests/test_black.py lines ~404-409 and read_data implementation lines ~34-54). (ID: todo-15)
- [ ] Double-check that there are no remaining references to deleted UnformattedLines, FormatOn, or FormatOff identifiers anywhere in the codebase (grep for these names should yield no uses). (ID: todo-16)
- [ ] Verify DebugVisitor.show() signature change accepts Union[str, Leaf, Node] and handles both string and pre-parsed trees (black.py lines ~730-738); ensure no callers rely on the old signature. (ID: todo-17)


=== PHASE 1 COMPLETE ===

=== PHASE 2: VALIDATION ===

Validating todo item 1 of 17
description: 'Verify format_str() calls normalize_fmt_off(src_node) before constructing LineGenerator and emitting lines (in black.py around lines 596-609).'
Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
def format_str\(
Matched content:
589:def format_str(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 596-609, format_str() calls normalize_fmt_off(src_node) at line 602 before constructing LineGenerator (line 603) and emitting lines, satisfying the requirement.


Todo item 1 of 17 is correct
description: 'Verify format_str() calls normalize_fmt_off(src_node) before constructing LineGenerator and emitting lines (in black.py around lines 596-609).'
Validating todo item 2 of 17
description: 'Confirm new preprocessing pass exists: functions normalize_fmt_off(), convert_one_fmt_off_pair(), and generate_ignored_nodes() are defined and used, with normalize_fmt_off() looping until convert_one_fmt_off_pair() returns False.'
Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: grepTool
(?<!def )normalize_fmt_off\(
Grep command failed with exit code 2: rg: regex parse error:
    (?:(?<!def )normalize_fmt_off\()
       ^^^^
error: look-around, including look-ahead and look-behind, is not supported

Consider enabling PCRE2 with the --pcre2 flag, which can handle backreferences
and look-around.


Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_fmt_off() is defined (line ~2555) and is called in format_str() (line ~602). normalize_fmt_off() loops with while try_again: try_again = convert_one_fmt_off_pair(node). convert_one_fmt_off_pair() is defined (line ~2562) and uses generate_ignored_nodes(), which is defined (line ~2613). This matches the requirement.


Todo item 2 of 17 is correct
description: 'Confirm new preprocessing pass exists: functions normalize_fmt_off(), convert_one_fmt_off_pair(), and generate_ignored_nodes() are defined and used, with normalize_fmt_off() looping until convert_one_fmt_off_pair() returns False.'
Validating todo item 3 of 17
description: 'Check convert_one_fmt_off_pair() only triggers on standalone '# fmt: off' comments (or disguised standalone: previous leaf missing or whitespace) and skips inline trailing '# fmt: off' comments (black.py lines ~2567-2578).'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:

Calling tool: grepTool
WHITESPACE\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):

Calling tool: grepTool
FMT_OFF\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py convert_one_fmt_off_pair(), lines 25712577 ensure only standalone fmt-off comments trigger: if the comment isnt STANDALONE_COMMENT, it checks the preceding leaf and continues (skips) when a non-whitespace previous leaf exists, thereby ignoring inline trailing '# fmt: off' while allowing standalone or disguised standalone (no prev or whitespace).


Todo item 3 of 17 is correct
description: 'Check convert_one_fmt_off_pair() only triggers on standalone '# fmt: off' comments (or disguised standalone: previous leaf missing or whitespace) and skips inline trailing '# fmt: off' comments (black.py lines ~2567-2578).'
Validating todo item 4 of 17
description: 'Check convert_one_fmt_off_pair() builds hidden_value that concatenates the '# fmt: off' line plus the exact string of all ignored nodes up to '# fmt: on', and trims a trailing newline if present to avoid adding an extra blank line (black.py lines ~2584-2591).'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair() constructs hidden_value as comment.value + "\n" + "".join(str(n) for n in ignored_nodes) and then trims a trailing newline if present. Verified at lines 2584-2591, which match the requirement to concatenate the '# fmt: off' line with ignored content up to '# fmt: on' and avoid an extra blank line.


Todo item 4 of 17 is correct
description: 'Check convert_one_fmt_off_pair() builds hidden_value that concatenates the '# fmt: off' line plus the exact string of all ignored nodes up to '# fmt: on', and trims a trailing newline if present to avoid adding an extra blank line (black.py lines ~2584-2591).'
Validating todo item 5 of 17
description: 'Validate convert_one_fmt_off_pair() updates prefixes correctly: sets first.prefix = prefix[comment.consumed:] to drop the consumed part, and computes the new STANDALONE_COMMENT prefix as prefix[:previous_consumed] + '\n' * comment.newlines (black.py lines ~2582-2586 and ~2601-2605).'
Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), the code sets first.prefix = prefix[comment.consumed:] and constructs the new STANDALONE_COMMENT Leaf with prefix=prefix[:previous_consumed] + "\n" * comment.newlines (lines 2582-2586 and 2601-2605), matching the requirement.


Todo item 5 of 17 is correct
description: 'Validate convert_one_fmt_off_pair() updates prefixes correctly: sets first.prefix = prefix[comment.consumed:] to drop the consumed part, and computes the new STANDALONE_COMMENT prefix as prefix[:previous_consumed] + '\n' * comment.newlines (black.py lines ~2582-2586 and ~2601-2605).'
Validating todo item 6 of 17
description: 'Verify convert_one_fmt_off_pair() removes all ignored nodes and inserts a single STANDALONE_COMMENT leaf at the correct index in the parent, and returns True to allow repeated conversion (black.py lines ~2591-2606).'
Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair() gathers ignored_nodes, removes each via ignored.remove(), records the first removal index, and inserts a single STANDALONE_COMMENT leaf at that index with the correct prefix. It then returns True, enabling normalize_fmt_off() to repeat conversion until all pairs are processed.


Todo item 6 of 17 is correct
description: 'Verify convert_one_fmt_off_pair() removes all ignored nodes and inserts a single STANDALONE_COMMENT leaf at the correct index in the parent, and returns True to allow repeated conversion (black.py lines ~2591-2606).'
Validating todo item 7 of 17
description: 'Confirm generate_ignored_nodes() starts from container_of(leaf) and yields sequential sibling containers until an '# fmt: on' comment is encountered or until ENDMARKER, ensuring content can span multiple top-level statements and functions (black.py lines ~2613-2627).'
Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2613-2627, generate_ignored_nodes() initializes from container_of(leaf) and iterates container.next_sibling, yielding each container until it encounters an FMT_ON comment (then returns) or reaches a token.ENDMARKER. container_of() (lines 1837-1859) also stops ascending at syms.file_input, enabling traversal across multiple top-level siblings, satisfying the requirement.


Todo item 7 of 17 is correct
description: 'Confirm generate_ignored_nodes() starts from container_of(leaf) and yields sequential sibling containers until an '# fmt: on' comment is encountered or until ENDMARKER, ensuring content can span multiple top-level statements and functions (black.py lines ~2613-2627).'
Validating todo item 8 of 17
description: 'Confirm container_of() stops ascending at syms.file_input and at SURROUNDED_BY_BRACKETS to prevent over-climbing past the module root or into bracket pairs (black.py lines ~1852-1856).'
Calling tool: grepTool
def container_of\(leaf: Leaf\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, container_of() now includes explicit stops: it breaks when parent.type == syms.file_input and when parent.type is in SURROUNDED_BY_BRACKETS (lines 1852-1856). This ensures it doesnt climb past the module root or into bracketed constructs, satisfying the todo requirement.


Todo item 8 of 17 is correct
description: 'Confirm container_of() stops ascending at syms.file_input and at SURROUNDED_BY_BRACKETS to prevent over-climbing past the module root or into bracket pairs (black.py lines ~1852-1856).'
Validating todo item 9 of 17
description: 'Ensure exception-based fmt on/off handling was removed: classes FormatError, FormatOn, and FormatOff no longer exist; generate_comments() no longer raises these exceptions; LineGenerator.visit/visit_default no longer has try/except for FormatOn/Off; UnformattedLines and visit_unformatted() are removed; split_line() no longer checks for UnformattedLines; EmptyLineTracker no longer special-cases UnformattedLines.'
Calling tool: grepTool
class FormatError|class FormatOn|class FormatOff|def generate_comments\(|class LineGenerator|UnformattedLines|visit_unformatted|def split_line\(|class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        : Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=)
1566:        self.visit_expr_stmt = partial(v, keywords=, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:
1630:                    return NO
1631:
1632:                elif prevp.parent.type == syms.typedargslist:
1633:                    # A bit hacky: if the equal sign has whitespace, it means we
1634:                    # previously found it's a typed argument.  So, we're using
1635:                    # that, too.
1636:                    return prevp.prefix
1637:
1638:        elif prevp.type in STARS:
1639:            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1640:                return NO
1641:
1642:        elif prevp.type == token.COLON:
1643:            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:
1644:                return SPACE if complex_subscript else NO
1645:
1646:        elif (
1647:            prevp.parent
1648:            and prevp.parent.type == syms.factor
1649:            and prevp.type in MATH_OPERATORS
1650:        ):
1651:            return NO
1652:
1653:        elif (
1654:            prevp.type == token.RIGHTSHIFT
1655:            and prevp.parent
1656:            and prevp.parent.type == syms.shift_expr
1657:            and prevp.prev_sibling
1658:            and prevp.prev_sibling.type == token.NAME
1659:            and prevp.prev_sibling.value == "print"  # type: ignore
1660:        ):
1661:            # Python 2 print chevron
1662:            return NO
1663:
1664:    elif prev.type in OPENING_BRACKETS:
1665:        return NO
1666:
1667:    if p.type in {syms.parameters, syms.arglist}:
1668:        # untyped function signatures or calls
1669:        if not prev or prev.type != token.COMMA:
1670:            return NO
1671:
1672:    elif p.type == syms.varargslist:
1673:        # lambdas
1674:        if prev and prev.type != token.COMMA:
1675:            return NO
1676:
1677:    elif p.type == syms.typedargslist:
1678:        # typed function signatures
1679:        if not prev:
1680:            return NO
1681:
1682:        if t == token.EQUAL:
1683:            if prev.type != syms.tname:
1684:                return NO
1685:
1686:        elif prev.type == token.EQUAL:
1687:            # A bit hacky: if the equal sign has whitespace, it means we
1688:            # previously found it's a typed argument.  So, we're using that, too.
1689:            return prev.prefix
1690:
1691:        elif prev.type != token.COMMA:
1692:            return NO
1693:
1694:    elif p.type == syms.tname:
1695:        # type names
1696:        if not prev:
1697:            prevp = preceding_leaf(p)
1698:            if not prevp or prevp.type != token.COMMA:
1699:                return NO
1700:
1701:    elif p.type == syms.trailer:
1702:        # attributes and calls
1703:        if t == token.LPAR or t == token.RPAR:
1704:            return NO
1705:
1706:        if not prev:
1707:            if t == token.DOT:
1708:                prevp = preceding_leaf(p)
1709:                if not prevp or prevp.type != token.NUMBER:
1710:                    return NO
1711:
1712:            elif t == token.LSQB:
1713:                return NO
1714:
1715:        elif prev.type != token.COMMA:
1716:            return NO
1717:
1718:    elif p.type == syms.argument:
1719:        # single argument

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.

Calling tool: grepTool
class UnformattedLines|def visit_unformatted\(|UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class FormatError|class FormatOn|class FormatOff
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def visit\(self, node: LN\)
Matched content:
685:    def visit(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")
680:
681:
682:class Visitor(Generic[T]):
683:    """Basic lib2to3 visitor that yields things of type `T` on `visit()`."""
684:
685:    def visit(self, node: LN) -> Iterator[T]:
686:        """Main method to visit `node` and its children.
687:
688:        It tries to find a `visit_*()` method for the given `node.type`, like
689:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):
710:    tree_depth: int = 0
711:
712:    def visit_default(self, node: LN) -> Iterator[T]:
713:        indent = " " * (2 * self.tree_depth)
714:        if isinstance(node, Node):
715:            _type = type_repr(node.type)
716:            out(f"{indent}{_type}", fg="yellow")
717:            self.tree_depth += 1
718:            for child in node.children:
719:                yield from self.visit(child)

Calling tool: grepTool
FormatError|FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
try:|except FormatOn|except FormatOff
Matched content:
148:    try:
301:    try:
306:    try:
342:        try:
378:    try:
453:        try:
495:    try:
512:        try:
542:    try:
653:        try:
660:            try:
1082:        try:
1087:        try:
1819:            try:
2101:        try:
2230:        try:
2306:    try:
2312:    try:
2328:        try:
2374:        try:
2786:    try:
2814:    try:
2959:        try:
3113:            try:
3133:    try:
3143:    try:
3217:    try:
3440:        try:
3475:    try:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py: classes FormatError/FormatOn/FormatOff are removed; generate_comments() (lines ~1971-1992) just yields comments and no longer raises; LineGenerator no longer overrides visit and visit_default (lines ~1422-1448) contain no try/except for FormatOn/Off; UnformattedLines class and visit_unformatted() are absent; split_line() (lines ~2051-2066) no longer checks UnformattedLines; EmptyLineTracker.maybe_empty_lines() (lines ~1297-1307) has no UnformattedLines special case.


Todo item 9 of 17 is correct
description: 'Ensure exception-based fmt on/off handling was removed: classes FormatError, FormatOn, and FormatOff no longer exist; generate_comments() no longer raises these exceptions; LineGenerator.visit/visit_default no longer has try/except for FormatOn/Off; UnformattedLines and visit_unformatted() are removed; split_line() no longer checks for UnformattedLines; EmptyLineTracker no longer special-cases UnformattedLines.'
Validating todo item 10 of 17
description: 'Verify generate_comments() now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and never raises on FMT_ON/FMT_OFF (black.py lines ~1971-1991).'
Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(

Calling tool: grepTool
FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched for generate_comments and inspected black.py lines 19711991. The function now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and contains no logic to raise on FMT_ON/FMT_OFF. Grepping the code confirms FormatOn/FormatOff classes are not used in black.py anymore.


Todo item 10 of 17 is correct
description: 'Verify generate_comments() now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and never raises on FMT_ON/FMT_OFF (black.py lines ~1971-1991).'
Validating todo item 11 of 17
description: 'Verify LineGenerator has visit_STANDALONE_COMMENT() that yields a line break if not inside brackets before visiting the comment leaf (black.py lines ~1544-1547).'
Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
class LineGenerator\(
Matched content:
1394:class LineGenerator(Visitor[Line]):

Calling tool: grepTool
def visit_STANDALONE_COMMENT\(
Matched content:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        : Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, LineGenerator defines visit_STANDALONE_COMMENT at lines 1544-1547. It checks if no brackets are open and yields a line break (yield from self.line()) before delegating to visit_default(leaf), matching the requirement.


Todo item 11 of 17 is correct
description: 'Verify LineGenerator has visit_STANDALONE_COMMENT() that yields a line break if not inside brackets before visiting the comment leaf (black.py lines ~1544-1547).'
Validating todo item 12 of 17
description: 'Check Line and whitespace handling for STANDALONE_COMMENT: ALWAYS_NO_SPACE includes STANDALONE_COMMENT; Line.is_comment returns True for a line with a single STANDALONE_COMMENT leaf; split_line() short-circuits when line.is_comment is True (black.py lines ~1578-1597, 1049-1052, and 2064-2066).'
Calling tool: grepTool
ALWAYS_NO_SPACE
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1593:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:14:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:67:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:111:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:162:    if t in ALWAYS_NO_SPACE:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1568:        self.visit_import_from = partial(v, keywords=, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:

Calling tool: grepTool
def is_comment|is_comment =
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified three requirements: 1) ALWAYS_NO_SPACE includes STANDALONE_COMMENT at black.py:1578; 2) Line.is_comment returns True for a single STANDALONE_COMMENT leaf at black.py:1049-1052; 3) split_line() short-circuits on line.is_comment at black.py:2064-2066. All implementations are present and correct.


Todo item 12 of 17 is correct
description: 'Check Line and whitespace handling for STANDALONE_COMMENT: ALWAYS_NO_SPACE includes STANDALONE_COMMENT; Line.is_comment returns True for a line with a single STANDALONE_COMMENT leaf; split_line() short-circuits when line.is_comment is True (black.py lines ~1578-1597, 1049-1052, and 2064-2066).'
Validating todo item 13 of 17
description: 'Validate EmptyLineTracker._maybe_empty_lines_for_class_or_def() avoids inserting empty lines when the previous line is a standalone comment at the same depth (black.py lines ~1365-1370).'
Calling tool: grepTool
class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)

Calling tool: grepTool
class Line|def is_comment|@property\n\s+def is_comment
Grep command failed with exit code 2: rg: the literal "\n" is not allowed in a regex

Consider enabling multiline mode with the --multiline flag (or -U for short).
When multiline mode is enabled, new line characters can be matched.


Calling tool: grepTool
(?i)is_comment
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2064:    if line.is_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, EmptyLineTracker._maybe_empty_lines_for_class_or_def includes a condition (lines 1365-1370) that checks if the previous line is a standalone comment at the same depth and if there are no pre-existing blank lines (before == 0). It then returns (0, 0), ensuring no empty lines are inserted. This matches the requirement.


Todo item 13 of 17 is correct
description: 'Validate EmptyLineTracker._maybe_empty_lines_for_class_or_def() avoids inserting empty lines when the previous line is a standalone comment at the same depth (black.py lines ~1365-1370).'
Validating todo item 14 of 17
description: 'Ensure FMT_OFF and FMT_ON sets are defined and include '# fmt: off/on' and Yapf equivalents '# yapf: disable/enable' (black.py lines ~1967-1968).'
Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 1967-1968, FMT_OFF and FMT_ON are defined and include '# fmt: off', '# fmt: on', and Yapf equivalents '# yapf: disable' and '# yapf: enable' (plus compact variants). Verified via grep and reading those lines.


Todo item 14 of 17 is correct
description: 'Ensure FMT_OFF and FMT_ON sets are defined and include '# fmt: off/on' and Yapf equivalents '# yapf: disable/enable' (black.py lines ~1967-1968).'
Validating todo item 15 of 17
description: 'Confirm that tests/data/fmtonoff2.py contains no '# output' marker so expected == input per read_data(); tests/test_black.py:test_fmtonoff2 reads 'fmtonoff2' and asserts formatted output equals expected (tests/test_black.py lines ~404-409 and read_data implementation lines ~34-54).'
Calling tool: grepTool
def test_fmtonoff2\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: globTool
**/tests/data/fmtonoff2.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified tests/data/fmtonoff2.py has no '# output' marker. read_data() (tests/test_black.py:34-54) therefore sets expected == input. test_fmtonoff2 (tests/test_black.py:404-409) reads 'fmtonoff2' and asserts formatted output equals expected. All conditions satisfied.


Todo item 15 of 17 is correct
description: 'Confirm that tests/data/fmtonoff2.py contains no '# output' marker so expected == input per read_data(); tests/test_black.py:test_fmtonoff2 reads 'fmtonoff2' and asserts formatted output equals expected (tests/test_black.py lines ~404-409 and read_data implementation lines ~34-54).'
Validating todo item 16 of 17
description: 'Double-check that there are no remaining references to deleted UnformattedLines, FormatOn, or FormatOff identifiers anywhere in the codebase (grep for these names should yield no uses).'
Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
FormatOn
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn

Calling tool: grepTool
FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
\b(UnformattedLines|FormatOn|FormatOff)\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: Global grep shows remaining references in docs: UnformattedLines in docs/reference/reference_classes.rst and FormatOn/FormatOff in docs/reference/reference_exceptions.rst. The requirement said grep should yield no uses anywhere in the codebase.


Validating todo item 1 of 17
description: 'Verify format_str() calls normalize_fmt_off(src_node) before constructing LineGenerator and emitting lines (in black.py around lines 596-609).'

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
def format_str\(
Matched content:
589:def format_str(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 596-609, format_str() calls normalize_fmt_off(src_node) at line 602 before constructing LineGenerator (line 603) and emitting lines, satisfying the requirement.

Todo item 1 of 17 is correct
description: 'Verify format_str() calls normalize_fmt_off(src_node) before constructing LineGenerator and emitting lines (in black.py around lines 596-609).'

Validating todo item 2 of 17
description: 'Confirm new preprocessing pass exists: functions normalize_fmt_off(), convert_one_fmt_off_pair(), and generate_ignored_nodes() are defined and used, with normalize_fmt_off() looping until convert_one_fmt_off_pair() returns False.'

Calling tool: grepTool
def normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: grepTool
(?<!def )normalize_fmt_off\(
Grep command failed with exit code 2: rg: regex parse error:
    (?:(?<!def )normalize_fmt_off\()
       ^^^^
error: look-around, including look-ahead and look-behind, is not supported

Consider enabling PCRE2 with the --pcre2 flag, which can handle backreferences
and look-around.


Calling tool: grepTool
normalize_fmt_off\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:602:    normalize_fmt_off(src_node)
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2555:def normalize_fmt_off(node: Node) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
560:        f.detach()
561:
562:
563:def format_file_contents(
564:    src_contents: str,
565:    *,
566:    line_length: int,
567:    fast: bool,
568:    mode: FileMode = FileMode.AUTO_DETECT,
569:) -> FileContent:
570:    """Reformat contents a file and return new contents.
571:
572:    If `fast` is False, additionally confirm that the reformatted code is
573:    valid by calling :func:`assert_equivalent` and :func:`assert_stable` on it.
574:    `line_length` is passed to :func:`format_str`.
575:    """
576:    if src_contents.strip() == "":
577:        raise NothingChanged
578:
579:    dst_contents = format_str(src_contents, line_length=line_length, mode=mode)
580:    if src_contents == dst_contents:
581:        raise NothingChanged
582:
583:    if not fast:
584:        assert_equivalent(src_contents, dst_contents)
585:        assert_stable(src_contents, dst_contents, line_length=line_length, mode=mode)
586:    return dst_contents
587:
588:
589:def format_str(
590:    src_contents: str, line_length: int, *, mode: FileMode = FileMode.AUTO_DETECT
591:) -> FileContent:
592:    """Reformat a string and return new contents.
593:
594:    `line_length` determines how many characters per line are allowed.
595:    """
596:    src_node = lib2to3_parse(src_contents)
597:    dst_contents = ""
598:    future_imports = get_future_imports(src_node)
599:    is_pyi = bool(mode & FileMode.PYI)
600:    py36 = bool(mode & FileMode.PYTHON36) or is_python36(src_node)
601:    normalize_strings = not bool(mode & FileMode.NO_STRING_NORMALIZATION)
602:    normalize_fmt_off(src_node)
603:    lines = LineGenerator(
604:        remove_u_prefix=py36 or "unicode_literals" in future_imports,
605:        is_pyi=is_pyi,
606:        normalize_strings=normalize_strings,
607:    )
608:    elt = EmptyLineTracker(is_pyi=is_pyi)
609:    empty_line = Line()
610:    after = 0
611:    for current_line in lines.visit(src_node):
612:        for _ in range(after):
613:            dst_contents += str(empty_line)
614:        before, after = elt.maybe_empty_lines(current_line)
615:        for _ in range(before):
616:            dst_contents += str(empty_line)
617:        for line in split_line(current_line, line_length=line_length, py36=py36):
618:            dst_contents += str(line)
619:    return dst_contents
620:
621:
622:def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
623:    """Return a tuple of (decoded_contents, encoding, newline).
624:
625:    `newline` is either CRLF or LF but `decoded_contents` is decoded with
626:    universal newlines (i.e. only contains LF).
627:    """
628:    srcbuf = io.BytesIO(src)
629:    encoding, lines = tokenize.detect_encoding(srcbuf.readline)
630:    if not lines:
631:        return "", encoding, "\n"
632:
633:    newline = "\r\n" if b"\r\n" == lines[0][-2:] else "\n"
634:    srcbuf.seek(0)
635:    with io.TextIOWrapper(srcbuf, encoding) as tiow:
636:        return tiow.read(), encoding, newline
637:
638:
639:GRAMMARS = [
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, normalize_fmt_off() is defined (line ~2555) and is called in format_str() (line ~602). normalize_fmt_off() loops with while try_again: try_again = convert_one_fmt_off_pair(node). convert_one_fmt_off_pair() is defined (line ~2562) and uses generate_ignored_nodes(), which is defined (line ~2613). This matches the requirement.

Todo item 2 of 17 is correct
description: 'Confirm new preprocessing pass exists: functions normalize_fmt_off(), convert_one_fmt_off_pair(), and generate_ignored_nodes() are defined and used, with normalize_fmt_off() looping until convert_one_fmt_off_pair() returns False.'

Validating todo item 3 of 17
description: 'Check convert_one_fmt_off_pair() only triggers on standalone '# fmt: off' comments (or disguised standalone: previous leaf missing or whitespace) and skips inline trailing '# fmt: off' comments (black.py lines ~2567-2578).'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom

Calling tool: grepTool
def preceding_leaf\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1805:    elif p.type == syms.sliceop:
1806:        return NO
1807:
1808:    return SPACE
1809:
1810:
1811:def preceding_leaf(node: Optional[LN]) -> Optional[Leaf]:
1812:    """Return the first leaf that precedes `node`, if any."""
1813:    while node:
1814:        res = node.prev_sibling
1815:        if res:
1816:            if isinstance(res, Leaf):
1817:                return res
1818:
1819:            try:
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:

Calling tool: grepTool
WHITESPACE\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
735:
736:        Convenience method for debugging.
737:        """
738:        v: DebugVisitor[None] = DebugVisitor()
739:        if isinstance(code, str):
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}

Calling tool: grepTool
def list_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):

Calling tool: grepTool
FMT_OFF\s*=
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py convert_one_fmt_off_pair(), lines 25712577 ensure only standalone fmt-off comments trigger: if the comment isnt STANDALONE_COMMENT, it checks the preceding leaf and continues (skips) when a non-whitespace previous leaf exists, thereby ignoring inline trailing '# fmt: off' while allowing standalone or disguised standalone (no prev or whitespace).

Todo item 3 of 17 is correct
description: 'Check convert_one_fmt_off_pair() only triggers on standalone '# fmt: off' comments (or disguised standalone: previous leaf missing or whitespace) and skips inline trailing '# fmt: off' comments (black.py lines ~2567-2578).'

Validating todo item 4 of 17
description: 'Check convert_one_fmt_off_pair() builds hidden_value that concatenates the '# fmt: off' line plus the exact string of all ignored nodes up to '# fmt: on', and trims a trailing newline if present to avoid adding an extra blank line (black.py lines ~2584-2591).'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair() constructs hidden_value as comment.value + "\n" + "".join(str(n) for n in ignored_nodes) and then trims a trailing newline if present. Verified at lines 2584-2591, which match the requirement to concatenate the '# fmt: off' line with ignored content up to '# fmt: on' and avoid an extra blank line.

Todo item 4 of 17 is correct
description: 'Check convert_one_fmt_off_pair() builds hidden_value that concatenates the '# fmt: off' line plus the exact string of all ignored nodes up to '# fmt: on', and trims a trailing newline if present to avoid adding an extra blank line (black.py lines ~2584-2591).'

Validating todo item 5 of 17
description: 'Validate convert_one_fmt_off_pair() updates prefixes correctly: sets first.prefix = prefix[comment.consumed:] to drop the consumed part, and computes the new STANDALONE_COMMENT prefix as prefix[:previous_consumed] + '\n' * comment.newlines (black.py lines ~2582-2586 and ~2601-2605).'

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In convert_one_fmt_off_pair(), the code sets first.prefix = prefix[comment.consumed:] and constructs the new STANDALONE_COMMENT Leaf with prefix=prefix[:previous_consumed] + "\n" * comment.newlines (lines 2582-2586 and 2601-2605), matching the requirement.

Todo item 5 of 17 is correct
description: 'Validate convert_one_fmt_off_pair() updates prefixes correctly: sets first.prefix = prefix[comment.consumed:] to drop the consumed part, and computes the new STANDALONE_COMMENT prefix as prefix[:previous_consumed] + '\n' * comment.newlines (black.py lines ~2582-2586 and ~2601-2605).'

Validating todo item 6 of 17
description: 'Verify convert_one_fmt_off_pair() removes all ignored nodes and inserts a single STANDALONE_COMMENT leaf at the correct index in the parent, and returns True to allow repeated conversion (black.py lines ~2591-2606).'

Calling tool: grepTool
def convert_one_fmt_off_pair\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2562:def convert_one_fmt_off_pair(node: Node) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, convert_one_fmt_off_pair() gathers ignored_nodes, removes each via ignored.remove(), records the first removal index, and inserts a single STANDALONE_COMMENT leaf at that index with the correct prefix. It then returns True, enabling normalize_fmt_off() to repeat conversion until all pairs are processed.

Todo item 6 of 17 is correct
description: 'Verify convert_one_fmt_off_pair() removes all ignored nodes and inserts a single STANDALONE_COMMENT leaf at the correct index in the parent, and returns True to allow repeated conversion (black.py lines ~2591-2606).'

Validating todo item 7 of 17
description: 'Confirm generate_ignored_nodes() starts from container_of(leaf) and yields sequential sibling containers until an '# fmt: on' comment is encountered or until ENDMARKER, ensuring content can span multiple top-level statements and functions (black.py lines ~2613-2627).'

Calling tool: grepTool
def generate_ignored_nodes\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])
2648:        return True
2649:
2650:    return False
2651:
2652:
2653:def is_empty_tuple(node: LN) -> bool:
2654:    """Return True if `node` holds an empty tuple."""
2655:    return (
2656:        node.type == syms.atom
2657:        and len(node.children) == 2
2658:        and node.children[0].type == token.LPAR
2659:        and node.children[1].type == token.RPAR
2660:    )
2661:
2662:
2663:def is_one_tuple(node: LN) -> bool:
2664:    """Return True if `node` holds a tuple with one element, with or without parens."""
2665:    if node.type == syms.atom:
2666:        if len(node.children) != 3:
2667:            return False
2668:
2669:        lpar, gexp, rpar = node.children
2670:        if not (
2671:            lpar.type == token.LPAR
2672:            and gexp.type == syms.testlist_gexp
2673:            and rpar.type == token.RPAR
2674:        ):
2675:            return False
2676:
2677:        return len(gexp.children) == 2 and gexp.children[1].type == token.COMMA
2678:
2679:    return (
2680:        node.type in IMPLICIT_TUPLE
2681:        and len(node.children) == 2
2682:        and node.children[1].type == token.COMMA
2683:    )
2684:
2685:
2686:def is_yield(node: LN) -> bool:
2687:    """Return True if `node` holds a `yield` or `yield from` expression."""
2688:    if node.type == syms.yield_expr:
2689:        return True
2690:
2691:    if node.type == token.NAME and node.value == "yield":  # type: ignore
2692:        return True
2693:
2694:    if node.type != syms.atom:
2695:        return False
2696:
2697:    if len(node.children) != 3:
2698:        return False
2699:

Calling tool: grepTool
def container_of\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 2613-2627, generate_ignored_nodes() initializes from container_of(leaf) and iterates container.next_sibling, yielding each container until it encounters an FMT_ON comment (then returns) or reaches a token.ENDMARKER. container_of() (lines 1837-1859) also stops ascending at syms.file_input, enabling traversal across multiple top-level siblings, satisfying the requirement.

Todo item 7 of 17 is correct
description: 'Confirm generate_ignored_nodes() starts from container_of(leaf) and yields sequential sibling containers until an '# fmt: on' comment is encountered or until ENDMARKER, ensuring content can span multiple top-level statements and functions (black.py lines ~2613-2627).'

Validating todo item 8 of 17
description: 'Confirm container_of() stops ascending at syms.file_input and at SURROUNDED_BY_BRACKETS to prevent over-climbing past the module root or into bracket pairs (black.py lines ~1852-1856).'

Calling tool: grepTool
def container_of\(leaf: Leaf\)
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1837:def container_of(leaf: Leaf) -> LN:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1820:                return list(res.leaves())[-1]
1821:
1822:            except IndexError:
1823:                return None
1824:
1825:        node = node.parent
1826:    return None
1827:
1828:
1829:def child_towards(ancestor: Node, descendant: LN) -> Optional[LN]:
1830:    """Return the child of `ancestor` that contains `descendant`."""
1831:    node: Optional[LN] = descendant
1832:    while node and node.parent != ancestor:
1833:        node = node.parent
1834:    return node
1835:
1836:
1837:def container_of(leaf: Leaf) -> LN:
1838:    """Return `leaf` or one of its ancestors that is the topmost container of it.
1839:
1840:    By "container" we mean a node where `leaf` is the very first child.
1841:    """
1842:    same_prefix = leaf.prefix
1843:    container: LN = leaf
1844:    while container:
1845:        parent = container.parent
1846:        if parent is None:
1847:            break
1848:
1849:        if parent.children[0].prefix != same_prefix:
1850:            break
1851:
1852:        if parent.type == syms.file_input:
1853:            break
1854:
1855:        if parent.type in SURROUNDED_BY_BRACKETS:
1856:            break
1857:
1858:        container = parent
1859:    return container
1860:
1861:
1862:def is_split_after_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1863:    """Return the priority of the `leaf` delimiter, given a line break after it.
1864:
1865:    The delimiter priorities returned here are from those delimiters that would
1866:    cause a line break after themselves.
1867:
1868:    Higher numbers are higher priority.
1869:    """
1870:    if leaf.type == token.COMMA:
1871:        return COMMA_PRIORITY
1872:
1873:    return 0
1874:
1875:
1876:def is_split_before_delimiter(leaf: Leaf, previous: Leaf = None) -> int:
1877:    """Return the priority of the `leaf` delimiter, given a line before after it.
1878:
1879:    The delimiter priorities returned here are from those delimiters that would
1880:    cause a line break before themselves.
1881:
1882:    Higher numbers are higher priority.
1883:    """
1884:    if is_vararg(leaf, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1885:        # * and ** might also be MATH_OPERATORS but in this case they are not.
1886:        # Don't treat them as a delimiter.
1887:        return 0
1888:
1889:    if (
1890:        leaf.type == token.DOT
1891:        and leaf.parent
1892:        and leaf.parent.type not in {syms.import_from, syms.dotted_name}
1893:        and (previous is None or previous.type in CLOSING_BRACKETS)
1894:    ):
1895:        return DOT_PRIORITY
1896:
1897:    if (
1898:        leaf.type in MATH_OPERATORS
1899:        and leaf.parent

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, container_of() now includes explicit stops: it breaks when parent.type == syms.file_input and when parent.type is in SURROUNDED_BY_BRACKETS (lines 1852-1856). This ensures it doesnt climb past the module root or into bracketed constructs, satisfying the todo requirement.

Todo item 8 of 17 is correct
description: 'Confirm container_of() stops ascending at syms.file_input and at SURROUNDED_BY_BRACKETS to prevent over-climbing past the module root or into bracket pairs (black.py lines ~1852-1856).'

Validating todo item 9 of 17
description: 'Ensure exception-based fmt on/off handling was removed: classes FormatError, FormatOn, and FormatOff no longer exist; generate_comments() no longer raises these exceptions; LineGenerator.visit/visit_default no longer has try/except for FormatOn/Off; UnformattedLines and visit_unformatted() are removed; split_line() no longer checks for UnformattedLines; EmptyLineTracker no longer special-cases UnformattedLines.'

Calling tool: grepTool
class FormatError|class FormatOn|class FormatOff|def generate_comments\(|class LineGenerator|UnformattedLines|visit_unformatted|def split_line\(|class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1394:class LineGenerator(Visitor[Line]):
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return
1230:
1231:        for index, comment_after in self.comments:
1232:            if _index == index:
1233:                yield comment_after
1234:
1235:    def remove_trailing_comma(self) -> None:
1236:        """Remove the trailing comma and moves the comments attached to it."""
1237:        comma_index = len(self.leaves) - 1
1238:        for i in range(len(self.comments)):
1239:            comment_index, comment = self.comments[i]
1240:            if comment_index == comma_index:
1241:                self.comments[i] = (comma_index - 1, comment)
1242:        self.leaves.pop()
1243:
1244:    def is_complex_subscript(self, leaf: Leaf) -> bool:
1245:        """Return True iff `leaf` is part of a slice with non-trivial exprs."""
1246:        open_lsqb = self.bracket_tracker.get_open_lsqb()
1247:        if open_lsqb is None:
1248:            return False
1249:
1250:        subscript_start = open_lsqb.next_sibling
1251:
1252:        if isinstance(subscript_start, Node):
1253:            if subscript_start.type == syms.listmaker:
1254:                return False
1255:
1256:            if subscript_start.type == syms.subscriptlist:
1257:                subscript_start = child_towards(subscript_start, leaf)
1258:        return subscript_start is not None and any(
1259:            n.type in TEST_DESCENDANTS for n in subscript_start.pre_order()
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)
1420:        yield complete_line
1421:
1422:    def visit_default(self, node: LN) -> Iterator[Line]:
1423:        """Default `visit_*()` implementation. Recurses to children of `node`."""
1424:        if isinstance(node, Leaf):
1425:            any_open_brackets = self.current_line.bracket_tracker.any_open_brackets()
1426:            for comment in generate_comments(node):
1427:                if any_open_brackets:
1428:                    # any comment within brackets is subject to splitting
1429:                    self.current_line.append(comment)
1430:                elif comment.type == token.COMMENT:
1431:                    # regular trailing comment
1432:                    self.current_line.append(comment)
1433:                    yield from self.line()
1434:
1435:                else:
1436:                    # regular standalone comment
1437:                    yield from self.line()
1438:
1439:                    self.current_line.append(comment)

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1440:                    yield from self.line()
1441:
1442:            normalize_prefix(node, inside_brackets=any_open_brackets)
1443:            if self.normalize_strings and node.type == token.STRING:
1444:                normalize_string_prefix(node, remove_u_prefix=self.remove_u_prefix)
1445:                normalize_string_quotes(node)
1446:            if node.type not in WHITESPACE:
1447:                self.current_line.append(node)
1448:        yield from super().visit_default(node)
1449:
1450:    def visit_INDENT(self, node: Node) -> Iterator[Line]:
1451:        """Increase indentation level, maybe yield a line."""
1452:        # In blib2to3 INDENT never holds comments.
1453:        yield from self.line(+1)
1454:        yield from self.visit_default(node)
1455:
1456:    def visit_DEDENT(self, node: Node) -> Iterator[Line]:
1457:        """Decrease indentation level, maybe yield a line."""
1458:        # The current line might still wait for trailing comments.  At DEDENT time
1459:        # there won't be any (they would be prefixes on the preceding NEWLINE).
1460:        # Emit the line then.
1461:        yield from self.line()
1462:
1463:        # While DEDENT has no value, its prefix may contain standalone comments
1464:        # that belong to the current indentation level.  Get 'em.
1465:        yield from self.visit_default(node)
1466:
1467:        # Finally, emit the dedent.
1468:        yield from self.line(-1)
1469:
1470:    def visit_stmt(
1471:        self, node: Node, keywords: Set[str], parens: Set[str]
1472:    ) -> Iterator[Line]:
1473:        """Visit a statement.
1474:
1475:        This implementation is shared for `if`, `while`, `for`, `try`, `except`,
1476:        `def`, `with`, `class`, `assert` and assignments.
1477:
1478:        The relevant Python language `keywords` for a given statement will be
1479:        NAME leaves within it. This methods puts those on a separate line.
1480:
1481:        `parens` holds a set of string leaf values immediately after which
1482:        invisible parens should be put.
1483:        """
1484:        normalize_invisible_parens(node, parens_after=parens)
1485:        for child in node.children:
1486:            if child.type == token.NAME and child.value in keywords:  # type: ignore
1487:                yield from self.line()
1488:
1489:            yield from self.visit(child)
1490:
1491:    def visit_suite(self, node: Node) -> Iterator[Line]:
1492:        """Visit a suite."""
1493:        if self.is_pyi and is_stub_suite(node):
1494:            yield from self.visit(node.children[2])
1495:        else:
1496:            yield from self.visit_default(node)
1497:
1498:    def visit_simple_stmt(self, node: Node) -> Iterator[Line]:
1499:        """Visit a statement without nested statements."""
1500:        is_suite_like = node.parent and node.parent.type in STATEMENT
1501:        if is_suite_like:
1502:            if self.is_pyi and is_stub_body(node):
1503:                yield from self.visit_default(node)
1504:            else:
1505:                yield from self.line(+1)
1506:                yield from self.visit_default(node)
1507:                yield from self.line(-1)
1508:
1509:        else:
1510:            if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):
1511:                yield from self.line()
1512:            yield from self.visit_default(node)
1513:
1514:    def visit_async_stmt(self, node: Node) -> Iterator[Line]:
1515:        """Visit `async def`, `async for`, `async with`."""
1516:        yield from self.line()
1517:
1518:        children = iter(node.children)
1519:        for child in children:
1520:            yield from self.visit(child)
1521:
1522:            if child.type == token.ASYNC:
1523:                break
1524:
1525:        internal_stmt = next(children)
1526:        for child in internal_stmt.children:
1527:            yield from self.visit(child)
1528:
1529:    def visit_decorators(self, node: Node) -> Iterator[Line]:
1530:        """Visit decorators."""
1531:        for child in node.children:
1532:            yield from self.line()
1533:            yield from self.visit(child)
1534:
1535:    def visit_SEMI(self, leaf: Leaf) -> Iterator[Line]:
1536:        """Remove a semicolon and put the other statement on a separate line."""
1537:        yield from self.line()
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        : Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})
1558:        self.visit_for_stmt = partial(v, keywords={"for", "else"}, parens={"for", "in"})
1559:        self.visit_try_stmt = partial(
1560:            v, keywords={"try", "except", "else", "finally"}, parens=
1561:        )
1562:        self.visit_except_clause = partial(v, keywords={"except"}, parens=)
1563:        self.visit_with_stmt = partial(v, keywords={"with"}, parens=)
1564:        self.visit_funcdef = partial(v, keywords={"def"}, parens=)
1565:        self.visit_classdef = partial(v, keywords={"class"}, parens=)
1566:        self.visit_expr_stmt = partial(v, keywords=, parens=ASSIGNMENTS)
1567:        self.visit_return_stmt = partial(v, keywords={"return"}, parens={"return"})
1568:        self.visit_import_from = partial(v, keywords=, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:
1618:                return NO
1619:
1620:            return SPACE
1621:
1622:        if prevp.type == token.EQUAL:
1623:            if prevp.parent:
1624:                if prevp.parent.type in {
1625:                    syms.arglist,
1626:                    syms.argument,
1627:                    syms.parameters,
1628:                    syms.varargslist,
1629:                }:
1630:                    return NO
1631:
1632:                elif prevp.parent.type == syms.typedargslist:
1633:                    # A bit hacky: if the equal sign has whitespace, it means we
1634:                    # previously found it's a typed argument.  So, we're using
1635:                    # that, too.
1636:                    return prevp.prefix
1637:
1638:        elif prevp.type in STARS:
1639:            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):
1640:                return NO
1641:
1642:        elif prevp.type == token.COLON:
1643:            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:
1644:                return SPACE if complex_subscript else NO
1645:
1646:        elif (
1647:            prevp.parent
1648:            and prevp.parent.type == syms.factor
1649:            and prevp.type in MATH_OPERATORS
1650:        ):
1651:            return NO
1652:
1653:        elif (
1654:            prevp.type == token.RIGHTSHIFT
1655:            and prevp.parent
1656:            and prevp.parent.type == syms.shift_expr
1657:            and prevp.prev_sibling
1658:            and prevp.prev_sibling.type == token.NAME
1659:            and prevp.prev_sibling.value == "print"  # type: ignore
1660:        ):
1661:            # Python 2 print chevron
1662:            return NO
1663:
1664:    elif prev.type in OPENING_BRACKETS:
1665:        return NO
1666:
1667:    if p.type in {syms.parameters, syms.arglist}:
1668:        # untyped function signatures or calls
1669:        if not prev or prev.type != token.COMMA:
1670:            return NO
1671:
1672:    elif p.type == syms.varargslist:
1673:        # lambdas
1674:        if prev and prev.type != token.COMMA:
1675:            return NO
1676:
1677:    elif p.type == syms.typedargslist:
1678:        # typed function signatures
1679:        if not prev:
1680:            return NO
1681:
1682:        if t == token.EQUAL:
1683:            if prev.type != syms.tname:
1684:                return NO
1685:
1686:        elif prev.type == token.EQUAL:
1687:            # A bit hacky: if the equal sign has whitespace, it means we
1688:            # previously found it's a typed argument.  So, we're using that, too.
1689:            return prev.prefix
1690:
1691:        elif prev.type != token.COMMA:
1692:            return NO
1693:
1694:    elif p.type == syms.tname:
1695:        # type names
1696:        if not prev:
1697:            prevp = preceding_leaf(p)
1698:            if not prevp or prevp.type != token.COMMA:
1699:                return NO
1700:
1701:    elif p.type == syms.trailer:
1702:        # attributes and calls
1703:        if t == token.LPAR or t == token.RPAR:
1704:            return NO
1705:
1706:        if not prev:
1707:            if t == token.DOT:
1708:                prevp = preceding_leaf(p)
1709:                if not prevp or prevp.type != token.NUMBER:
1710:                    return NO
1711:
1712:            elif t == token.LSQB:
1713:                return NO
1714:
1715:        elif prev.type != token.COMMA:
1716:            return NO
1717:
1718:    elif p.type == syms.argument:
1719:        # single argument

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1920:        and leaf.parent.type in {syms.comp_for, syms.old_comp_for}
1921:    ):
1922:        return COMPREHENSION_PRIORITY
1923:
1924:    if (
1925:        leaf.value == "if"
1926:        and leaf.parent
1927:        and leaf.parent.type in {syms.comp_if, syms.old_comp_if}
1928:    ):
1929:        return COMPREHENSION_PRIORITY
1930:
1931:    if leaf.value in {"if", "else"} and leaf.parent and leaf.parent.type == syms.test:
1932:        return TERNARY_PRIORITY
1933:
1934:    if leaf.value == "is":
1935:        return COMPARATOR_PRIORITY
1936:
1937:    if (
1938:        leaf.value == "in"
1939:        and leaf.parent
1940:        and leaf.parent.type in {syms.comp_op, syms.comparison}
1941:        and not (
1942:            previous is not None
1943:            and previous.type == token.NAME
1944:            and previous.value == "not"
1945:        )
1946:    ):
1947:        return COMPARATOR_PRIORITY
1948:
1949:    if (
1950:        leaf.value == "not"
1951:        and leaf.parent
1952:        and leaf.parent.type == syms.comp_op
1953:        and not (
1954:            previous is not None
1955:            and previous.type == token.NAME
1956:            and previous.value == "is"
1957:        )
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(
2025:                type=comment_type, value=comment, newlines=nlines, consumed=consumed
2026:            )
2027:        )
2028:        nlines = 0
2029:    return result
2030:
2031:
2032:def make_comment(content: str) -> str:
2033:    """Return a consistently formatted comment from the given `content` string.
2034:
2035:    All comments (except for "##", "#!", "#:") should have a single space between
2036:    the hash sign and the content.
2037:
2038:    If `content` didn't start with a hash sign, one is provided.
2039:    """
2040:    content = content.rstrip()
2041:    if not content:
2042:        return "#"
2043:
2044:    if content[0] == "#":
2045:        content = content[1:]
2046:    if content and content[0] not in " !:#":
2047:        content = " " + content
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.
2088:            # This mostly happens to multiline strings that are by definition
2089:            # reported as not fitting a single line.
2090:            yield from right_hand_split(line, py36)
2091:
2092:        if line.inside_brackets:
2093:            split_funcs = [delimiter_split, standalone_comment_split, rhs]
2094:        else:
2095:            split_funcs = [rhs]
2096:    for split_func in split_funcs:
2097:        # We are accumulating lines in `result` because we might want to abort
2098:        # mission and return the original line in the end, or attempt a different
2099:        # split altogether.

Calling tool: grepTool
class UnformattedLines|def visit_unformatted\(|UnformattedLines
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
class FormatError|class FormatOn|class FormatOff
No files found. Call grepTool again with a more generic pattern.

Calling tool: grepTool
def visit\(self, node: LN\)
Matched content:
685:    def visit(self, node: LN) -> Iterator[T]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
640:    pygram.python_grammar_no_print_statement_no_exec_statement,
641:    pygram.python_grammar_no_print_statement,
642:    pygram.python_grammar,
643:]
644:
645:
646:def lib2to3_parse(src_txt: str) -> Node:
647:    """Given a string with source, return the lib2to3 Node."""
648:    grammar = pygram.python_grammar_no_print_statement
649:    if src_txt[-1:] != "\n":
650:        src_txt += "\n"
651:    for grammar in GRAMMARS:
652:        drv = driver.Driver(grammar, pytree.convert)
653:        try:
654:            result = drv.parse_string(src_txt, True)
655:            break
656:
657:        except ParseError as pe:
658:            lineno, column = pe.context[1]
659:            lines = src_txt.splitlines()
660:            try:
661:                faulty_line = lines[lineno - 1]
662:            except IndexError:
663:                faulty_line = "<line number missing in source>"
664:            exc = ValueError(f"Cannot parse: {lineno}:{column}: {faulty_line}")
665:    else:
666:        raise exc from None
667:
668:    if isinstance(result, Leaf):
669:        result = Node(syms.file_input, [result])
670:    return result
671:
672:
673:def lib2to3_unparse(node: Node) -> str:
674:    """Given a lib2to3 node, return its string representation."""
675:    code = str(node)
676:    return code
677:
678:
679:T = TypeVar("T")
680:
681:
682:class Visitor(Generic[T]):
683:    """Basic lib2to3 visitor that yields things of type `T` on `visit()`."""
684:
685:    def visit(self, node: LN) -> Iterator[T]:
686:        """Main method to visit `node` and its children.
687:
688:        It tries to find a `visit_*()` method for the given `node.type`, like
689:        `visit_simple_stmt` for Node objects or `visit_INDENT` for Leaf objects.
690:        If no dedicated `visit_*()` method is found, chooses `visit_default()`
691:        instead.
692:
693:        Then yields objects of type `T` from the selected visitor.
694:        """
695:        if node.type < 256:
696:            name = token.tok_name[node.type]
697:        else:
698:            name = type_repr(node.type)
699:        yield from getattr(self, f"visit_{name}", self.visit_default)(node)
700:
701:    def visit_default(self, node: LN) -> Iterator[T]:
702:        """Default `visit_*()` implementation. Recurses to children of `node`."""
703:        if isinstance(node, Node):
704:            for child in node.children:
705:                yield from self.visit(child)
706:
707:
708:@dataclass
709:class DebugVisitor(Visitor[T]):
710:    tree_depth: int = 0
711:
712:    def visit_default(self, node: LN) -> Iterator[T]:
713:        indent = " " * (2 * self.tree_depth)
714:        if isinstance(node, Node):
715:            _type = type_repr(node.type)
716:            out(f"{indent}{_type}", fg="yellow")
717:            self.tree_depth += 1
718:            for child in node.children:
719:                yield from self.visit(child)

Calling tool: grepTool
FormatError|FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:10:.. autoexception:: black.FormatError
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
try:|except FormatOn|except FormatOff
Matched content:
148:    try:
301:    try:
306:    try:
342:        try:
378:    try:
453:        try:
495:    try:
512:        try:
542:    try:
653:        try:
660:            try:
1082:        try:
1087:        try:
1819:            try:
2101:        try:
2230:        try:
2306:    try:
2312:    try:
2328:        try:
2374:        try:
2786:    try:
2814:    try:
2959:        try:
3113:            try:
3133:    try:
3143:    try:
3217:    try:
3440:        try:
3475:    try:

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified in black.py: classes FormatError/FormatOn/FormatOff are removed; generate_comments() (lines ~1971-1992) just yields comments and no longer raises; LineGenerator no longer overrides visit and visit_default (lines ~1422-1448) contain no try/except for FormatOn/Off; UnformattedLines class and visit_unformatted() are absent; split_line() (lines ~2051-2066) no longer checks UnformattedLines; EmptyLineTracker.maybe_empty_lines() (lines ~1297-1307) has no UnformattedLines special case.

Todo item 9 of 17 is correct
description: 'Ensure exception-based fmt on/off handling was removed: classes FormatError, FormatOn, and FormatOff no longer exist; generate_comments() no longer raises these exceptions; LineGenerator.visit/visit_default no longer has try/except for FormatOn/Off; UnformattedLines and visit_unformatted() are removed; split_line() no longer checks for UnformattedLines; EmptyLineTracker no longer special-cases UnformattedLines.'

Validating todo item 10 of 17
description: 'Verify generate_comments() now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and never raises on FMT_ON/FMT_OFF (black.py lines ~1971-1991).'

Calling tool: grepTool
def generate_comments\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone
1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
1989:    """
1990:    for pc in list_comments(leaf.prefix, is_endmarker=leaf.type == token.ENDMARKER):
1991:        yield Leaf(pc.type, pc.value, prefix="\n" * pc.newlines)
1992:
1993:
1994:@dataclass
1995:class ProtoComment:
1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
1997:    value: str  # content of the comment
1998:    newlines: int  # how many newlines before the comment
1999:    consumed: int  # how many characters of the original leaf's prefix did we consume
2000:
2001:
2002:@lru_cache(maxsize=4096)
2003:def list_comments(prefix: str, *, is_endmarker: bool) -> List[ProtoComment]:
2004:    result: List[ProtoComment] = []
2005:    if not prefix or "#" not in prefix:
2006:        return result
2007:
2008:    consumed = 0
2009:    nlines = 0
2010:    for index, line in enumerate(prefix.split("\n")):
2011:        consumed += len(line) + 1  # adding the length of the split '\n'
2012:        line = line.lstrip()
2013:        if not line:
2014:            nlines += 1
2015:        if not line.startswith("#"):
2016:            continue
2017:
2018:        if index == 0 and not is_endmarker:
2019:            comment_type = token.COMMENT  # simple trailing comment
2020:        else:
2021:            comment_type = STANDALONE_COMMENT
2022:        comment = make_comment(line)
2023:        result.append(
2024:            ProtoComment(

Calling tool: grepTool
FormatOn|FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Searched for generate_comments and inspected black.py lines 19711991. The function now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and contains no logic to raise on FMT_ON/FMT_OFF. Grepping the code confirms FormatOn/FormatOff classes are not used in black.py anymore.

Todo item 10 of 17 is correct
description: 'Verify generate_comments() now only yields Leaf(pc.type, pc.value, prefix='\n' * pc.newlines) and never raises on FMT_ON/FMT_OFF (black.py lines ~1971-1991).'

Validating todo item 11 of 17
description: 'Verify LineGenerator has visit_STANDALONE_COMMENT() that yields a line break if not inside brackets before visiting the comment leaf (black.py lines ~1544-1547).'

Calling tool: globTool
**/black.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py

Calling tool: grepTool
class LineGenerator\(
Matched content:
1394:class LineGenerator(Visitor[Line]):

Calling tool: grepTool
def visit_STANDALONE_COMMENT\(
Matched content:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1538:
1539:    def visit_ENDMARKER(self, leaf: Leaf) -> Iterator[Line]:
1540:        """End of file. Process outstanding comments and end with a newline."""
1541:        yield from self.visit_default(leaf)
1542:        yield from self.line()
1543:
1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
1545:        if not self.current_line.bracket_tracker.any_open_brackets():
1546:            yield from self.line()
1547:        yield from self.visit_default(leaf)
1548:
1549:    def __attrs_post_init__(self) -> None:
1550:        """You are in a twisty little maze of passages."""
1551:        v = self.visit_stmt
1552:        : Set[str] = set()
1553:        self.visit_assert_stmt = partial(v, keywords={"assert"}, parens={"assert", ","})
1554:        self.visit_if_stmt = partial(
1555:            v, keywords={"if", "else", "elif"}, parens={"if", "elif"}
1556:        )
1557:        self.visit_while_stmt = partial(v, keywords={"while", "else"}, parens={"while"})

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, LineGenerator defines visit_STANDALONE_COMMENT at lines 1544-1547. It checks if no brackets are open and yields a line break (yield from self.line()) before delegating to visit_default(leaf), matching the requirement.

Todo item 11 of 17 is correct
description: 'Verify LineGenerator has visit_STANDALONE_COMMENT() that yields a line break if not inside brackets before visiting the comment leaf (black.py lines ~1544-1547).'

Validating todo item 12 of 17
description: 'Check Line and whitespace handling for STANDALONE_COMMENT: ALWAYS_NO_SPACE includes STANDALONE_COMMENT; Line.is_comment returns True for a line with a single STANDALONE_COMMENT leaf; split_line() short-circuits when line.is_comment is True (black.py lines ~1578-1597, 1049-1052, and 2064-2066).'

Calling tool: grepTool
ALWAYS_NO_SPACE
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1593:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:14:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:67:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:111:    if t in ALWAYS_NO_SPACE:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/empty_lines.py:162:    if t in ALWAYS_NO_SPACE:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1568:        self.visit_import_from = partial(v, keywords=, parens={"import"})
1569:        self.visit_async_funcdef = self.visit_async_stmt
1570:        self.visit_decorated = self.visit_decorators
1571:
1572:
1573:IMPLICIT_TUPLE = {syms.testlist, syms.testlist_star_expr, syms.exprlist}
1574:BRACKET = {token.LPAR: token.RPAR, token.LSQB: token.RSQB, token.LBRACE: token.RBRACE}
1575:OPENING_BRACKETS = set(BRACKET.keys())
1576:CLOSING_BRACKETS = set(BRACKET.values())
1577:BRACKETS = OPENING_BRACKETS | CLOSING_BRACKETS
1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
1579:
1580:
1581:def whitespace(leaf: Leaf, *, complex_subscript: bool) -> str:  # noqa C901
1582:    """Return whitespace prefix if needed for the given `leaf`.
1583:
1584:    `complex_subscript` signals whether the given leaf is part of a subscription
1585:    which has non-trivial arguments, like arithmetic expressions or function calls.
1586:    """
1587:    NO = ""
1588:    SPACE = " "
1589:    DOUBLESPACE = "  "
1590:    t = leaf.type
1591:    p = leaf.parent
1592:    v = leaf.value
1593:    if t in ALWAYS_NO_SPACE:
1594:        return NO
1595:
1596:    if t == token.COMMENT:
1597:        return DOUBLESPACE
1598:
1599:    assert p is not None, f"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}"
1600:    if t == token.COLON and p.type not in {
1601:        syms.subscript,
1602:        syms.subscriptlist,
1603:        syms.sliceop,
1604:    }:
1605:        return NO
1606:
1607:    prev = leaf.prev_sibling
1608:    if not prev:
1609:        prevp = preceding_leaf(p)
1610:        if not prevp or prevp.type in OPENING_BRACKETS:
1611:            return NO
1612:
1613:        if t == token.COLON:
1614:            if prevp.type == token.COLON:
1615:                return NO
1616:
1617:            elif prevp.type != token.COMMA and not complex_subscript:

Calling tool: grepTool
def is_comment|is_comment =
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)

Calling tool: grepTool
def split_line\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2051:def split_line(

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2048:    return "#" + content
2049:
2050:
2051:def split_line(
2052:    line: Line, line_length: int, inner: bool = False, py36: bool = False
2053:) -> Iterator[Line]:
2054:    """Split a `line` into potentially many lines.
2055:
2056:    They should fit in the allotted `line_length` but might not be able to.
2057:    `inner` signifies that there were a pair of brackets somewhere around the
2058:    current `line`, possibly transitively. This means we can fallback to splitting
2059:    by delimiters if the LHS/RHS don't yield any results.
2060:
2061:    If `py36` is True, splitting may generate syntax that is only compatible
2062:    with Python 3.6 and later.
2063:    """
2064:    if line.is_comment:
2065:        yield line
2066:        return
2067:
2068:    line_str = str(line).strip("\n")
2069:    if not line.should_explode and is_line_short_enough(
2070:        line, line_length=line_length, line_str=line_str
2071:    ):
2072:        yield line
2073:        return
2074:
2075:    split_funcs: List[SplitFunc]
2076:    if line.is_def:
2077:        split_funcs = [left_hand_split]
2078:    else:
2079:
2080:        def rhs(line: Line, py36: bool = False) -> Iterator[Line]:
2081:            for omit in generate_trailers_to_omit(line, line_length):
2082:                lines = list(right_hand_split(line, line_length, py36, omit=omit))
2083:                if is_line_short_enough(lines[0], line_length=line_length):
2084:                    yield from lines
2085:                    return
2086:
2087:            # All splits failed, best effort split with no omits.

Calling tool: grepTool
STANDALONE_COMMENT
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:757:STANDALONE_COMMENT = 153
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1126:            if leaf.type == STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1196:            comment.type == STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1207:            comment.type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1544:    def visit_STANDALONE_COMMENT(self, leaf: Leaf) -> Iterator[Line]:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1578:ALWAYS_NO_SPACE = CLOSING_BRACKETS | {token.COMMA, STANDALONE_COMMENT}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1988:    are emitted with a fake STANDALONE_COMMENT token identifier.
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1996:    type: int  # token.COMMENT or STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2021:            comment_type = STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2357:            and current_line.leaves[-1].type != STANDALONE_COMMENT
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2574:                if comment.type != STANDALONE_COMMENT:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2601:                        STANDALONE_COMMENT,
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2878:        if leaf.type == STANDALONE_COMMENT or has_inline_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
740:            code = lib2to3_parse(code)
741:        list(v.visit(code))
742:
743:
744:KEYWORDS = set(keyword.kwlist)
745:WHITESPACE = {token.DEDENT, token.INDENT, token.NEWLINE}
746:FLOW_CONTROL = {"return", "raise", "break", "continue"}
747:STATEMENT = {
748:    syms.if_stmt,
749:    syms.while_stmt,
750:    syms.for_stmt,
751:    syms.try_stmt,
752:    syms.except_clause,
753:    syms.with_stmt,
754:    syms.funcdef,
755:    syms.classdef,
756:}
757:STANDALONE_COMMENT = 153
758:token.tok_name[STANDALONE_COMMENT] = "STANDALONE_COMMENT"
759:LOGIC_OPERATORS = {"and", "or"}
760:COMPARATORS = {
761:    token.LESS,
762:    token.GREATER,
763:    token.EQEQUAL,
764:    token.NOTEQUAL,
765:    token.LESSEQUAL,
766:    token.GREATEREQUAL,
767:}
768:MATH_OPERATORS = {
769:    token.VBAR,

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1110:            and self.leaves[3].type == token.RPAR
1111:            and self.leaves[3].value == ")"
1112:        )
1113:
1114:    @property
1115:    def is_triple_quoted_string(self) -> bool:
1116:        """Is the line a triple quoted string?"""
1117:        return (
1118:            bool(self)
1119:            and self.leaves[0].type == token.STRING
1120:            and self.leaves[0].value.startswith(('"""', "'''"))
1121:        )
1122:
1123:    def contains_standalone_comments(self, depth_limit: int = sys.maxsize) -> bool:
1124:        """If so, needs to be split before emitting."""
1125:        for leaf in self.leaves:
1126:            if leaf.type == STANDALONE_COMMENT:
1127:                if leaf.bracket_depth <= depth_limit:
1128:                    return True
1129:
1130:        return False
1131:
1132:    def contains_multiline_strings(self) -> bool:
1133:        for leaf in self.leaves:
1134:            if is_multiline_string(leaf):
1135:                return True
1136:
1137:        return False
1138:
1139:    def maybe_remove_trailing_comma(self, closing: Leaf) -> bool:
1140:        """Remove trailing comma if there is one and it's safe."""
1141:        if not (
1142:            self.leaves
1143:            and self.leaves[-1].type == token.COMMA
1144:            and closing.type in CLOSING_BRACKETS
1145:        ):
1146:            return False
1147:
1148:        if closing.type == token.RBRACE:
1149:            self.remove_trailing_comma()
1150:            return True
1151:
1152:        if closing.type == token.RSQB:
1153:            comma = self.leaves[-1]
1154:            if comma.parent and comma.parent.type == syms.listmaker:
1155:                self.remove_trailing_comma()
1156:                return True
1157:
1158:        # For parens let's check if it's safe to remove the comma.
1159:        # Imports are always safe.
1160:        if self.is_import:
1161:            self.remove_trailing_comma()
1162:            return True
1163:
1164:        # Otheriwsse, if the trailing one is the only one, we might mistakenly
1165:        # change a tuple into a different type by removing the comma.
1166:        depth = closing.bracket_depth + 1
1167:        commas = 0
1168:        opening = closing.opening_bracket
1169:        for _opening_index, leaf in enumerate(self.leaves):
1170:            if leaf is opening:
1171:                break
1172:
1173:        else:
1174:            return False
1175:
1176:        for leaf in self.leaves[_opening_index + 1 :]:
1177:            if leaf is closing:
1178:                break
1179:
1180:            bracket_depth = leaf.bracket_depth
1181:            if bracket_depth == depth and leaf.type == token.COMMA:
1182:                commas += 1
1183:                if leaf.parent and leaf.parent.type == syms.arglist:
1184:                    commas += 1
1185:                    break
1186:
1187:        if commas > 1:
1188:            self.remove_trailing_comma()
1189:            return True
1190:
1191:        return False
1192:
1193:    def append_comment(self, comment: Leaf) -> bool:
1194:        """Add an inline or standalone comment to the line."""
1195:        if (
1196:            comment.type == STANDALONE_COMMENT
1197:            and self.bracket_tracker.any_open_brackets()
1198:        ):
1199:            comment.prefix = ""
1200:            return False
1201:
1202:        if comment.type != token.COMMENT:
1203:            return False
1204:
1205:        after = len(self.leaves) - 1
1206:        if after == -1:
1207:            comment.type = STANDALONE_COMMENT
1208:            comment.prefix = ""
1209:            return False
1210:
1211:        else:
1212:            self.comments.append((after, comment))
1213:            return True
1214:
1215:    def comments_after(self, leaf: Leaf, _index: int = -1) -> Iterator[Leaf]:
1216:        """Generate comments that should appear directly after `leaf`.
1217:
1218:        Provide a non-negative leaf `_index` to speed up the function.
1219:        """
1220:        if not self.comments:
1221:            return
1222:
1223:        if _index == -1:
1224:            for _index, _leaf in enumerate(self.leaves):
1225:                if leaf is _leaf:
1226:                    break
1227:
1228:            else:
1229:                return

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified three requirements: 1) ALWAYS_NO_SPACE includes STANDALONE_COMMENT at black.py:1578; 2) Line.is_comment returns True for a single STANDALONE_COMMENT leaf at black.py:1049-1052; 3) split_line() short-circuits on line.is_comment at black.py:2064-2066. All implementations are present and correct.

Todo item 12 of 17 is correct
description: 'Check Line and whitespace handling for STANDALONE_COMMENT: ALWAYS_NO_SPACE includes STANDALONE_COMMENT; Line.is_comment returns True for a line with a single STANDALONE_COMMENT leaf; split_line() short-circuits when line.is_comment is True (black.py lines ~1578-1597, 1049-1052, and 2064-2066).'

Validating todo item 13 of 17
description: 'Validate EmptyLineTracker._maybe_empty_lines_for_class_or_def() avoids inserting empty lines when the previous line is a standalone comment at the same depth (black.py lines ~1365-1370).'

Calling tool: grepTool
class EmptyLineTracker
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1283:class EmptyLineTracker:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1260:        )
1261:
1262:    def __str__(self) -> str:
1263:        """Render the line."""
1264:        if not self:
1265:            return "\n"
1266:
1267:        indent = "    " * self.depth
1268:        leaves = iter(self.leaves)
1269:        first = next(leaves)
1270:        res = f"{first.prefix}{indent}{first.value}"
1271:        for leaf in leaves:
1272:            res += str(leaf)
1273:        for _, comment in self.comments:
1274:            res += str(comment)
1275:        return res + "\n"
1276:
1277:    def __bool__(self) -> bool:
1278:        """Return True if the line has leaves or comments."""
1279:        return bool(self.leaves or self.comments)
1280:
1281:
1282:@dataclass
1283:class EmptyLineTracker:
1284:    """Provides a stateful method that returns the number of potential extra
1285:    empty lines needed before and after the currently processed line.
1286:
1287:    Note: this tracker works on lines that haven't been split yet.  It assumes
1288:    the prefix of the first leaf consists of optional newlines.  Those newlines
1289:    are consumed by `maybe_empty_lines()` and included in the computation.
1290:    """
1291:
1292:    is_pyi: bool = False
1293:    previous_line: Optional[Line] = None
1294:    previous_after: int = 0
1295:    previous_defs: List[int] = Factory(list)
1296:
1297:    def maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1298:        """Return the number of extra empty lines before and after the `current_line`.
1299:
1300:        This is for separating `def`, `async def` and `class` with extra empty
1301:        lines (two on module-level).
1302:        """
1303:        before, after = self._maybe_empty_lines(current_line)
1304:        before -= self.previous_after
1305:        self.previous_after = after
1306:        self.previous_line = current_line
1307:        return before, after
1308:
1309:    def _maybe_empty_lines(self, current_line: Line) -> Tuple[int, int]:
1310:        max_allowed = 1
1311:        if current_line.depth == 0:
1312:            max_allowed = 1 if self.is_pyi else 2
1313:        if current_line.leaves:
1314:            # Consume the first leaf's extra newlines.
1315:            first_leaf = current_line.leaves[0]
1316:            before = first_leaf.prefix.count("\n")
1317:            before = min(before, max_allowed)
1318:            first_leaf.prefix = ""
1319:        else:
1320:            before = 0
1321:        depth = current_line.depth
1322:        while self.previous_defs and self.previous_defs[-1] >= depth:
1323:            self.previous_defs.pop()
1324:            if self.is_pyi:
1325:                before = 0 if depth else 1
1326:            else:
1327:                before = 1 if depth else 2
1328:        if current_line.is_decorator or current_line.is_def or current_line.is_class:
1329:            return self._maybe_empty_lines_for_class_or_def(current_line, before)
1330:
1331:        if (
1332:            self.previous_line
1333:            and self.previous_line.is_import
1334:            and not current_line.is_import
1335:            and depth == self.previous_line.depth
1336:        ):
1337:            return (before or 1), 0
1338:
1339:        if (
1340:            self.previous_line
1341:            and self.previous_line.is_class
1342:            and current_line.is_triple_quoted_string
1343:        ):
1344:            return before, 1
1345:
1346:        return before, 0
1347:
1348:    def _maybe_empty_lines_for_class_or_def(
1349:        self, current_line: Line, before: int
1350:    ) -> Tuple[int, int]:
1351:        if not current_line.is_decorator:
1352:            self.previous_defs.append(current_line.depth)
1353:        if self.previous_line is None:
1354:            # Don't insert empty lines before the first line in the file.
1355:            return 0, 0
1356:
1357:        if self.previous_line.is_decorator:
1358:            return 0, 0
1359:
1360:        if self.previous_line.depth < current_line.depth and (
1361:            self.previous_line.is_class or self.previous_line.is_def
1362:        ):
1363:            return 0, 0
1364:
1365:        if (
1366:            self.previous_line.is_comment
1367:            and self.previous_line.depth == current_line.depth
1368:            and before == 0
1369:        ):
1370:            return 0, 0
1371:
1372:        if self.is_pyi:
1373:            if self.previous_line.depth > current_line.depth:
1374:                newlines = 1
1375:            elif current_line.is_class or self.previous_line.is_class:
1376:                if current_line.is_stub_class and self.previous_line.is_stub_class:
1377:                    # No blank line between classes with an emty body
1378:                    newlines = 0
1379:                else:
1380:                    newlines = 1
1381:            elif current_line.is_def and not self.previous_line.is_def:
1382:                # Blank line between a block of functions and a block of non-functions
1383:                newlines = 1
1384:            else:
1385:                newlines = 0
1386:        else:
1387:            newlines = 2
1388:        if current_line.depth and newlines:
1389:            newlines -= 1
1390:        return newlines, 0
1391:
1392:
1393:@dataclass
1394:class LineGenerator(Visitor[Line]):
1395:    """Generates reformatted Line objects.  Empty lines are not emitted.
1396:
1397:    Note: destroys the tree it's visiting by mutating prefixes of its leaves
1398:    in ways that will no longer stringify to valid Python code on the tree.
1399:    """
1400:
1401:    is_pyi: bool = False
1402:    normalize_strings: bool = True
1403:    current_line: Line = Factory(Line)
1404:    remove_u_prefix: bool = False
1405:
1406:    def line(self, indent: int = 0) -> Iterator[Line]:
1407:        """Generate a line.
1408:
1409:        If the line is empty, only emit if it makes sense.
1410:        If the line is too long, split it first and then generate.
1411:
1412:        If any lines were generated, set up a new current_line.
1413:        """
1414:        if not self.current_line:
1415:            self.current_line.depth += indent
1416:            return  # Line is empty, don't emit. Creating a new one unnecessary.
1417:
1418:        complete_line = self.current_line
1419:        self.current_line = Line(depth=complete_line.depth + indent)

Calling tool: grepTool
class Line|def is_comment|@property\n\s+def is_comment
Grep command failed with exit code 2: rg: the literal "\n" is not allowed in a regex

Consider enabling multiline mode with the --multiline flag (or -U for short).
When multiline mode is enabled, new line characters can be matched.


Calling tool: grepTool
(?i)is_comment
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1038:            if self.is_comment:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1049:    def is_comment(self) -> bool:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1366:            self.previous_line.is_comment
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2064:    if line.is_comment:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1000:    inside_brackets: bool = False
1001:    should_explode: bool = False
1002:
1003:    def append(self, leaf: Leaf, preformatted: bool = False) -> None:
1004:        """Add a new `leaf` to the end of the line.
1005:
1006:        Unless `preformatted` is True, the `leaf` will receive a new consistent
1007:        whitespace prefix and metadata applied by :class:`BracketTracker`.
1008:        Trailing commas are maybe removed, unpacked for loop variables are
1009:        demoted from being delimiters.
1010:
1011:        Inline comments are put aside.
1012:        """
1013:        has_value = leaf.type in BRACKETS or bool(leaf.value.strip())
1014:        if not has_value:
1015:            return
1016:
1017:        if token.COLON == leaf.type and self.is_class_paren_empty:
1018:            del self.leaves[-2:]
1019:        if self.leaves and not preformatted:
1020:            # Note: at this point leaf.prefix should be empty except for
1021:            # imports, for which we only preserve newlines.
1022:            leaf.prefix += whitespace(
1023:                leaf, complex_subscript=self.is_complex_subscript(leaf)
1024:            )
1025:        if self.inside_brackets or not preformatted:
1026:            self.bracket_tracker.mark(leaf)
1027:            self.maybe_remove_trailing_comma(leaf)
1028:        if not self.append_comment(leaf):
1029:            self.leaves.append(leaf)
1030:
1031:    def append_safe(self, leaf: Leaf, preformatted: bool = False) -> None:
1032:        """Like :func:`append()` but disallow invalid standalone comment structure.
1033:
1034:        Raises ValueError when any `leaf` is appended after a standalone comment
1035:        or when a standalone comment is not the first leaf on the line.
1036:        """
1037:        if self.bracket_tracker.depth == 0:
1038:            if self.is_comment:
1039:                raise ValueError("cannot append to standalone comments")
1040:
1041:            if self.leaves and leaf.type == STANDALONE_COMMENT:
1042:                raise ValueError(
1043:                    "cannot append standalone comments to a populated line"
1044:                )
1045:
1046:        self.append(leaf, preformatted=preformatted)
1047:
1048:    @property
1049:    def is_comment(self) -> bool:
1050:        """Is this line a standalone comment?"""
1051:        return len(self.leaves) == 1 and self.leaves[0].type == STANDALONE_COMMENT
1052:
1053:    @property
1054:    def is_decorator(self) -> bool:
1055:        """Is this line a decorator?"""
1056:        return bool(self) and self.leaves[0].type == token.AT
1057:
1058:    @property
1059:    def is_import(self) -> bool:
1060:        """Is this an import line?"""
1061:        return bool(self) and is_import(self.leaves[0])
1062:
1063:    @property
1064:    def is_class(self) -> bool:
1065:        """Is this line a class definition?"""
1066:        return (
1067:            bool(self)
1068:            and self.leaves[0].type == token.NAME
1069:            and self.leaves[0].value == "class"
1070:        )
1071:
1072:    @property
1073:    def is_stub_class(self) -> bool:
1074:        """Is this line a class definition with a body consisting only of "..."?"""
1075:        return self.is_class and self.leaves[-3:] == [
1076:            Leaf(token.DOT, ".") for _ in range(3)
1077:        ]
1078:
1079:    @property

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py, EmptyLineTracker._maybe_empty_lines_for_class_or_def includes a condition (lines 1365-1370) that checks if the previous line is a standalone comment at the same depth and if there are no pre-existing blank lines (before == 0). It then returns (0, 0), ensuring no empty lines are inserted. This matches the requirement.

Todo item 13 of 17 is correct
description: 'Validate EmptyLineTracker._maybe_empty_lines_for_class_or_def() avoids inserting empty lines when the previous line is a standalone comment at the same depth (black.py lines ~1365-1370).'

Validating todo item 14 of 17
description: 'Ensure FMT_OFF and FMT_ON sets are defined and include '# fmt: off/on' and Yapf equivalents '# yapf: disable/enable' (black.py lines ~1967-1968).'

Calling tool: grepTool
FMT_OFF|FMT_ON
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2517:        if pc.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2570:            if comment.value in FMT_OFF:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py:2621:            if comment.value in FMT_ON:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
1958:    ):
1959:        return COMPARATOR_PRIORITY
1960:
1961:    if leaf.value in LOGIC_OPERATORS and leaf.parent:
1962:        return LOGIC_PRIORITY
1963:
1964:    return 0
1965:
1966:
1967:FMT_OFF = {"# fmt: off", "# fmt:off", "# yapf: disable"}
1968:FMT_ON = {"# fmt: on", "# fmt:on", "# yapf: enable"}
1969:
1970:
1971:def generate_comments(leaf: LN) -> Iterator[Leaf]:
1972:    """Clean the prefix of the `leaf` and generate comments from it, if any.
1973:
1974:    Comments in lib2to3 are shoved into the whitespace prefix.  This happens
1975:    in `pgen2/driver.py:Driver.parse_tokens()`.  This was a brilliant implementation
1976:    move because it does away with modifying the grammar to include all the
1977:    possible places in which comments can be placed.
1978:
1979:    The sad consequence for us though is that comments don't "belong" anywhere.
1980:    This is why this function generates simple parentless Leaf objects for
1981:    comments.  We simply don't know what the correct parent should be.
1982:
1983:    No matter though, we can live without this.  We really only need to
1984:    differentiate between inline and standalone comments.  The latter don't
1985:    share the line with any code.
1986:
1987:    Inline comments are emitted as regular token.COMMENT leaves.  Standalone

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/black.py
2498:    if new_escape_count > orig_escape_count:
2499:        return  # Do not introduce more escaping
2500:
2501:    if new_escape_count == orig_escape_count and orig_quote == '"':
2502:        return  # Prefer double quotes
2503:
2504:    leaf.value = f"{prefix}{new_quote}{new_body}{new_quote}"
2505:
2506:
2507:def normalize_invisible_parens(node: Node, parens_after: Set[str]) -> None:
2508:    """Make existing optional parentheses invisible or create new ones.
2509:
2510:    `parens_after` is a set of string leaf values immeditely after which parens
2511:    should be put.
2512:
2513:    Standardizes on visible parentheses for single-element tuples, and keeps
2514:    existing visible parentheses for other tuples and generator expressions.
2515:    """
2516:    for pc in list_comments(node.prefix, is_endmarker=False):
2517:        if pc.value in FMT_OFF:
2518:            # This `node` has a prefix with `# fmt: off`, don't mess with parens.
2519:            return
2520:
2521:    check_lpar = False
2522:    for index, child in enumerate(list(node.children)):
2523:        if check_lpar:
2524:            if child.type == syms.atom:
2525:                maybe_make_parens_invisible_in_atom(child)
2526:            elif is_one_tuple(child):
2527:                # wrap child in visible parentheses
2528:                lpar = Leaf(token.LPAR, "(")
2529:                rpar = Leaf(token.RPAR, ")")
2530:                child.remove()
2531:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2532:            elif node.type == syms.import_from:
2533:                # "import from" nodes store parentheses directly as part of
2534:                # the statement
2535:                if child.type == token.LPAR:
2536:                    # make parentheses invisible
2537:                    child.value = ""  # type: ignore
2538:                    node.children[-1].value = ""  # type: ignore
2539:                elif child.type != token.STAR:
2540:                    # insert invisible parentheses
2541:                    node.insert_child(index, Leaf(token.LPAR, ""))
2542:                    node.append_child(Leaf(token.RPAR, ""))
2543:                break
2544:
2545:            elif not (isinstance(child, Leaf) and is_multiline_string(child)):
2546:                # wrap child in invisible parentheses
2547:                lpar = Leaf(token.LPAR, "")
2548:                rpar = Leaf(token.RPAR, "")
2549:                index = child.remove() or 0
2550:                node.insert_child(index, Node(syms.atom, [lpar, child, rpar]))
2551:
2552:        check_lpar = isinstance(child, Leaf) and child.value in parens_after
2553:
2554:
2555:def normalize_fmt_off(node: Node) -> None:
2556:    """Convert content between `# fmt: off`/`# fmt: on` into standalone comments."""
2557:    try_again = True
2558:    while try_again:
2559:        try_again = convert_one_fmt_off_pair(node)
2560:
2561:
2562:def convert_one_fmt_off_pair(node: Node) -> bool:
2563:    """Convert content of a single `# fmt: off`/`# fmt: on` into a standalone comment.
2564:
2565:    Returns True if a pair was converted.
2566:    """
2567:    for leaf in node.leaves():
2568:        previous_consumed = 0
2569:        for comment in list_comments(leaf.prefix, is_endmarker=False):
2570:            if comment.value in FMT_OFF:
2571:                # We only want standalone comments. If there's no previous leaf or
2572:                # the previous leaf is indentation, it's a standalone comment in
2573:                # disguise.
2574:                if comment.type != STANDALONE_COMMENT:
2575:                    prev = preceding_leaf(leaf)
2576:                    if prev and prev.type not in WHITESPACE:
2577:                        continue
2578:
2579:                ignored_nodes = list(generate_ignored_nodes(leaf))
2580:                first = ignored_nodes[0]  # Can be a container node with the `leaf`.
2581:                parent = first.parent
2582:                prefix = first.prefix
2583:                first.prefix = prefix[comment.consumed :]
2584:                hidden_value = (
2585:                    comment.value + "\n" + "".join(str(n) for n in ignored_nodes)
2586:                )
2587:                if hidden_value.endswith("\n"):
2588:                    # That happens when one of the `ignored_nodes` ended with a NEWLINE
2589:                    # leaf (possibly followed by a DEDENT).
2590:                    hidden_value = hidden_value[:-1]
2591:                first_idx = None
2592:                for ignored in ignored_nodes:
2593:                    index = ignored.remove()
2594:                    if first_idx is None:
2595:                        first_idx = index
2596:                assert parent is not None, "INTERNAL ERROR: fmt: on/off handling (1)"
2597:                assert first_idx is not None, "INTERNAL ERROR: fmt: on/off handling (2)"
2598:                parent.insert_child(
2599:                    first_idx,
2600:                    Leaf(
2601:                        STANDALONE_COMMENT,
2602:                        hidden_value,
2603:                        prefix=prefix[:previous_consumed] + "\n" * comment.newlines,
2604:                    ),
2605:                )
2606:                return True
2607:
2608:            previous_consumed += comment.consumed
2609:
2610:    return False
2611:
2612:
2613:def generate_ignored_nodes(leaf: Leaf) -> Iterator[LN]:
2614:    """Starting from the container of `leaf`, generate all leaves until `# fmt: on`.
2615:
2616:    Stops at the end of the block.
2617:    """
2618:    container: Optional[LN] = container_of(leaf)
2619:    while container is not None and container.type != token.ENDMARKER:
2620:        for comment in list_comments(container.prefix, is_endmarker=False):
2621:            if comment.value in FMT_ON:
2622:                return
2623:
2624:        yield container
2625:
2626:        container = container.next_sibling
2627:
2628:
2629:def maybe_make_parens_invisible_in_atom(node: LN) -> bool:
2630:    """If it's safe, make the parens in the atom `node` invisible, recursively."""
2631:    if (
2632:        node.type != syms.atom
2633:        or is_empty_tuple(node)
2634:        or is_one_tuple(node)
2635:        or is_yield(node)
2636:        or max_delimiter_priority_in_atom(node) >= COMMA_PRIORITY
2637:    ):
2638:        return False
2639:
2640:    first = node.children[0]
2641:    last = node.children[-1]
2642:    if first.type == token.LPAR and last.type == token.RPAR:
2643:        # make parentheses invisible
2644:        first.value = ""  # type: ignore
2645:        last.value = ""  # type: ignore
2646:        if len(node.children) > 1:
2647:            maybe_make_parens_invisible_in_atom(node.children[1])

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: In black.py lines 1967-1968, FMT_OFF and FMT_ON are defined and include '# fmt: off', '# fmt: on', and Yapf equivalents '# yapf: disable' and '# yapf: enable' (plus compact variants). Verified via grep and reading those lines.

Todo item 14 of 17 is correct
description: 'Ensure FMT_OFF and FMT_ON sets are defined and include '# fmt: off/on' and Yapf equivalents '# yapf: disable/enable' (black.py lines ~1967-1968).'

Validating todo item 15 of 17
description: 'Confirm that tests/data/fmtonoff2.py contains no '# output' marker so expected == input per read_data(); tests/test_black.py:test_fmtonoff2 reads 'fmtonoff2' and asserts formatted output equals expected (tests/test_black.py lines ~404-409 and read_data implementation lines ~34-54).'

Calling tool: grepTool
def test_fmtonoff2\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:404:    def test_fmtonoff2(self) -> None:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
396:    def test_fmtonoff(self) -> None:
397:        source, expected = read_data("fmtonoff")
398:        actual = fs(source)
399:        self.assertFormatEqual(expected, actual)
400:        black.assert_equivalent(source, actual)
401:        black.assert_stable(source, actual, line_length=ll)
402:
403:    @patch("black.dump_to_file", dump_to_stderr)
404:    def test_fmtonoff2(self) -> None:
405:        source, expected = read_data("fmtonoff2")
406:        actual = fs(source)
407:        self.assertFormatEqual(expected, actual)
408:        black.assert_equivalent(source, actual)
409:        black.assert_stable(source, actual, line_length=ll)
410:
411:    @patch("black.dump_to_file", dump_to_stderr)
412:    def test_remove_empty_parentheses_after_class(self) -> None:
413:        source, expected = read_data("class_blank_parentheses")
414:        actual = fs(source)
415:        self.assertFormatEqual(expected, actual)
416:        black.assert_equivalent(source, actual)
417:        black.assert_stable(source, actual, line_length=ll)
418:
419:    @patch("black.dump_to_file", dump_to_stderr)
420:    def test_new_line_between_class_and_code(self) -> None:
421:        source, expected = read_data("class_methods_new_line")
422:        actual = fs(source)
423:        self.assertFormatEqual(expected, actual)
424:        black.assert_equivalent(source, actual)
425:        black.assert_stable(source, actual, line_length=ll)

Calling tool: grepTool
def read_data\(
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py:34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/test_black.py
1:#!/usr/bin/env python3
2:import asyncio
3:from concurrent.futures import ThreadPoolExecutor
4:from contextlib import contextmanager
5:from functools import partial
6:from io import BytesIO, TextIOWrapper
7:import os
8:from pathlib import Path
9:import re
10:import sys
11:from tempfile import TemporaryDirectory
12:from typing import Any, BinaryIO, Generator, List, Tuple, Iterator
13:import unittest
14:from unittest.mock import patch, MagicMock
15:
16:from click import unstyle
17:from click.testing import CliRunner
18:
19:import black
20:
21:
22:ll = 88
23:ff = partial(black.format_file_in_place, line_length=ll, fast=True)
24:fs = partial(black.format_str, line_length=ll)
25:THIS_FILE = Path(__file__)
26:THIS_DIR = THIS_FILE.parent
27:EMPTY_LINE = "# EMPTY LINE WITH WHITESPACE" + " (this comment will be removed)"
28:
29:
30:def dump_to_stderr(*output: str) -> str:
31:    return "\n" + "\n".join(output) + "\n"
32:
33:
34:def read_data(name: str, data: bool = True) -> Tuple[str, str]:
35:    """read_data('test_name') -> 'input', 'output'"""
36:    if not name.endswith((".py", ".pyi", ".out", ".diff")):
37:        name += ".py"
38:    _input: List[str] = []
39:    _output: List[str] = []
40:    base_dir = THIS_DIR / "data" if data else THIS_DIR
41:    with open(base_dir / name, "r", encoding="utf8") as test:
42:        lines = test.readlines()
43:    result = _input
44:    for line in lines:
45:        line = line.replace(EMPTY_LINE, "")
46:        if line.rstrip() == "# output":
47:            result = _output
48:            continue
49:
50:        result.append(line)
51:    if _input and not _output:
52:        # If there's no output marker, treat the entire file as already pre-formatted.
53:        _output = _input[:]
54:    return "".join(_input).strip() + "\n", "".join(_output).strip() + "\n"
55:
56:
57:@contextmanager
58:def cache_dir(exists: bool = True) -> Iterator[Path]:
59:    with TemporaryDirectory() as workspace:
60:        cache_dir = Path(workspace)
61:        if not exists:
62:            cache_dir = cache_dir / "new"
63:        with patch("black.CACHE_DIR", cache_dir):
64:            yield cache_dir
65:
66:
67:@contextmanager
68:def event_loop(close: bool) -> Iterator[None]:
69:    policy = asyncio.get_event_loop_policy()
70:    old_loop = policy.get_event_loop()
71:    loop = policy.new_event_loop()
72:    asyncio.set_event_loop(loop)
73:    try:
74:        yield
75:
76:    finally:
77:        policy.set_event_loop(old_loop)
78:        if close:
79:            loop.close()
80:

Calling tool: globTool
**/tests/data/fmtonoff2.py
Matched files:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py

Calling tool: readTool
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/tests/data/fmtonoff2.py
1:import pytest
2:
3:TmSt = 1
4:TmEx = 2
5:
6:# fmt: off
7:
8:# Test data:
9:#   Position, Volume, State, TmSt/TmEx/None, [call, [arg1...]]
10:
11:@pytest.mark.parametrize('test', [
12:
13:    # Test don't manage the volume
14:    [
15:        ('stuff', 'in')
16:    ],
17:])
18:def test_fader(test):
19:    pass
20:
21:def check_fader(test):
22:    pass
23:
24:def test_calculate_fades():
25:    calcs = [
26:        # one is zero/none
27:        (0, 4, 0, 0, 10,        0, 0, 6, 10),
28:        (None, 4, 0, 0, 10,     0, 0, 6, 10),
29:    ]
30:
31:# fmt: on

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as CORRECT
Reason: Verified tests/data/fmtonoff2.py has no '# output' marker. read_data() (tests/test_black.py:34-54) therefore sets expected == input. test_fmtonoff2 (tests/test_black.py:404-409) reads 'fmtonoff2' and asserts formatted output equals expected. All conditions satisfied.

Todo item 15 of 17 is correct
description: 'Confirm that tests/data/fmtonoff2.py contains no '# output' marker so expected == input per read_data(); tests/test_black.py:test_fmtonoff2 reads 'fmtonoff2' and asserts formatted output equals expected (tests/test_black.py lines ~404-409 and read_data implementation lines ~34-54).'

Validating todo item 16 of 17
description: 'Double-check that there are no remaining references to deleted UnformattedLines, FormatOn, or FormatOff identifiers anywhere in the codebase (grep for these names should yield no uses).'

Calling tool: grepTool
UnformattedLines
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:41::class:`UnformattedLines`
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_classes.rst:44:.. autoclass:: black.UnformattedLines

Calling tool: grepTool
FormatOn
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:12:.. autoexception:: black.FormatOn

Calling tool: grepTool
FormatOff
Matched content:
/Users/marcus/repos/BugsInPy/framework/bin/temp/black-15/bad/black/docs/reference/reference_exceptions.rst:14:.. autoexception:: black.FormatOff

Calling tool: grepTool
\b(UnformattedLines|FormatOn|FormatOff)\b
No files found. Call grepTool again with a more generic pattern.

Calling tool: updateTodo
Todo Item Completed
Todo item was marked as INCORRECT
Reason: Global grep shows remaining references in docs: UnformattedLines in docs/reference/reference_classes.rst and FormatOn/FormatOff in docs/reference/reference_exceptions.rst. The requirement said grep should yield no uses anywhere in the codebase.


=== PHASE 2 COMPLETE ===

